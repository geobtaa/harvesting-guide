{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse XML for MSU Important Farmland Maps\n",
    "\n",
    "- convert XML to a spreadsheet\n",
    "- format Aardvark schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import re\n",
    "import urllib.request\n",
    "import uuid\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open('maps-geoportal_2022-05-09-04.xml'), 'html.parser')\n",
    "features = soup.find_all('mods:mods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_bbox(coords):\n",
    "    [x_range,y_range] = coords.split('/')\n",
    "    \n",
    "    x_coord = []\n",
    "    for coord in x_range.split('--'):\n",
    "        if 'W' in coord:\n",
    "            degree = float(re.search('W (.*)°', coord).group(1))\n",
    "            minute = float(re.search('°(.*)ʹ', coord).group(1))\n",
    "            #second = float(re.search('ʹ(.*)ʺ', coord).group(1))\n",
    "            dd = degree + minute/60\n",
    "             #+ second/3600\n",
    "            dd = round(dd,4)\n",
    "            dd *= -1\n",
    "        elif 'E' in coord:\n",
    "            degree = float(re.search('E (.*)°', coord).group(1))\n",
    "            minute = float(re.search('°(.*)ʹ', coord).group(1))\n",
    "            #second = float(re.search('ʹ(.*)ʺ', coord).group(1))\n",
    "            dd = degree + minute/60\n",
    "            #+ second/3600\n",
    "            dd = round(dd,4)\n",
    "        \n",
    "        x_coord.append(dd)\n",
    "\n",
    "    [w,e] = sorted(x_coord, key=float)\n",
    "    \n",
    "    \n",
    "    y_coord = []\n",
    "    for coord in y_range.split('--'):\n",
    "        if 'S' in coord:\n",
    "            degree = float(re.search('S (.*)°', coord).group(1))\n",
    "            minute = float(re.search('°(.*)ʹ', coord).group(1))\n",
    "            second = float(re.search('ʹ(.*)ʺ', coord).group(1))\n",
    "            dd = degree + minute/60 + second/3600\n",
    "            dd = round(dd,4)\n",
    "            dd *= -1\n",
    "        elif 'N' in coord:\n",
    "            degree = float(re.search('N (.*)°', coord).group(1))\n",
    "            minute = float(re.search('°(.*)ʹ', coord).group(1))\n",
    "            second = float(re.search('ʹ(.*)ʺ', coord).group(1))\n",
    "            dd = degree + minute/60 + second/3600\n",
    "            dd = round(dd,4)\n",
    "        \n",
    "        y_coord.append(dd)\n",
    "    \n",
    "    [s,n] = sorted(y_coord, key=float)\n",
    "\n",
    "    return '{},{},{},{}'.format(w,s,e,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def request_arkURL(arkURL):\n",
    "    page = urllib.request.urlopen(arkURL)\n",
    "\n",
    "    information = identifier = page.url\n",
    "    download = information+'/datastream/OBJ/Download/'\n",
    "    \n",
    "    soup2 = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    downloadDIV = soup2.find('a', {'aria-label': 'download Original file'}).parent\n",
    "    div_siblings = downloadDIV.previous_siblings\n",
    "    \n",
    "    format = fileSize = ''\n",
    "    for div in div_siblings:\n",
    "        if isinstance(div, NavigableString):\n",
    "            continue\n",
    "        if isinstance(div, Tag):\n",
    "            txt = div.find('span', 'msul_repo_screen_reader_only').text\n",
    "#             print(txt)\n",
    "            if 'Format ' in txt:\n",
    "                format = txt.split('Format ')[1]\n",
    "            if 'Size ' in txt:\n",
    "                fileSize = txt.split('Size ')[1]\n",
    "\n",
    "    return information, identifier, download, format, fileSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ALL_METADATA = []\n",
    "for feature in features:\n",
    "    title = ''\n",
    "    alternativeTitle = feature.find_all('mods:title')[0].text\n",
    "    \n",
    "    cartographer = publisher = contributor = ''\n",
    "    nameTags = feature.find_all('mods:name')\n",
    "    for name_tag in nameTags:\n",
    "        name_list = [x.text for x in name_tag.find_all('mods:namepart')]\n",
    "        name = '|'.join(name_list)\n",
    "        \n",
    "        role_list = [x.text for x in name_tag.find_all('mods:roleterm')]\n",
    "        for role in role_list:\n",
    "            if role == 'cartographer':\n",
    "                cartographer = name\n",
    "            if role == 'publisher':\n",
    "                publisher = name\n",
    "            if role == 'contributor':\n",
    "                contributor = name\n",
    "            \n",
    "    \n",
    "    resourceType = feature.find('mods:typeofresource').text\n",
    "    \n",
    "    spatialCoverage = feature.find('mods:placeterm').text  # may not correct\n",
    "\n",
    "    dateIssued = feature.find('mods:dateissued').text\n",
    "    \n",
    "    language = feature.find('mods:language').find('mods:languageterm', type='code').text\n",
    "    \n",
    "    bbox = feature.find('mods:coordinates').text\n",
    "#     bbox = format_bbox(bbox)\n",
    "    \n",
    "#     \n",
    "\n",
    " \n",
    "    scale = feature.find('mods:scale').text\n",
    "    \n",
    "    try:\n",
    "        note = feature.find('mods:note').text\n",
    "    except:\n",
    "        note = 'null'\n",
    "    \n",
    "    description = scale + '; ' + note\n",
    "    \n",
    "    topicTags = [ x.find('mods:topic') for x in feature.find_all('mods:subject', authority='lcsh')]\n",
    "    keyword = '|'.join([x.text for x in topicTags if x != None])\n",
    "    \n",
    "    catalogURL = feature.find('mods:url', note='catalog_record').text\n",
    "    \n",
    "    rights = feature.find('mods:accesscondition',type='use and reproduction').text\n",
    "    \n",
    "    \n",
    "    # request arkURL -> landingPage url & download & filesize & Identifier & format\n",
    "    arkURL = feature.find('mods:url', note='ark').text    # Permanent Link\n",
    "    information, identifier, download, format, fileSize = request_arkURL(arkURL)\n",
    "    \n",
    "    resourceClass = 'Maps'\n",
    "    subject = ''\n",
    "    temporalCoverage = dateRange = ''\n",
    "    memberOf = '64bd8c4c-8e60-4956-b43d-bdc3f93db488'\n",
    "    isPartOf = '06d-02'\n",
    "    code = '06d-02'\n",
    "    accessRights = 'Public'\n",
    "    ID = uuid.uuid4()\n",
    "\n",
    "    \n",
    "    \n",
    "    metadata = [title, alternativeTitle, description,language,cartographer,publisher,contributor,\n",
    "                resourceClass, resourceType, keyword, dateIssued, temporalCoverage, dateRange,\n",
    "                spatialCoverage, bbox, memberOf, isPartOf, code, rights, accessRights, format, fileSize,\n",
    "                ID, identifier, information, arkURL, download]\n",
    "    \n",
    "\n",
    "          \n",
    "    ALL_METADATA.append(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames = ['Title', 'Alternative Title', 'Description', 'Language', 'Cartographer', 'Publisher', 'Contributor',\n",
    "              'Resource Class', 'Resource Type', 'Keyword', 'Date Issued', 'Temporal Coverage', 'Date Range',\n",
    "              'Spatial Coverage', 'Bounding Box', 'Member Of', 'Is Part Of', 'Code', 'Rights', 'Access Rights', \n",
    "              'Format', 'File Size', 'ID', 'Identifier', 'Information', 'Permanent Link', 'Download']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MSU_maps_metadata.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fieldnames)\n",
    "    writer.writerows(ALL_METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
