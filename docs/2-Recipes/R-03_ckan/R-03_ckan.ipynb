{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0caeaf6",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This script will harvest from a set of CKAN data portals. It saves metadata files and will compare the output between runs. The result will be two CSVs: new items and deleted items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239ad10",
   "metadata": {},
   "source": [
    "Set up your directory to contain these four items:\n",
    "\n",
    "- `harvest.ipynb`\n",
    "- `CKANportals.csv` includes some basic information about each CKAN portal.\n",
    "- `resource` folder: collects existing resource names by portal for each re-accession. The new one will be compared with the latest one to get both the created and deleted datasets.\n",
    "- `reports` folder: stores the metadata CSV files for all new and deleted datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a3560",
   "metadata": {},
   "source": [
    "## 1. Import modules\n",
    "\n",
    "### Import required modules necessary for the script and use auto-generate time statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa74523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib.request\n",
    "import json \n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from html.parser import HTMLParser\n",
    "import re\n",
    "import ast\n",
    "import decimal\n",
    "import ssl\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a254be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-generate the current time in 'YYYYMM' format\n",
    "actionDate = time.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48cd13",
   "metadata": {},
   "source": [
    "## 2. Extraction of Portals\n",
    "\n",
    "### Read from local CKANportals.csv ane extract the URL, Provider, Publisher, Spatial Coverage and Bounding box for each portalName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77312d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "portalsInfo = {}\n",
    "\n",
    "with open('CKANportals.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    \n",
    "    # Jump over the fieldnames\n",
    "    # Loop over from the first content record\n",
    "    csv_fields = next(reader)\n",
    "    for row in reader:\n",
    "        portalsInfo[row[0]] = [row[1], row[2], row[3], row[4], row[5]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f75f18",
   "metadata": {},
   "source": [
    "### Loop over each portal, collect the up-to-date resources. We get the created datasets and deleted datasets after comparison. For those newly created datasets, request and create their metadata. For those deleted, store the resource name along with its portal code in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769cf90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compare old and new resource list\n",
    "# return created and deleted items separately\n",
    "\n",
    "def returnNotMatches(old, new):\n",
    "    oldResource = set(old)\n",
    "    newResource = set(new)\n",
    "    return [list(newResource - oldResource), list(oldResource - newResource)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd797405",
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to removes html tags from text\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True        \n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def cleanData(value):\n",
    "    fieldvalue = strip_tags(value)\n",
    "    return fieldvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d64a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to format metadata for new items\n",
    "\n",
    "def metadataNewItems(newdata):    \n",
    "    metadata = []\n",
    "    \n",
    "    title = ''\n",
    "    alternativeTitle = newdata['result']['title']\n",
    "        \n",
    "    description = cleanData(newdata['result']['notes'])\n",
    "    ### Remove newline, whitespace, defalut description and replace singe quote, double quote \n",
    "    if description == '{{default.description}}':\n",
    "        description = description.replace('{{default.description}}', '')\n",
    "    else:\n",
    "        description = re.sub(r'[\\n]+|[\\r\\n]+',' ', description, flags=re.S)\n",
    "        description = re.sub(r'\\s{2,}' , ' ', description)\n",
    "        description = description.replace(u'\\u2019', \"'\").replace(u'\\u201c', '\\\"').replace(u'\\u201d', '\\\"').replace(u'\\u00a0', '').replace(u'\\u00b7', '').replace(u'\\u2022', '').replace(u'\\u2013','-').replace(u'\\u200b', '')\n",
    "\n",
    "    language = 'eng'  \n",
    "    creator = ''\n",
    "    index = 0\n",
    "        \n",
    "    publisher = portalPublisher       \n",
    "    spatialCoverage = portalSpaCov   \n",
    "\n",
    "    if 'extras' in newitem['result']:\n",
    "        extras = newitem['result']['extras']    \n",
    "        for dictionary in extras:\n",
    "            if dictionary['key'] == 'dsOriginator':\n",
    "                creator = dictionary['value']\n",
    "\n",
    "                ## if Creator field contains keywork 'County', extract the county name to fill in Publisher and Spatial Coverage field\n",
    "                ## otherwise, autofill both fileds with 'Minnesota'\n",
    "                index = creator.find('County')\n",
    "                if index != -1:\n",
    "                    publisher = creator[: index + 6]\n",
    "                    spatialCoverage = publisher + f', {portalSpaCov}|{portalSpaCov}'   \n",
    "    \n",
    "                            \n",
    "    format_types = []\n",
    "    resourceClass = ''\n",
    "    formatElement = ''\n",
    "    downloadURL =  ''\n",
    "    resourceType = ''\n",
    "    featureServer = ''\n",
    "    webService = ''\n",
    "    html = ''\n",
    "    previewImg = ''\n",
    "    \n",
    "    distribution = newdata['result']['resources']\n",
    "    for dictionary in distribution:\n",
    "        try:\n",
    "            ### if one of the distributions is a shapefile, change genre/format and get the downloadURL\n",
    "            format_types.extend([dictionary['format']])\n",
    "            if dictionary['format'] == 'SHP':\n",
    "                resourceClass = 'Datasets'\n",
    "                formatElement = 'Shapefile'\n",
    "                downloadURL = dictionary['url']\n",
    "                resourceType = 'Vector data'\n",
    "                \n",
    "                \n",
    "            ### if one of the distributions is WMS, and it is taged as 'aerial photography'\n",
    "            ### change genre, type, and format to relate to imagery\n",
    "            if dictionary['format'] == 'WMS':\n",
    "                tags = newdata['result']['tags']\n",
    "                for tag in tags:\n",
    "                    if tag['display_name'] == 'aerial photography':                        \n",
    "                        resourceClass = 'Imagery'\n",
    "                        formatElement = 'Imagery'\n",
    "                        downloadURL = dictionary['url']\n",
    "                        resourceType = 'Satellite imagery'\n",
    "                        \n",
    "            ### saves the url if the dataset has Webservice format         \n",
    "            if dictionary['format'] == 'ags_mapserver':\n",
    "                webService = dictionary['url']\n",
    "                \n",
    "            ### saves the metadata page\n",
    "            if dictionary['format'] == 'HTML':\n",
    "                html = dictionary['url']   \n",
    "            \n",
    "            ### saves the thumbnail iamge\n",
    "            if dictionary['format'] == 'JPEG':\n",
    "                previewImg = dictionary['url']    \n",
    "                \n",
    "        ### if the distribution section of the metadata is not structured in a typical way\n",
    "        except:\n",
    "            resourceClass = ''\n",
    "            formatElement = ''\n",
    "            downloadURL =  ''       \n",
    "            continue\n",
    "                                                \n",
    "    \n",
    "    ### extracts the bounding box \n",
    "    try:\n",
    "        bbox = []\n",
    "        spatial = ''\n",
    "        extra_spatial = newdata['result']['extras']\n",
    "        for dictionary in extra_spatial:\n",
    "            if dictionary['key'] == 'spatial':\n",
    "                spatialList = ast.literal_eval(dictionary['value'].split(':[')[1].split(']}')[0])\n",
    "                coordmin = spatialList[0]\n",
    "                coordmax = spatialList[2]\n",
    "                coordmin.extend(coordmax)\n",
    "                typeDmal = decimal.Decimal\n",
    "                fix3 = typeDmal(\"0.001\")\n",
    "                for coord in coordmin:\n",
    "                    coordFix = typeDmal(coord).quantize(fix3)\n",
    "                    bbox.extend([str(coordFix)])\n",
    "                    spatial = ','.join(bbox)            \n",
    "    except:\n",
    "        spatial = ''     \n",
    "        \n",
    "    try:\n",
    "        theme = ''\n",
    "        groups_theme = newdata['result']['groups']\n",
    "        if len(groups_theme) != 0:\n",
    "            theme = groups_theme[0]['display_name'].replace('+', 'and')\n",
    "    except:\n",
    "        theme = ''\n",
    "    \n",
    "    keyword_list = []\n",
    "    keyword = newdata['result']['tags']\n",
    "    for dictionary in keyword:\n",
    "        keyword_list.extend([dictionary['display_name']])\n",
    "    keyword_list = ','.join(keyword_list).replace(',', '|')\n",
    "    \n",
    "    dateIssued = newdata['result']['metadata_created']\n",
    "    temporalCoverage = 'Continually updated resource'\n",
    "    dateRange = ''\n",
    "    \n",
    "    information = landingurl + newdata['result']['name']\n",
    "    ID = newdata['result']['id']\n",
    "    \n",
    "    featureServer = ''\n",
    "    mapServer = ''\n",
    "    imageServer = ''\n",
    "    \n",
    "    ### specifies the Webservice type by querying the webService string    \n",
    "    try:\n",
    "        if 'FeatureServer' in webService:\n",
    "            featureServer = webService\n",
    "        if 'MapServer' in webService:\n",
    "            mapServer = webService\n",
    "        if 'ImageServer' in webService:\n",
    "            imageServer = webService\n",
    "    except:\n",
    "            print(ID)\n",
    "    \n",
    "    identifier = item\n",
    "    provider = portalProvider  \n",
    "    code = portal     \n",
    "    memberOf = 'ba5cc745-21c5-4ae9-954b-72dd8db6815a'\n",
    "    isPartOf = portal\n",
    "    \n",
    "    \n",
    "    status = 'Active'\n",
    "    accuralMethod = 'CKAN'\n",
    "    dateAccessioned = time.strftime('%Y-%m-%d')\n",
    "                \n",
    "    rights = ''               \n",
    "    accessRights = 'Public'\n",
    "    suppressed = 'FALSE'\n",
    "    childRecord = 'FALSE'\n",
    "    \n",
    "    metadataList = [title, alternativeTitle, description, language, creator, publisher,\n",
    "                    resourceClass, theme, keyword_list, dateIssued, temporalCoverage,\n",
    "                    dateRange, spatialCoverage, spatial, resourceType,\n",
    "                    formatElement, information, downloadURL, mapServer, featureServer,\n",
    "                    imageServer, html, previewImg, ID, identifier, provider, code, memberOf, isPartOf, status,\n",
    "                    accuralMethod, dateAccessioned, rights, accessRights, suppressed, childRecord]\n",
    "    \n",
    "    ### check the resource class: if it is neither 'Datasets' nor 'Imagery', create a empty list\n",
    "    for i in range(len(metadataList)):\n",
    "        if metadataList[6] != '':\n",
    "            metadata = metadataList\n",
    "        else: \n",
    "            continue\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllNewMetadata = []\n",
    "AllDeleltedItem = []\n",
    "\n",
    "for portal in portalsInfo:     \n",
    "    print()\n",
    "    print(f'Harvesting portal {portal}')\n",
    "    \n",
    "    ### delete later\n",
    "    if portal == '05d-11':\n",
    "        print('>>> skip 05d-11')\n",
    "        continue\n",
    "\n",
    "    portalURL = portalsInfo[portal][0]\n",
    "    portalProvider = portalsInfo[portal][1]\n",
    "    portalPublisher = portalsInfo[portal][2]\n",
    "    portalSpaCov = portalsInfo[portal][3]\n",
    "\n",
    "    packageURL = portalURL + 'api/3/action/package_list'\n",
    "    landingurl = portalURL + 'dataset/'\n",
    "\n",
    "    # request new resources list\n",
    "    context = ssl._create_unverified_context()\n",
    "    response = urllib.request.urlopen(packageURL, context=context).read()\n",
    "    packageList = json.loads(response.decode('utf-8'))\n",
    "    newList = packageList['result']\n",
    "\n",
    "    #store new resources locally for next re-accession\n",
    "    with open(f'CKAN/{portal}_{actionDate}.csv', 'w') as fw:\n",
    "        writer = csv.writer(fw)\n",
    "        field = ['result']\n",
    "        rows = np.reshape(newList, (-1, 1))\n",
    "        writer.writerow(field)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    # find the latest resources list\n",
    "    dates = []\n",
    "    filenames = os.listdir('CKAN')\n",
    "    for filename in filenames:\n",
    "        if filename.startswith(portal):\n",
    "            dates.append(filename[-12:-4]) \n",
    "\n",
    "    if actionDate in dates:\n",
    "        dates.remove(actionDate)\n",
    "\n",
    "\n",
    "    # For portals already existed for last re-accession:\n",
    "    ## compare the current and the latest resources\n",
    "    ## and find new and deleted items\n",
    "    if dates:\n",
    "        oldDate = max(dates)\n",
    "        oldResource = f'CKAN/{portal}_{oldDate}.csv'\n",
    "\n",
    "        oldList = []\n",
    "        with open(oldResource) as fr:\n",
    "            reader = csv.reader(fr)\n",
    "            field = next(reader)\n",
    "            for row in reader:\n",
    "                oldList.append(row[0])\n",
    "\n",
    "        newItems = []\n",
    "        deletedItems = []\n",
    "\n",
    "        newItems = returnNotMatches(oldList, newList)[0]\n",
    "        deletedItems = returnNotMatches(oldList, newList)[1]\n",
    "        AllDeleltedItem += [[portal, x] for x in deletedItems]\n",
    "\n",
    "\n",
    "    # For new portals:\n",
    "    # all current resources are new and do not have deleted items\n",
    "    else:\n",
    "        newItems = newList\n",
    "\n",
    "\n",
    "    # Create metadata for all new items for each portal\n",
    "    withEmpty = []\n",
    "    metadata = []\n",
    "    count = 0\n",
    "    total = len(newItems)\n",
    "\n",
    "    for item in newItems:\n",
    "        count += 1\n",
    "        itemURL = portalURL + 'api/3/action/package_show?id=' + item\n",
    "        print(f'>>> Collecting dataset({count}/{total}): {itemURL}')\n",
    "\n",
    "        context = ssl._create_unverified_context()\n",
    "        response = urllib.request.urlopen(itemURL, context=context).read()\n",
    "        newitem = json.loads(response.decode('utf-8'))\n",
    "        withEmpty.append(metadataNewItems(newitem))\n",
    "\n",
    "    # check whether empty\n",
    "    metadata = [x for x in withEmpty if x != []]\n",
    "    AllNewMetadata += metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee8df2",
   "metadata": {},
   "source": [
    "## 3. Print Reports\n",
    "\n",
    "- These series of cells in the following of steps each:\n",
    "- 1. Read the new CSV for both new and deleted items\n",
    "- 2. Write CSV file for all new datasets.\n",
    "- 3. Write CSV file for all deleted datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3787566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printReport(report, fields, datalist):\n",
    "    with open(report, 'w', newline='', encoding='utf-8') as f:\n",
    "        csvout = csv.writer(f)\n",
    "        csvout.writerow(fields)\n",
    "        csvout.writerows(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames_new = ['Title', 'Alternative Title', 'Description', 'Language', 'Creator', 'titleSource', 'Resource Class',\n",
    "              'Theme', 'Keyword', 'Date Issued', 'Temporal Coverage', 'Date Range', 'Spatial Coverage',\n",
    "              'Bounding Box', 'Resource Type', 'Format', 'Information', 'Download', 'MapServer', \n",
    "              'FeatureServer', 'ImageServer', 'HTML', 'Image', 'ID', 'Identifier', 'Provider', 'Code', 'Member Of', \n",
    "              'Is Part Of', 'Status', 'Accrual Method', 'Date Accessioned', 'Rights', 'Access Rights', 'Suppressed', 'Child Record']\n",
    "\n",
    "filepath_new = f'reports/allNewItems_{actionDate}.csv'   \n",
    "printReport(filepath_new, fieldnames_new, AllNewMetadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames_del = ['Portal', 'Resource']\n",
    "\n",
    "filepath_del = f'reports/allDeletedItems_{actionDate}.csv'   \n",
    "printReport(filepath_del, fieldnames_del, AllDeleltedItem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
