{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a446268",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This script will scan a list of ArcGIS Hubs and return the metadata for all suitable items as a CSV file in the GeoBTAA Metadata Application Profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7df424",
   "metadata": {},
   "source": [
    "### Before you run this Notebook: Get the currently active portal list by downloading them from GEOMG. \n",
    "\n",
    "1. Filter for items with these parameters:\n",
    "   - Resource Class: Websites\n",
    "   - Accrual Method: DCAT US 1.1\n",
    "   - This link should work: https://geomg.lib.umn.edu/documents?f%5Bb1g_dct_accrualMethod_s%5D%5B%5D=DCAT+US+1.1&f%5Bgbl_resourceClass_sm%5D%5B%5D=Websites&rows=20&sort=score+desc\n",
    "   \n",
    "2. Rename the downloaded file `arcPortals.csv` and move it into the same directory as this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff38b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import urllib.request\n",
    "from html.parser import HTMLParser\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5a55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the current local time with the format like 'YYYYMMDD' and save to the variable named 'ActionDate'\n",
    "ActionDate = time.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38c9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants and set up paths\n",
    "directory = \".\"  # Set to directory containing arcPortals.csv\n",
    "portalFile = \"arcPortals.csv\"  # Name of portal list csv file\n",
    "fieldnames = [  # DCAT schema fields to be included in report\n",
    "    \"Title\",\n",
    "    \"Alternative Title\",\n",
    "    \"Description\",\n",
    "    \"Language\",\n",
    "    \"Creator\",\n",
    "    \"Resource Class\",\n",
    "    \"Resource Type\",\n",
    "    \"Keyword\",\n",
    "    \"Date Issued\",\n",
    "    \"Temporal Coverage\",\n",
    "    \"Date Range\",\n",
    "    \"Spatial Coverage\",\n",
    "    \"Bounding Box\",\n",
    "    \"Format\",\n",
    "    \"Information\",\n",
    "    \"Download\",\n",
    "    \"MapServer\",\n",
    "    \"FeatureServer\",\n",
    "    \"ImageServer\",\n",
    "    \"ID\",\n",
    "    \"Identifier\",\n",
    "    \"Provider\",\n",
    "    \"Code\",\n",
    "    \"Member Of\",\n",
    "    \"Is Part Of\",\n",
    "    \"Rights\",\n",
    "    \"Accrual Method\",\n",
    "    \"Date Accessioned\",\n",
    "    \"Access Rights\",\n",
    "]\n",
    "json_ids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7616ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove html tags from text\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return \"\".join(self.fed)\n",
    "\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "\n",
    "def cleanData(value):\n",
    "    return strip_tags(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6391c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate an output CSV\n",
    "\n",
    "def printItemReport(report, fields, dictionary):\n",
    "    with open(report, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        csvout = csv.writer(outfile)\n",
    "        csvout.writerow(fields)\n",
    "        for portal in dictionary:\n",
    "            for keys in portal:\n",
    "                allvalues = portal[keys]\n",
    "                csvout.writerow(allvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3391b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a dictionary of the JSONs\n",
    "\n",
    "def getIdentifiers(data):\n",
    "    json_ids = {}\n",
    "    for x in range(len(data[\"dataset\"])):\n",
    "        json_ids[x] = data[\"dataset\"][x][\"identifier\"]\n",
    "    return json_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1908624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the title as: alternativeTitle [place name] {year}\n",
    "\n",
    "def format_title(alternativeTitle, titleSource):\n",
    "    # find if year exist in alternativeTitle\n",
    "    year = ''\n",
    "    try:  \n",
    "      year_range = re.findall(r'(\\d{4})-(\\d{4})', alternativeTitle)\n",
    "    except:\n",
    "      year_range = ''\n",
    "    try: \n",
    "      single_year = re.match(r'.*(17\\d{2}|18\\d{2}|19\\d{2}|20\\d{2})', alternativeTitle)\n",
    "    except:\n",
    "      single_year = ''    \n",
    "    if year_range:   # if a 'yyyy-yyyy' exists\n",
    "        year = '-'.join(year_range[0])\n",
    "        alternativeTitle = alternativeTitle.replace(year, '').strip().rstrip(',')\n",
    "    elif single_year:  # or if a 'yyyy' exists\n",
    "        year = single_year.group(1)\n",
    "        alternativeTitle = alternativeTitle.replace(year, '').strip().rstrip(',')\n",
    "     \n",
    "    altTitle = str(alternativeTitle)\n",
    "    title = altTitle + ' [{}]'.format(titleSource)   \n",
    "    if year:\n",
    "        title += ' {' + year +'}'       \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb10c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a dictionary of selected metadata elements\n",
    "# This includes blank fields '' for some columns\n",
    "\n",
    "def metadataNewItems(newdata, newitem_ids):\n",
    "    newItemDict = {}\n",
    "    # y = position of the dataset in the DCAT metadata json, v = landing page URLs\n",
    "    for y, v in newitem_ids.items():\n",
    "        identifier = v\n",
    "        metadata = []\n",
    "        \n",
    "\n",
    "#ALTERNATIVE TITLE\n",
    "       \n",
    "        alternativeTitle = \"\"\n",
    "        try:\n",
    "            alternativeTitle = cleanData(newdata[\"dataset\"][y]['title'])\n",
    "        except:\n",
    "            alternativeTitle = newdata[\"dataset\"][y]['title']\n",
    "            \n",
    "# TITLE\n",
    "            \n",
    "        # call the format_title function\n",
    "        title = format_title(alternativeTitle, titleSource)\n",
    "            \n",
    "#DESCRIPTION\n",
    "\n",
    "        description = cleanData(newdata[\"dataset\"][y]['description'])\n",
    "        description = description.replace(\"{{default.description}}\", \"\").replace(\"{{description}}\", \"\")\n",
    "        description = re.sub(r'[\\n]+|[\\r\\n]+', ' ', description, flags=re.S)\n",
    "        description = re.sub(r'\\s{2,}', ' ', description)\n",
    "        description = description.translate({8217: \"'\", 8220: '\"', 8221: '\"', 160: \"\", 183: \"\", 8226: \"\", 8211: \"-\", 8203: \"\"})\n",
    "\n",
    "\n",
    "# RESOURCE TYPE\n",
    "\n",
    "        # if 'LiDAR' exists in Title or Description, add it to Resource Type\n",
    "        if 'LiDAR' in title or 'LiDAR' in description:\n",
    "            resourceType = 'LiDAR'\n",
    "                            \n",
    "#CREATOR\n",
    "        creator = newdata[\"dataset\"][y][\"publisher\"]\n",
    "        for pub in creator.values():\n",
    "            try:\n",
    "                creator = pub.replace(u\"\\u2019\", \"'\")\n",
    "            except:\n",
    "                creator = pub\n",
    "\n",
    "\n",
    "# DISTRIBUTION\n",
    "\n",
    "        information = cleanData(newdata[\"dataset\"][y]['landingPage'])\n",
    "\n",
    "        format_types = []\n",
    "        resourceClass = \"\"\n",
    "        formatElement = \"\"\n",
    "        downloadURL = \"\"\n",
    "        resourceType = \"\"\n",
    "        webService = \"\"\n",
    "        featureServer = \"\"\n",
    "        mapServer = \"\"\n",
    "        imageServer = \"\"\n",
    "\n",
    "\n",
    "\n",
    "        distribution = newdata[\"dataset\"][y][\"distribution\"]\n",
    "        for dictionary in distribution:\n",
    "            try:\n",
    "                # If one of the distributions is a shapefile, change genre/format and get the downloadURL\n",
    "                format_types.append(dictionary[\"title\"])\n",
    "                if dictionary[\"title\"] == \"Shapefile\":\n",
    "                    resourceClass = \"Datasets|Web services\"\n",
    "                    formatElement = \"Shapefile\"\n",
    "                    if 'downloadURL' in dictionary.keys():\n",
    "                        downloadURL = dictionary[\"downloadURL\"].split('?')[0]\n",
    "                    else:\n",
    "                        downloadURL = dictionary[\"accessURL\"].split('?')[0]\n",
    "\n",
    "                    resourceType = \"Vector data\"\n",
    "\n",
    "                # If the Rest API is based on an ImageServer, change genre, type, and format to relate to imagery\n",
    "                if dictionary[\"title\"] == \"ArcGIS GeoService\":\n",
    "                    if 'accessURL' in dictionary.keys():\n",
    "                        webService = dictionary['accessURL']\n",
    "\n",
    "                        if webService.rsplit('/', 1)[-1] == 'ImageServer':\n",
    "                            resourceClass = \"Imagery|Web services\"\n",
    "                            formatElement = 'Imagery'\n",
    "                            resourceType = \"Satellite imagery\"\n",
    "                    else:\n",
    "                        resourceClass = \"\"\n",
    "                        formatElement = \"\"\n",
    "                        downloadURL = \"\"\n",
    "\n",
    "            # If the distribution section of the metadata is not structured in a typical way\n",
    "            except:\n",
    "                resourceClass = \"\"\n",
    "                formatElement = \"\"\n",
    "                downloadURL = \"\"\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            if \"FeatureServer\" in webService:\n",
    "                featureServer = webService\n",
    "            if \"MapServer\" in webService:\n",
    "                mapServer = webService\n",
    "            if \"ImageServer\" in webService:\n",
    "                imageServer = webService\n",
    "        except:\n",
    "            print(identifier)\n",
    "\n",
    "\n",
    "\n",
    "# BOUNDING BOX\n",
    "        \n",
    "        bbox = newdata[\"dataset\"][y][\"spatial\"]                \n",
    "    \n",
    "#         try:\n",
    "#             bboxList = []\n",
    "#             bbox = ''\n",
    "#             spatial = cleanData(newdata[\"dataset\"][y]['spatial'])\n",
    "#             typeDmal = decimal.Decimal\n",
    "#             fix4 = typeDmal(\"0.01\")\n",
    "#             for coord in spatial.split(\",\"):\n",
    "#                 coordFix = typeDmal(coord).quantize(fix4)\n",
    "#                 bboxList.append(str(coordFix))\n",
    "#             bbox = ','.join(bboxList)\n",
    "#         except:\n",
    "#             spatial = \"\"\n",
    "            \n",
    "# KEYWORDS\n",
    "\n",
    "        keyword = newdata[\"dataset\"][y][\"keyword\"]\n",
    "        keyword_list = []\n",
    "        keyword_list = '|'.join(keyword).replace(' ', '')\n",
    "\n",
    "        \n",
    "# DATES\n",
    "\n",
    "        dateIssued = cleanData(newdata[\"dataset\"][y]['issued']).split('T', 1)[0] \n",
    "        temporalCoverage = \"\"\n",
    "        dateRange = \"\"\n",
    "\n",
    "        # auto-generate Temporal Coverage and Date Range\n",
    "        if re.search(r\"\\{(.*?)\\}\", title):     # if title has {YYYY} or {YYYY-YYYY}\n",
    "            temporalCoverage = re.search(r\"\\{(.*?)\\}\", title).group(1)\n",
    "            dateRange = temporalCoverage[:4] + '-' + temporalCoverage[-4:]\n",
    "        else:\n",
    "            temporalCoverage = 'Continually updated resource'\n",
    "        \n",
    "#RIGHTS\n",
    "\n",
    "        rights = cleanData(newdata[\"dataset\"][y]['license']) if 'license' in newdata[\"dataset\"][y] else \"\"\n",
    "\n",
    "\n",
    "# IDENTIFIER\n",
    "        slug = identifier.split('=', 1)[-1].replace(\"&sublayer=\", \"_\")\n",
    "        querystring = parse_qs(urlparse(identifier).query)\n",
    "        identifier_new = \"https://hub.arcgis.com/datasets/\" + \"\" + querystring[\"id\"][0]\n",
    "\n",
    "            \n",
    "# Define full metadata list\n",
    "\n",
    "        metadataList = [\n",
    "            title, \n",
    "            alternativeTitle, \n",
    "            description, \n",
    "            language, \n",
    "            creator,\n",
    "            resourceClass, \n",
    "            resourceType, \n",
    "            keyword_list, \n",
    "            dateIssued, \n",
    "            temporalCoverage,\n",
    "            dateRange, \n",
    "            spatialCoverage, \n",
    "            bbox,\n",
    "            formatElement, \n",
    "            information, \n",
    "            downloadURL, \n",
    "            mapServer, \n",
    "            featureServer,\n",
    "            imageServer, \n",
    "            slug, \n",
    "            identifier_new, \n",
    "            provider, \n",
    "            portalCode, \n",
    "            memberOf, \n",
    "            isPartOf, \n",
    "            rights,\n",
    "            accrualMethod,\n",
    "            dateAccessioned, \n",
    "            accessRights\n",
    "        ]     \n",
    "\n",
    "        # deletes items where the resourceClass is empty\n",
    "        for i in range(len(metadataList)):\n",
    "            if metadataList[5] != \"\":\n",
    "                metadata.append(metadataList[i])\n",
    "\n",
    "        newItemDict[slug] = metadata\n",
    "\n",
    "        for k in list(newItemDict.keys()):\n",
    "            if not newItemDict[k]:\n",
    "                del newItemDict[k]\n",
    "\n",
    "    return newItemDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ca9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRecords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908a93c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08b-42003 https://openac-alcogis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04b-24003 https://maps.aacounty.org//api/feed/dcat-us/1.1.json\n",
      "10b-55003 https://data-ashlandcountywi.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "11b-39009 https://data-athgis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04b-24005 https://opendata.baltimorecountymd.gov/api/feed/dcat-us/1.1.json\n",
      "05b-27011 https://data-bigstonecounty.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04b-24009 https://calvert-county-open-data-calvertgis.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55025-01 https://data-carpc.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04b-24013 https://data-carrollco-md.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27019 http://data-carver.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "08b-42027 http://gisdata-centrecountygov.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "08b-42029 https://chester-county-s-gis-hub-chesco.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27023 https://data-chippewa.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "13c-02 https://data-cityofgi.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10c-03 https://data-cityofmadison.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05c-02 https://information.stpaul.gov/api/feed/dcat-us/1.1.json\n",
      "05b-27027 https://data-claycountymn.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "12b-17031 https://hub-cookcountyil.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "08b-42039 https://share-open-data-crawfordcountypa.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "11b-39035 https://data-cuyahoga.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "08b-42043 https://data-dauphinco.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "11b-39041 https://gisdata-delco.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04f-01 https://dvrpc-dvrpcgis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "07c-01 https://data.detroitmi.gov/api/feed/dcat-us/1.1.json\n",
      "10b-55025 https://gis-countyofdane.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "12b-17043 https://gisdata-dupage.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55035-01 https://hub-eccounty.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "01b-18163 https://dev-evansvilleapc.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "11b-39049 https://auditor-fca.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04b-24021 https://gis-fcgmd.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55125-01 https://data-vilas.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "11a-01 https://ogrip-geohio.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27051 https://hub-co-grant-mn-us.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04b-24025 https://harford-county-gis-hub-harfordgis.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27053 https://gis-hennepin.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "1000-0001 https://hudgis-hud.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "09a-04 https://www.indianamap.org/api/feed/dcat-us/1.1.json\n",
      "03a-03 https://geodata.iowa.gov/api/feed/dcat-us/1.1.json\n",
      "03a-02 https://public-iowadot.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55059 https://dataportal.kenoshacounty.org/api/feed/dcat-us/1.1.json\n",
      "12b-17097 https://data-lakecountyil.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55021 https://opendata-cclid.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "13c-01 https://data2-lincolnne.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "03b-19113 http://opendata-linncounty-gis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "11b-39093 https://data-loraingis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04a-01 http://data.imap.maryland.gov/api/feed/dcat-us/1.1.json\n",
      "02b-17113 http://www.mcgis.org//api/feed/dcat-us/1.1.json\n",
      "06a-02 https://gis-midnr.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55079 https://gis-mclio.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "08b-42091 https://data-montcopa.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "13a-04 https://data-outdoornebraska.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "13a-01 https://www.nebraskamap.gov/api/feed/dcat-us/1.1.json\n",
      "14a-02 https://gisdata-njdep.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "14a-01 https://njogis-newjersey.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "06b-26125 http://accessoakland.oakgov.com/api/feed/dcat-us/1.1.json\n",
      "13b-31055 https://data-dogis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "04c-01 https://opendata.dc.gov/api/feed/dcat-us/1.1.json\n",
      "05c-01 https://opendata.minneapolismn.gov/api/feed/dcat-us/1.1.json\n",
      "01c-02 http://data.indy.gov/api/feed/dcat-us/1.1.json\n",
      "12c-02 https://opioid-awareness-peoriacountygis.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55087 https://data-ocgis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "08a-02 https://newdata-dcnr.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "12b-17143 https://data-peoriacountygis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "08c-01-2 http://data-phl.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55093 https://data-piercecounty-wi.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27119 https://hub-pcg.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27121 https://hub-popecounty.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55101 http://data.racinecounty.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27123 https://data-ramseygis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27129 https://hub-renvilleco.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27137 https://open-data-slcgis.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "13b-31153 https://data2-sarpy.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55111 https://data-saukgis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "06f-01 http://maps-semcog.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "09c-01 http://data-southbend.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55109 https://gis-scccdd.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "11b-39151 http://opendata.starkcountyohio.gov/api/feed/dcat-us/1.1.json\n",
      "06a-01 http://gis-michigan.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27145 https://stearns-county-gis-stearns.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "11b-39153 https://data-summitgis.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "07d-02 https://mbgna-umich.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "12d-03 http://library-uchicago.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "07b-26161 https://data-washtenaw.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55133 https://data-waukeshacounty.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55135 https://data2017-04-05t135915451z-waupacacounty.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55137 https://data-waushara.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27167 https://hub-wilkinco.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10c-04 https://rapidsdata-wisconsinrapids.opendata.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "10b-55141 https://opendata.woodcogis.com/api/feed/dcat-us/1.1.json\n",
      "05b-27173 https://hub-yellowmedicine.hub.arcgis.com/api/feed/dcat-us/1.1.json\n",
      "08b-42133 https://york-county-pa-gis-portal-yorkcountypa.hub.arcgis.com/api/feed/dcat-us/1.1.json\n"
     ]
    }
   ],
   "source": [
    "with open(portalFile, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # Read in values from arcPortals.csv to be used within the script or as part of the metadata report\n",
    "        portalCode = row['ID']\n",
    "        url = row['Identifier']\n",
    "        provider = row['Title']\n",
    "        titleSource = row['Publisher']\n",
    "        spatialCoverage = row['Spatial Coverage']\n",
    "        isPartOf = row['ID']\n",
    "        memberOf = row['Member Of']\n",
    "        accrualMethod = \"ArcGIS Hub\"\n",
    "        dateAccessioned = time.strftime('%Y-%m-%d')\n",
    "        accessRights = \"Public\"\n",
    "        language = \"eng\"\n",
    "\n",
    "        print(portalCode, url)\n",
    "        \n",
    "        \n",
    "        response = urllib.request.urlopen(url)\n",
    "        # check if data portal URL is broken\n",
    "        if response.headers['content-type'] != 'application/json; charset=utf-8':\n",
    "            print(\"\\n--------------------- Data portal URL does not exist --------------------\\n\",\n",
    "                  portalCode, url,  \"\\n--------------------------------------------------------------------------\\n\")\n",
    "            continue\n",
    "        else:\n",
    "            newdata = json.load(response)\n",
    "\n",
    "\n",
    "        # Makes a list of dataset identifiers\n",
    "        newjson_ids = getIdentifiers(newdata)\n",
    "\n",
    "        allRecords.append(metadataNewItems(newdata, newjson_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d787b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "newItemsReport = f\"{directory}/{ActionDate}_scannedRecords.csv\"\n",
    "printItemReport(newItemsReport, fieldnames, allRecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8959e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reopen the new CSV and drop duplicate items with the same ID\n",
    "\n",
    "df_newitems = pd.read_csv(newItemsReport)\n",
    "df_finalItems = df_newitems.drop_duplicates(subset=['ID'])\n",
    "df_finalItems.to_csv(newItemsReport, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07c00a",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "The Hub sites are fairly unstable and it is likely that one or more of them will fail and interrupt the script. Check and see if the site is down, moved, etc. Make any updates to GEOMG directly. For tracking problems, the Status field in GEOMG is plain text and can be used for admin notes.\n",
    "\n",
    "- If a site is missing, Unpublish it from GEOMG and indicate the Date Retired, and make a note in the Status field.  \n",
    "- If a site just isn't working, Remove the value \"DCAT US 1.1\" from the Accrual Method field and make a note in the Status field.\n",
    "\n",
    "Edit the arcPortals.csv (or re-download it) and keep running this Notebook until it works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911c45c",
   "metadata": {},
   "source": [
    "## How to upload to GEOMG\n",
    "\n",
    "### Review the previous upload\n",
    "\n",
    "1. Check the Date Accessioned field of the last harvest and copy it. \n",
    "\n",
    "\n",
    "### Upload everything that you just harvested.\n",
    "\n",
    "2. Upload the new CSV file. This will overwrite the Date Accessioned value for any items that were already present.\n",
    "\n",
    "### Delete items that were retired from ArcGIS Hubs\n",
    "3. Use the old Date Accessioned value to search for the previous harvest date. This example uses 2023-03-07: (https://geomg.lib.umn.edu/documents?f%5Bb1g_dct_accrualMethod_s%5D%5B%5D=ArcGIS+Hub&q=%222023-03-07%22&rows=20&sort=score+desc)\n",
    "4. Unpublished the ones that have the old date in the Date Accessioned field - record this number in the ticket under Number Deleted\n",
    "\n",
    "### Publish items that are new as of the latest harvest\n",
    "5. Look for records in the uploaded batch that are still \"Draft\" - these are new records. \n",
    "6. Publish them and record this number in the GitHub issue ticked under Number Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600d533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
