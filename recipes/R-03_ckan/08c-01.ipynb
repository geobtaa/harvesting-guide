{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This script will scan the DCAT API for the OpenDataPhilly data portal and return the metadata for all items as a CSV file in the GeoBTAA Metadata Application Profile. It will also create a secondary CSV file for the associated multiple downloads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and declare file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "# Third-party libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# auto-generate the current time in 'YYYYMM' format\n",
    "action_date = time.strftime('%Y%m%d')\n",
    "csv_file = action_date + \"_08c-01-metadata.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the JSONs and merge them into a single pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "# URLs of the APIs\n",
    "url1 = \"https://opendataphilly.org/datasets.json\"\n",
    "url2 = \"https://opendataphilly.org/data.json\"\n",
    "\n",
    "# Downloading JSON data\n",
    "response1 = requests.get(url1)\n",
    "data1 = response1.json()\n",
    "\n",
    "response2 = requests.get(url2)\n",
    "data2 = response2.json()\n",
    "\n",
    "# Load JSONs into pandas dataframes\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2['dataset'])  # Here's where we're targeting the \"dataset\" key\n",
    "\n",
    "# Merge dataframes by matching the titles\n",
    "merged_df = pd.merge(df1, df2, on='title', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to keep and their new names\n",
    "columns_to_keep_and_rename = {\n",
    "    \"title\": \"Alternative Title\",\n",
    "    \"organization\": \"Creator\",\n",
    "    \"description\": \"Description\",\n",
    "    \"category_x\": \"Keyword\",\n",
    "    \"url\": \"url\",\n",
    "    \"license\": \"Rights\",\n",
    "    \"distribution\": \"distribution\"\n",
    "}\n",
    "\n",
    "# Select and rename the specified columns\n",
    "df = merged_df[list(columns_to_keep_and_rename.keys())].rename(columns=columns_to_keep_and_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the distribution arrays\n",
    "\n",
    "There are many datasets in this portal that have dozens of links with various types of formats listed in the distribution section. Since this array is fairly heterogeneous, we are only going to pull records that have Shapefile downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional section: This code gives you an idea of how many links and formats there are\n",
    "\n",
    "# # Create a new column that counts the number of items in the 'distribution' column\n",
    "# df['distribution_count'] = df['distribution'].apply(lambda x: len(x))\n",
    "\n",
    "# # Initialize a dictionary to count the different formats\n",
    "# format_counts = {}\n",
    "\n",
    "# # Iterate through the 'distribution' column to collect formats\n",
    "# for distribution in df['distribution']:\n",
    "#     for item in distribution:\n",
    "#         format_type = item['format']\n",
    "#         format_counts[format_type] = format_counts.get(format_type, 0) + 1\n",
    "\n",
    "# # Summary of distribution counts\n",
    "# distribution_summary = df['distribution_count'].describe()\n",
    "# print(\"Distribution count summary:\")\n",
    "# print(distribution_summary)\n",
    "\n",
    "# # Summary of format counts\n",
    "# print(\"\\nFormat counts:\")\n",
    "# for format_type, count in format_counts.items():\n",
    "#     print(f\"{format_type}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the 'distribution' column\n",
    "def process_distribution(row):\n",
    "    for item in row['distribution']:\n",
    "        if item['format'] == \"SHP\":\n",
    "            download_url = item['downloadURL']\n",
    "            # Downloads from phl.carto.com are not working, so we will drop them\n",
    "            if not download_url.startswith(\"https://phl.carto.com\"):\n",
    "                row['Download'] = download_url\n",
    "                row['Format'] = \"Shapefile\"\n",
    "                break\n",
    "    return row\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df = df.apply(process_distribution, axis=1)\n",
    "\n",
    "# Drop rows without valid Shapefiles\n",
    "df.dropna(subset=['Download'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the 'url' value to create landing page, Identifier and ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Information'] = \"https://opendataphilly.org/\" + df['url']\n",
    "df['Identifier'] = df['url'].str.replace('/datasets/', '')  # Remove the beginning \"/datasets/\"\n",
    "df['Identifier'] = df['Identifier'].str.rstrip('/')  # Remove the trailing \"/\"\n",
    "df['ID'] = \"opendataphilly_\" + df['Identifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the creator is Philadelphia, reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Creator'] = df['Creator'].replace(\"City of Philadelphia\", \"Pennsylvania--Philadelphia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a date from the title if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function uses regular expressions to extract the year from the alternative title, and replaces it with an empty string to remove it from the title.\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_year(row):\n",
    "    alternative_title = row.get('Alternative Title', '')\n",
    "    match = re.search(r'\\b\\d{4}\\b', alternative_title)  # Looks for a 4-digit number\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None\n",
    "\n",
    "# Applying the function to the DataFrame\n",
    "df['Temporal Coverage'] = df.apply(extract_year, axis=1)\n",
    "df['Date Range'] = df['Temporal Coverage'] + \"-\" + df['Temporal Coverage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse keywords and add values to Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predefined list of terms\n",
    "predefined_terms = [\n",
    "    'Boundaries',\n",
    "    'Economy',\n",
    "    'Environment',\n",
    "    'Transportation'\n",
    "]\n",
    "\n",
    "# Function to process the 'tags' column\n",
    "def process_tags(row):\n",
    "    tags = row['Keyword']\n",
    "    theme_values = []\n",
    "\n",
    "    for tag in tags:\n",
    "        if tag in predefined_terms:\n",
    "            theme_values.append(tag)\n",
    "        if \"Zoning\" in tag or \"Land Records\" in tag or \"Real Estate\" in tag:\n",
    "            theme_values.append(\"Property\")\n",
    "        if \"Health\" in tag:\n",
    "            theme_values.append(\"Health\")\n",
    "        if \"Arts\" in tag:\n",
    "            theme_values.append(\"Society\")\n",
    "        if \"Budget\" in tag:\n",
    "            theme_values.append(\"Economy\")\n",
    "        if \"Education\" in tag:\n",
    "            theme_values.append(\"Society\")\n",
    "        if \"Elections\" in tag:\n",
    "            theme_values.append(\"Society|Events\")\n",
    "\n",
    "    row['Theme'] = '|'.join(theme_values)\n",
    "    # Keep the original 'tags' value\n",
    "    row['Keyword'] = '|'.join(tags)\n",
    "    return row\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df = df.apply(process_tags, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add default and constructed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Alternative Title'] + \" [Pennsylvania--Philadelphia]\"\n",
    "df['Resource Class'] = \"Datasets\"\n",
    "df['Date Accessioned'] = action_date\n",
    "df['Spatial Coverage'] = \"Pennsylvania--Pennsylvania\"\n",
    "df['Code'] = \"08c-01\"\n",
    "df['Is Part Of'] = \"08c-01\"\n",
    "df['Member Of'] = \"ba5cc745-21c5-4ae9-954b-72dd8db6815a\"\n",
    "df['Accrual Method'] = \"JKAN\"\n",
    "df['Access Rights'] = \"Public\"\n",
    "df['Language'] = \"eng\"\n",
    "df['Provider'] = \"OpenDataPhilly\"\n",
    "df['Bounding Box'] = \"-75.280298,39.867005,-74.955833,40.137959\"\n",
    "df['Display Note'] = \"Tip: This dataset was automatically cataloged from the OpenDataPhilly data portal. Click the View Source button to see more formats and layers associated with this record.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired order of columns\n",
    "desired_order = [\n",
    "'Title',\n",
    "'Alternative Title',\n",
    "'Description',\n",
    "'Language',\n",
    "'Display Note',\n",
    "'Creator',\n",
    "'Provider',\n",
    "'Resource Class',\n",
    "'Theme',\n",
    "'Temporal Coverage',\n",
    "'Date Range',\n",
    "'Spatial Coverage',\n",
    "'Bounding Box',\n",
    "'Member Of',\n",
    "'Is Part Of',\n",
    "'Format',\n",
    "'Information',\n",
    "'Download',\n",
    "'ID',\n",
    "'Identifier',\n",
    "'Rights',\n",
    "'Access Rights',\n",
    "'Date Accessioned',\n",
    "'Code',\n",
    "'Accrual Method'\n",
    "]\n",
    "\n",
    "# Reindex the DataFrame based on the desired order of columns\n",
    "df = df.reindex(columns=desired_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_file, quoting=csv.QUOTE_NONNUMERIC, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply .str.strip() method to all string columns in the DataFrame and replace newline and tab characters\n",
    "# df = df.apply(lambda x: x.str.replace('\\n', ' ').str.replace('\\t', ' ').str.replace('<br/>', ' ').str.replace('<br/><br/>', '|').str.strip() if x.dtype == \"object\" else x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
