{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edaebb0",
   "metadata": {},
   "source": [
    "## Transform a batch OpenGeoMetadata JSON files\n",
    "\n",
    "**Purpose: This script will read a batch of GeoBlacklight metadata JSON files in the OGM Aardvark schema and tranform them into a single CSV.** \n",
    "\n",
    "Metadata records in the [OGM Aardvark](https://opengeometadata.org/docs/aardvark) schema are frequently shared as batches of JSON files. The entire [OpenGeoMetadata organization](https://github.com/OpenGeoMetadata) contains repositories full of hundreds of thousands of GeoBlacklight JSONs.\n",
    "\n",
    "In order to ingest these into the BTAA Geoportal, we need to transform them into a CSV.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b91c0",
   "metadata": {},
   "source": [
    "## Part 1: Load the modules and JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a33c67",
   "metadata": {},
   "source": [
    "### Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf654768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8083b1",
   "metadata": {},
   "source": [
    "### Declare the paths and file names\n",
    "\n",
    "First, move a folder of the JSONs into this directory. Files in the folder can be nested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042cb274",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = r\"solr\" # enter the name of the folder\n",
    "csv_name = \"fixtures\" # create a name for the output CSV without the .csv extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e4301",
   "metadata": {},
   "source": [
    "### Load the files into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7454688",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [] # empty list\n",
    "\n",
    "# through all items, format and append to dataset list\n",
    "for path, dir, files in os.walk(json_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            json_file_open = open(file_path, 'rb')\n",
    "            data = json_file_open.read().decode('utf-8', errors='ignore')\n",
    "            loaded = json.loads(data)\n",
    "            dataset.append(loaded)\n",
    "            \n",
    "df = pd.DataFrame(dataset) # convert dataset into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e04a8f",
   "metadata": {},
   "source": [
    "## Part 2: Split multivalued and compound fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b57ef",
   "metadata": {},
   "source": [
    "### Split multivalued fields (arrays)\n",
    "\n",
    "This will remove the punctuation from fields that are formatted as arrays and separate them with pipes ('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9dc6575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column dct_license_sm not found in DataFrame.\n",
      "Column dct_rightsHolder_sm not found in DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Function to join array elements into a pipe-separated string\n",
    "def join_multivalues(val):\n",
    "    if isinstance(val, list):\n",
    "        return '|'.join(map(str, val))\n",
    "    return val\n",
    "\n",
    "# Apply the function to each column that needs processing\n",
    "multivalue_columns = [\n",
    "    'dcat_keyword_sm', 'dcat_theme_sm', 'dct_subject_sm', 'dct_creator_sm',\n",
    "    'dct_publisher_sm', 'dct_alternative_sm', 'dct_description_sm',\n",
    "    'dct_language_sm', 'dct_identifier_sm', 'dct_isPartOf_sm', \n",
    "    'dct_isReplacedBy_sm', 'dct_isVersionOf_sm', 'dct_relation_sm',\n",
    "    'dct_replaces_sm', 'dct_source_sm', 'dct_license_sm', 'dct_rights_sm',\n",
    "    'dct_rightsHolder_sm', 'dct_spatial_sm', 'dct_temporal_sm',\n",
    "    'gbl_resourceClass_sm', 'gbl_resourceType_sm', 'gbl_displayNote_sm',\n",
    "    'pcdm_memberOf_sm', 'gbl_indexYear_im'\n",
    "]\n",
    "\n",
    "for column in multivalue_columns:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].apply(join_multivalues)\n",
    "    else:\n",
    "        print(f\"Column {column} not found in DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ddc29d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dct_title_s', 'dct_alternative_sm', 'dct_description_sm',\n",
      "       'dct_language_sm', 'dct_publisher_sm', 'schema_provider_s',\n",
      "       'gbl_resourceClass_sm', 'gbl_resourceType_sm', 'dct_subject_sm',\n",
      "       'dcat_theme_sm', 'dcat_keyword_sm', 'dct_temporal_sm', 'dct_issued_s',\n",
      "       'gbl_indexYear_im', 'gbl_dateRange_drsim', 'dct_spatial_sm',\n",
      "       'locn_geometry', 'dcat_bbox', 'dcat_centroid', 'dct_accessRights_s',\n",
      "       'dct_format_s', 'gbl_wxsIdentifier_s', 'dct_references_s', 'id',\n",
      "       'dct_identifier_sm', 'gbl_mdModified_dt', 'gbl_mdVersion_s',\n",
      "       'dct_creator_sm', 'pcdm_memberOf_sm', 'dct_isPartOf_sm',\n",
      "       'dct_source_sm', 'dct_isReplacedBy_sm', 'dct_isVersionOf_sm',\n",
      "       'dct_relation_sm', 'dct_replaces_sm', 'gbl_georeferenced_b',\n",
      "       'gbl_suppressed_b', 'dct_rights_sm', 'gbl_fileSize_s',\n",
      "       'layer_geom_type_s', 'gbl_displayNote_sm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c5d3b",
   "metadata": {},
   "source": [
    "### Split the References into separate columns\n",
    "\n",
    "This step makes it easier to edit individual links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c79f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def extract_values(row):\n",
    "    # Check if the value is a string; otherwise, return None or an empty dict\n",
    "    if isinstance(row['dct_references_s'], str):\n",
    "        try:\n",
    "            dct_references_s = json.loads(row['dct_references_s'].replace('\"\"', '\"'))\n",
    "            return dct_references_s\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON decode error in row: {row}\")\n",
    "            return {}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "# Apply the function to split the column and expand into separate columns\n",
    "df_expanded = df.apply(extract_values, axis=1).apply(pd.Series)\n",
    "\n",
    "# Concatenate the original DataFrame with the expanded DataFrame\n",
    "df = pd.concat([df, df_expanded], axis=1)\n",
    "\n",
    "# Rename columns based on keys in the JSON\n",
    "column_mapping = {\n",
    "    'http://schema.org/downloadUrl': 'Download',\n",
    "    'http://schema.org/url': 'Information',\n",
    "    'http://www.isotc211.org/schemas/2005/gmd/': 'ISO19139',\n",
    "    'http://www.opengis.net/cat/csw/csdgm': 'FGDC',\n",
    "    'http://www.w3.org/1999/xhtml': 'HTML',\n",
    "    'http://lccn.loc.gov/sh85035852': 'Documentation',\n",
    "    'http://iiif.io/api/image': 'IIIF',\n",
    "    'http://iiif.io/api/presentation#manifest': 'Manifest',\n",
    "    'http://www.loc.gov/mods/v3': 'MODS',\n",
    "    'https://openindexmaps.org': 'Index Map',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wms': 'WMS',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wfs': 'WFS',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wcs': 'WCS',\n",
    "    'urn:x-esri:serviceType:ArcGIS#FeatureLayer': 'FeatureServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#TiledMapLayer': 'TileServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#DynamicMapLayer': 'MapServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#ImageMapLayer': 'ImageServer',\n",
    "    'http://schema.org/DownloadAction': 'Harvard Download',\n",
    "    'https://github.com/cogeotiff/cog-spec': 'COG',\n",
    "    'https://github.com/protomaps/PMTiles': 'PMTiles',\n",
    "    'https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames': 'XYZ Tiles',\n",
    "    'http://schema.org/thumbnailUrl': 'B1G Image',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wmts': 'WMTS',\n",
    "    'https://oembed.com': 'oembed',\n",
    "    'https://github.com/mapbox/tilejson-spec': 'TileJSON',\n",
    "    'https://wiki.osgeo.org/wiki/Tile_Map_Service_Specification': 'Tile Map Service'\n",
    "    }\n",
    "df.rename(columns=column_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de4050",
   "metadata": {},
   "source": [
    "### Reorder coordinates\n",
    "\n",
    "This will reorder the 4 bbox coordinates into W,S,E,N, which is what the Klokan Bounding Box tool produces on the CSV export option. The BTAA metadata editor uses this order as well when ingesting items. However, Aardvark ultimately uses W,E,N,S, so these would need to be reordered before converting back to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc821630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the 'dcat_bbox' column is a string and handle missing or incorrect formats\n",
    "if 'dcat_bbox' in df.columns:\n",
    "    # Strip 'ENVELOPE()' and split, ensuring all entries are treated as strings\n",
    "    df[['w', 'e', 'n', 's']] = df['dcat_bbox'].apply(\n",
    "        lambda x: x.strip('ENVELOPE()').split(',') if isinstance(x, str) and 'ENVELOPE(' in x and ')' in x else [None, None, None, None]\n",
    "    ).tolist()\n",
    "\n",
    "    # Ensure all elements are strings for the join operation\n",
    "    df['Bounding Box'] = df[['w', 's', 'e', 'n']].apply(\n",
    "        lambda row: ','.join(str(item) for item in row if item is not None),\n",
    "        axis=1\n",
    "    )\n",
    "else:\n",
    "    print(\"Column 'dcat_bbox' is missing from the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e084b1",
   "metadata": {},
   "source": [
    "## Part 4: Export to a new CSV with Aardvark labels as headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06042ee7",
   "metadata": {},
   "source": [
    "### Rename the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c8d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping of old field names to new labels\n",
    "column_mapping = {\n",
    "    'dcat_keyword_sm': 'Keyword',\n",
    "    'dcat_theme_sm': 'Theme',\n",
    "    'dcat_centroid': 'Centroid',\n",
    "    'dct_subject_sm': 'Subject',\n",
    "    'dct_creator_sm': 'Creator',\n",
    "    'dct_publisher_sm': 'Publisher',\n",
    "    'dct_alternative_sm': 'Alternative Title',\n",
    "    'dct_description_sm': 'Description',\n",
    "    'dct_language_sm': 'Language',\n",
    "    'dct_title_s': 'Title',\n",
    "    'dct_identifier_sm': 'Identifier',\n",
    "    'dct_format_s': 'Format',\n",
    "    'dct_isPartOf_sm': 'Is Part Of',\n",
    "    'dct_isReplacedBy_sm': 'Is Replaced By',\n",
    "    'dct_isVersionOf_sm': 'Is Version Of',\n",
    "    'dct_relation_sm': 'Relation',\n",
    "    'dct_replaces_sm': 'Replaces',\n",
    "    'dct_source_sm': 'Source',\n",
    "    'dct_accessRights_s': 'Access Rights',\n",
    "    'dct_license_sm': 'License',\n",
    "    'dct_rights_sm': 'Rights',\n",
    "    'dct_rightsHolder_sm': 'Rights Holder',\n",
    "    'dct_spatial_sm': 'Spatial Coverage',\n",
    "    'dct_issued_s': 'Date Issued',\n",
    "    'dct_temporal_sm': 'Temporal Coverage',\n",
    "    'gbl_mdVersion_s': 'Metadata Version',\n",
    "    'gbl_mdModified_dt': 'Modified',\n",
    "    'gbl_suppressed_b': 'Suppressed',\n",
    "    'gbl_resourceClass_sm': 'Resource Class',\n",
    "    'gbl_resourceType_sm': 'Resource Type',\n",
    "    'gbl_displayNote_sm': 'Display Note',\n",
    "    'id': 'ID',\n",
    "    'gbl_wxsIdentifier_s': 'WxS Identifier',\n",
    "    'gbl_fileSize_s': 'File Size',\n",
    "    'gbl_georeferenced_b': 'Georeferenced',\n",
    "    'gbl_dateRange_drsim': 'Date Range',\n",
    "    'gbl_indexYear_im': 'Index Year',\n",
    "    'locn_geometry': 'Geometry',\n",
    "    'pcdm_memberOf_sm': 'Member Of',\n",
    "    'schema_provider_s': 'Provider'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487bcf0",
   "metadata": {},
   "source": [
    "### Check for multiple downloads and create a secondary CSV called \"multiple-downloads.csv\"\n",
    "\n",
    "See https://geobtaa.github.io/metadata/recipes/secondary-tables/ for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25826b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the value is an array\n",
    "def is_array_type(value):\n",
    "    return isinstance(value, list)\n",
    "\n",
    "# Function to extract the download information and write to \"multiple-downloads.csv\"\n",
    "def extract_downloads(row):\n",
    "    friendlier_id = row[\"ID\"]\n",
    "    downloads = row[\"Download\"]\n",
    "    extracted_downloads = []\n",
    "    if is_array_type(downloads):\n",
    "        for download in downloads:\n",
    "            if isinstance(download, dict):\n",
    "                label = download.get(\"label\", \"\")\n",
    "                value = download.get(\"url\", \"\")\n",
    "                extracted_downloads.append({\"friendlier_id\": friendlier_id, \"label\": label, \"value\": value})\n",
    "\n",
    "    return extracted_downloads\n",
    "\n",
    "# Apply the function to each row in the DataFrame where \"Download\" is an array\n",
    "download_list = df[df[\"Download\"].apply(is_array_type)].apply(extract_downloads, axis=1).explode().tolist()\n",
    "\n",
    "# Write the extracted downloads to \"multiple-downloads.csv\"\n",
    "with open(\"multiple-downloads.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"friendlier_id\", \"label\", \"value\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(download_list)\n",
    "\n",
    "# Update the \"Download\" column in the main DataFrame (df) to remove array-type values\n",
    "df[\"Download\"] = df[\"Download\"].apply(lambda x: x[0][\"url\"] if is_array_type(x) else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38345bf",
   "metadata": {},
   "source": [
    "### Write the DataFrame to a CSV file with Aardvark labels\n",
    "\n",
    "This can be uploaded to GBL Admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5842da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"{}.csv\".format(csv_name), index=False, na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efb18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
