{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edaebb0",
   "metadata": {},
   "source": [
    "## Transform a batch OpenGeoMetadata JSON files\n",
    "\n",
    "**Purpose: This script will read a batch of GeoBlacklight metadata JSON files and tranform them into a single CSV.** \n",
    "\n",
    "Metadata records in the [GeoBlacklight](https://opengeometadata.org/docs/gbl-1.0) or [OpenGeoMetadata](https://opengeometadata.org/docs/ogm-aardvark) standards are frequently shared as batches of JSON files. The entire [OpenGeoMetadata organization](https://github.com/OpenGeoMetadata) contains repositories full of hundreds of thousands of GeoBlacklight JSONs.\n",
    "\n",
    "In order to ingest these into the BTAA Geoportal, we need to transform them into a CSV.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a33c67",
   "metadata": {},
   "source": [
    "## 1. Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf654768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8083b1",
   "metadata": {},
   "source": [
    "## 2. Declare the paths and file names\n",
    "\n",
    "Put a folder of the JSONs into this directory. They can be nested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042cb274",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = r\"princeton\" # enter the name of the folder\n",
    "csv_name = \"princeton\" # create a name for the output CSV without the .csv extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e4301",
   "metadata": {},
   "source": [
    "## 3. Load the files into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7454688",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [] # empty list\n",
    "\n",
    "# through all items, format and append to dataset list\n",
    "for path, dir, files in os.walk(json_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            json_file_open = open(file_path, 'rb')\n",
    "            data = json_file_open.read().decode('utf-8', errors='ignore')\n",
    "            loaded = json.loads(data)\n",
    "            dataset.append(loaded)\n",
    "            \n",
    "df = pd.DataFrame(dataset) # convert dataset into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b57ef",
   "metadata": {},
   "source": [
    "## 4. Edit the values of various fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9dc6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the first value of a multivalued cell;this removes the []\n",
    "# df['dc_creator_sm']=df['dc_creator_sm'].str[0]\n",
    "# df['dc_subject_sm']=df['dc_subject_sm'].str[0]\n",
    "\n",
    "df['dc_creator_sm']=df['dc_creator_sm'].str.join('|')\n",
    "df['dc_subject_sm']=df['dc_subject_sm'].str.join('|')\n",
    "df['dct_spatial_sm']=df['dct_spatial_sm'].str.join('|')\n",
    "\n",
    "\n",
    "\n",
    "# remove brackets from Temporal Coverage which is a mix of single values and lists\n",
    "# .str.join('') takes each item, whether a list or a single character, and joins them with a pipe\n",
    "df['dct_temporal_sm']=df['dct_temporal_sm'].str.join('|')\n",
    "\n",
    "# Split solr_geom coordinates and reorder from WENS to WSEN\n",
    "df[['w', 'e','n','s']] = df['solr_geom'].str.strip('ENVELOPE()').str.split(',', expand=True)\n",
    "df['Bounding Box'] = df[['w', 's','e','n']].agg(','.join, axis=1) \n",
    "\n",
    "#Convert Data Type to Resource Class value\n",
    "# df['Resource Class'] = df['dc_type_s'].apply(lambda x: 'Datasets' if x == 'Dataset' else '')\n",
    "\n",
    "#Convert Geometry Type to Resource Type value\n",
    "df['Resource Type'] = df['layer_geom_type_s'].astype(str) + ' data'\n",
    "\n",
    "# Create Date Range field\n",
    "df['Date Range'] = df['dct_temporal_sm'].astype(str) +'-' + df['dct_temporal_sm'].astype(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c5d3b",
   "metadata": {},
   "source": [
    "## 5. Split the References into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb81ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(row):\n",
    "    dct_references_s = json.loads(row['dct_references_s'].replace('\"\"', '\"'))\n",
    "    return dct_references_s\n",
    "\n",
    "# Apply the function to split the column and expand into separate columns\n",
    "df = pd.concat([df, df.apply(extract_values, axis=1).apply(pd.Series)], axis=1)\n",
    "\n",
    "# Rename columns based on keys in the JSON\n",
    "df = df.rename(columns={\n",
    "    'http://schema.org/downloadUrl': 'Download',\n",
    "    'http://schema.org/url': 'Information',\n",
    "    'http://www.isotc211.org/schemas/2005/gmd/': 'ISO19139',\n",
    "    'http://www.opengis.net/cat/csw/csdgm': 'FGDC',\n",
    "    'http://www.w3.org/1999/xhtml': 'HTML',\n",
    "    'http://lccn.loc.gov/sh85035852': 'Documentation',\n",
    "    'http://iiif.io/api/image': 'IIIF',\n",
    "    'http://iiif.io/api/presentation#manifest': 'Manifest',\n",
    "    'http://www.loc.gov/mods/v3': 'MODS',\n",
    "    'https://openindexmaps.org': 'Index Map',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wms': 'WMS',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wfs': 'WFS',\n",
    "    'urn:x-esri:serviceType:ArcGIS#FeatureLayer': 'FeatureServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#TiledMapLayer': 'TileServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#DynamicMapLayer': 'MapServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#ImageMapLayer': 'ImageServer',\n",
    "    'http://schema.org/DownloadAction': 'Harvard Download'\n",
    "    # Add more key-value pairs for renaming columns as needed\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c3958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3080a2f7",
   "metadata": {},
   "source": [
    "## 6. Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c55c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\n",
    "    'geoblacklight_version',\n",
    "    'layer_modified_dt', \n",
    "#     'thumbnail_path_ss',\n",
    "    'w','e','n','s', \n",
    "    'layer_id_s',\n",
    "    'solr_year_i',\n",
    "    'layer_geom_type_s',\n",
    "    'solr_geom',\n",
    "    'dct_references_s'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06042ee7",
   "metadata": {},
   "source": [
    "## 7. Rename  columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c8d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'dc_title_s': 'Title', \n",
    "    'dc_description_s': 'Description',\n",
    "    'dc_creator_sm': 'Creator',\n",
    "    'dct_issued_s': 'Date Issued',\n",
    "    'dc_rights_s' : 'Access Rights',\n",
    "    'dc_format_s': 'Format',\n",
    "    'layer_slug_s' : 'ID',\n",
    "    'dc_identifier_s' : 'Identifier',\n",
    "    'dc_language_s' : 'Language',\n",
    "    'dct_provenance_s' : 'Provider',\n",
    "    'dc_publisher_s' : 'Publisher',\n",
    "    'dc_publisher_sm' : 'Publisher',\n",
    "    'dc_source_sm' : 'Source',\n",
    "    'dct_spatial_sm' : 'Spatial Coverage',\n",
    "    'dc_subject_sm' : 'Subject',\n",
    "    'dct_temporal_sm' : 'Temporal Coverage',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca95d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_rows = []\n",
    "# for index, row in df.iterrows():\n",
    "#     dct_isPartOf_sm = row['dct_isPartOf_sm']\n",
    "#     if pd.notna(dct_isPartOf_sm):\n",
    "#         if isinstance(dct_isPartOf_sm, str):\n",
    "#             title = dct_isPartOf_sm.strip()\n",
    "#             new_id = str(uuid.uuid4())  # Generating a new UUID as the ID for the collection\n",
    "#             new_row = {\n",
    "#                 'Title': title,\n",
    "#                 'ID': new_id,\n",
    "#                 'Resource Class': 'Collections'\n",
    "#             }\n",
    "#             new_rows.append(new_row)\n",
    "#         elif isinstance(dct_isPartOf_sm, list):\n",
    "#             for title in dct_isPartOf_sm:\n",
    "#                 title = title.strip()\n",
    "#                 new_id = str(uuid.uuid4())  # Generating a new UUID as the ID for each collection\n",
    "#                 new_row = {\n",
    "#                     'Title': title,\n",
    "#                     'ID': new_id,\n",
    "#                     'Resource Class': 'Collections'\n",
    "#                 }\n",
    "#                 new_rows.append(new_row)\n",
    "\n",
    "# # Append the new rows to the DataFrame\n",
    "# df = df.append(new_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487bcf0",
   "metadata": {},
   "source": [
    "## 8. Write to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5842da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "df.to_csv(\"{}.csv\".format(csv_name),index=False, na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53211780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
