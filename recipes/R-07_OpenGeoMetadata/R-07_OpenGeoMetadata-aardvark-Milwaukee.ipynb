{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edaebb0",
   "metadata": {},
   "source": [
    "## Transform a batch OpenGeoMetadata JSON files\n",
    "\n",
    "Customized for UW Milwaukee\n",
    "\n",
    "**Purpose: This script will read a batch of GeoBlacklight metadata JSON files in the OGM Aardvark schema and tranform them into a single CSV.** \n",
    "\n",
    "Metadata records in the [OGM Aardvark](https://opengeometadata.org/docs/aardvark) schema are frequently shared as batches of JSON files. The entire [OpenGeoMetadata organization](https://github.com/OpenGeoMetadata) contains repositories full of hundreds of thousands of GeoBlacklight JSONs.\n",
    "\n",
    "In order to ingest these into the BTAA Geoportal, we need to transform them into a CSV.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1a199",
   "metadata": {},
   "source": [
    "To do:\n",
    "- fix title formatting script to account for more place name values, including just states\n",
    "- fix the locations.json loading to be able to do it at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b91c0",
   "metadata": {},
   "source": [
    "## Part 1: Load the modules and JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a33c67",
   "metadata": {},
   "source": [
    "### Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf654768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8083b1",
   "metadata": {},
   "source": [
    "### Declare the paths and file names\n",
    "\n",
    "First, move a folder of the JSONs into this directory. Files in the folder can be nested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042cb274",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = r\"uwm\" # enter the name of the folder\n",
    "csv_name = \"uwm\" # create a name for the output CSV without the .csv extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b525d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_path = os.path.join('../../', 'data', 'locations.json')\n",
    "# with open(json_path, 'r') as file:\n",
    "#     locations = json.load(file)\n",
    "\n",
    "# counties_in_wisconsin = locations['counties_in_wisconsin']\n",
    "# cities_in_wisconsin = locations['cities_in_wisconsin']\n",
    "# states_in_us = locations['states']\n",
    "# nations = locations['nations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e4301",
   "metadata": {},
   "source": [
    "### Load the files into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7454688",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [] # empty list\n",
    "\n",
    "# through all items, format and append to dataset list\n",
    "for path, dir, files in os.walk(json_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            json_file_open = open(file_path, 'rb')\n",
    "            data = json_file_open.read().decode('utf-8', errors='ignore')\n",
    "            loaded = json.loads(data)\n",
    "            dataset.append(loaded)\n",
    "            \n",
    "df = pd.DataFrame(dataset) # convert dataset into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e04a8f",
   "metadata": {},
   "source": [
    "## Part 2: Split multivalued and compound fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b57ef",
   "metadata": {},
   "source": [
    "### Split multivalued fields (arrays)\n",
    "\n",
    "This will remove the punctuation from fields that are formatted as arrays and separate them with pipes ('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to join array elements into a pipe-separated string\n",
    "def join_multivalues(val):\n",
    "    if isinstance(val, list):\n",
    "        return '|'.join(map(str, val))\n",
    "    return val\n",
    "\n",
    "# Apply the function to each column that needs processing\n",
    "multivalue_columns = [\n",
    "    'dcat_keyword_sm', 'dcat_theme_sm', 'dct_subject_sm', 'dct_creator_sm',\n",
    "    'dct_publisher_sm', 'dct_alternative_sm', 'dct_description_sm',\n",
    "    'dct_language_sm', 'dct_identifier_sm', 'dct_isPartOf_sm', \n",
    "    'dct_isReplacedBy_sm', 'dct_isVersionOf_sm', 'dct_relation_sm',\n",
    "    'dct_replaces_sm', 'dct_source_sm', 'dct_license_sm', 'dct_rights_sm',\n",
    "    'dct_rightsHolder_sm', 'dct_spatial_sm', 'dct_temporal_sm',\n",
    "    'gbl_resourceClass_sm', 'gbl_resourceType_sm', 'gbl_displayNote_sm',\n",
    "    'pcdm_memberOf_sm', 'gbl_indexYear_im'\n",
    "]\n",
    "\n",
    "for column in multivalue_columns:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].apply(join_multivalues)\n",
    "    else:\n",
    "        print(f\"Column {column} not found in DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c5d3b",
   "metadata": {},
   "source": [
    "### Split the References into separate columns\n",
    "\n",
    "This step makes it easier to edit individual links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(row):\n",
    "    # Check if the value is a string; otherwise, return None or an empty dict\n",
    "    if isinstance(row['dct_references_s'], str):\n",
    "        try:\n",
    "            dct_references_s = json.loads(row['dct_references_s'].replace('\"\"', '\"'))\n",
    "            return dct_references_s\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON decode error in row: {row}\")\n",
    "            return {}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "# Apply the function to split the column and expand into separate columns\n",
    "df_expanded = df.apply(extract_values, axis=1).apply(pd.Series)\n",
    "\n",
    "# Concatenate the original DataFrame with the expanded DataFrame\n",
    "df = pd.concat([df, df_expanded], axis=1)\n",
    "\n",
    "# Rename columns based on keys in the JSON\n",
    "column_mapping = {\n",
    "    'http://schema.org/downloadUrl': 'Download',\n",
    "    'http://schema.org/url': 'Information',\n",
    "#     'http://www.isotc211.org/schemas/2005/gmd/': 'ISO19139',\n",
    "    'http://www.isotc211.org/schemas/2005/gmd': 'ISO19139',\n",
    "    'http://www.opengis.net/cat/csw/csdgm': 'FGDC',\n",
    "    'http://www.w3.org/1999/xhtml': 'HTML',\n",
    "    'http://lccn.loc.gov/sh85035852': 'Documentation',\n",
    "    'http://iiif.io/api/image': 'IIIF',\n",
    "    'http://iiif.io/api/presentation#manifest': 'Manifest',\n",
    "    'http://www.loc.gov/mods/v3': 'MODS',\n",
    "    'https://openindexmaps.org': 'Index Map',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wms': 'WMS',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wfs': 'WFS',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wcs': 'WCS',\n",
    "    'urn:x-esri:serviceType:ArcGIS#FeatureLayer': 'FeatureServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#TiledMapLayer': 'TileServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#DynamicMapLayer': 'MapServer',\n",
    "    'urn:x-esri:serviceType:ArcGIS#ImageMapLayer': 'ImageServer',\n",
    "    'http://schema.org/DownloadAction': 'Harvard Download',\n",
    "    'https://github.com/cogeotiff/cog-spec': 'COG',\n",
    "    'https://github.com/protomaps/PMTiles': 'PMTiles',\n",
    "    'https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames': 'XYZ Tiles',\n",
    "    'http://schema.org/thumbnailUrl': 'B1G Image',\n",
    "    'http://www.opengis.net/def/serviceType/ogc/wmts': 'WMTS',\n",
    "    'https://oembed.com': 'oembed',\n",
    "    'https://github.com/mapbox/tilejson-spec': 'TileJSON',\n",
    "    'https://wiki.osgeo.org/wiki/Tile_Map_Service_Specification': 'Tile Map Service'\n",
    "    }\n",
    "df.rename(columns=column_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de4050",
   "metadata": {},
   "source": [
    "### Reorder coordinates\n",
    "\n",
    "This will reorder the 4 bbox coordinates into W,S,E,N, which is what the Klokan Bounding Box tool produces on the CSV export option. The BTAA metadata editor uses this order as well when ingesting items. However, Aardvark ultimately uses W,E,N,S, so these would need to be reordered before converting back to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc821630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the 'dcat_bbox' column is a string and handle missing or incorrect formats\n",
    "if 'dcat_bbox' in df.columns:\n",
    "    # Strip 'ENVELOPE()' and split, ensuring all entries are treated as strings\n",
    "    df[['w', 'e', 'n', 's']] = df['dcat_bbox'].apply(\n",
    "        lambda x: x.strip('ENVELOPE()').split(',') if isinstance(x, str) and 'ENVELOPE(' in x and ')' in x else [None, None, None, None]\n",
    "    ).tolist()\n",
    "\n",
    "    # Ensure all elements are strings for the join operation\n",
    "    df['Bounding Box'] = df[['w', 's', 'e', 'n']].apply(\n",
    "        lambda row: ','.join(str(item) for item in row if item is not None),\n",
    "        axis=1\n",
    "    )\n",
    "else:\n",
    "    print(\"Column 'dcat_bbox' is missing from the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a087a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00e084b1",
   "metadata": {},
   "source": [
    "## Part 4: Export to a new CSV with Aardvark labels as headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06042ee7",
   "metadata": {},
   "source": [
    "### Rename the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping of old field names to new labels\n",
    "column_mapping = {\n",
    "    'dcat_keyword_sm': 'Keyword',\n",
    "    'dcat_theme_sm': 'Theme',\n",
    "    'dcat_centroid': 'Centroid',\n",
    "    'dct_subject_sm': 'Subject',\n",
    "    'dct_creator_sm': 'Creator',\n",
    "    'dct_publisher_sm': 'Publisher',\n",
    "#     'dct_alternative_sm': 'Alternative Title',\n",
    "    'dct_description_sm': 'Description',\n",
    "    'dct_language_sm': 'Language',\n",
    "    'dct_title_s': 'Alternative Title',\n",
    "    'dct_identifier_sm': 'Identifier',\n",
    "    'dct_format_s': 'Format',\n",
    "    'dct_isPartOf_sm': 'Is Part Of',\n",
    "    'dct_isReplacedBy_sm': 'Is Replaced By',\n",
    "    'dct_isVersionOf_sm': 'Is Version Of',\n",
    "    'dct_relation_sm': 'Relation',\n",
    "    'dct_replaces_sm': 'Replaces',\n",
    "    'dct_source_sm': 'Source',\n",
    "    'dct_accessRights_s': 'Access Rights',\n",
    "    'dct_license_sm': 'License',\n",
    "    'dct_rights_sm': 'Rights',\n",
    "    'dct_rightsHolder_sm': 'Rights Holder',\n",
    "    'dct_spatial_sm': 'Spatial Coverage',\n",
    "    'dct_issued_s': 'Date Issued',\n",
    "    'dct_temporal_sm': 'Temporal Coverage',\n",
    "    'gbl_mdVersion_s': 'Metadata Version',\n",
    "    'gbl_mdModified_dt': 'Modified',\n",
    "    'gbl_suppressed_b': 'Suppressed',\n",
    "    'gbl_resourceClass_sm': 'Resource Class',\n",
    "    'gbl_resourceType_sm': 'Resource Type',\n",
    "    'gbl_displayNote_sm': 'Display Note',\n",
    "    'id': 'ID',\n",
    "    'gbl_wxsIdentifier_s': 'WxS Identifier',\n",
    "    'gbl_fileSize_s': 'File Size',\n",
    "    'gbl_georeferenced_b': 'Georeferenced',\n",
    "    'gbl_dateRange_drsim': 'Date Range',\n",
    "    'gbl_indexYear_im': 'Index Year',\n",
    "    'locn_geometry': 'Geometry',\n",
    "    'pcdm_memberOf_sm': 'Member Of',\n",
    "    'schema_provider_s': 'Provider'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=column_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f48812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load locations.json\n",
    "json_path = os.path.join('../../', 'data', 'locations.json')\n",
    "with open(json_path, 'r') as file:\n",
    "    locations = json.load(file)\n",
    "\n",
    "counties_in_wisconsin = locations['counties_in_wisconsin']\n",
    "cities_in_wisconsin = locations['cities_in_wisconsin']\n",
    "\n",
    "# Define the transform_title function\n",
    "def transform_title(row):\n",
    "    alt_title = row['Alternative Title']\n",
    "    \n",
    "    # Search for a city or county name in the title.\n",
    "    for county in counties_in_wisconsin:\n",
    "        if re.search(f\"{county} County\", alt_title, re.I):\n",
    "            alt_title = re.sub(f\"{county} County, Wisconsin\", f\"[Wisconsin--{county} County]\", alt_title, flags=re.I, count=1)\n",
    "            break\n",
    "    else:\n",
    "        for city in cities_in_wisconsin:\n",
    "            if re.search(rf\"\\b{city}\\b\", alt_title, re.I):\n",
    "                alt_title = re.sub(rf\"{city}, Wisconsin\", f\"[Wisconsin--{city}]\", alt_title, flags=re.I, count=1)\n",
    "                break\n",
    "        else:\n",
    "            alt_title = re.sub(r\"\\b(Wisconsin)\\b, Wisconsin\", \"[Wisconsin]\", alt_title, flags=re.I, count=1)\n",
    "\n",
    "    # Capture content in brackets\n",
    "    bracket_content = re.findall(r'\\[(.*?)\\]', alt_title)\n",
    "    \n",
    "    if bracket_content:\n",
    "        # Remove bracketed content from original position\n",
    "        alt_title = re.sub(r'\\[.*?\\]', '', alt_title).strip()\n",
    "        \n",
    "        # Append bracketed content to the end of the title\n",
    "        alt_title = f\"{alt_title} [{bracket_content[0]}]\"\n",
    "\n",
    "    # Remove unwanted dashes at the beginning or just before a bracket\n",
    "    alt_title = re.sub(r\"^\\s*-\\s*|\\s*-+\\s*(?=\\[)\", \"\", alt_title)\n",
    "    \n",
    "    # Make sure first letter is capitalized\n",
    "    alt_title = alt_title[0].capitalize() + alt_title[1:]\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    alt_title = re.sub(r'\\s+', ' ', alt_title).strip()\n",
    "    \n",
    "    return alt_title\n",
    "\n",
    "# Define the format_title function\n",
    "def format_title(row):\n",
    "    alternativeTitle = row['Alternative Title']\n",
    "    year = ''\n",
    "    try:  \n",
    "        year_range = re.findall(r'(\\d{4})-(\\d{4})', alternativeTitle)\n",
    "    except:\n",
    "        year_range = ''\n",
    "    try: \n",
    "        single_year = re.match(r'.*(17\\d{2}|18\\d{2}|19\\d{2}|20\\d{2})', alternativeTitle)\n",
    "    except:\n",
    "        single_year = ''    \n",
    "    if year_range:   # if a 'yyyy-yyyy' exists\n",
    "        year = '-'.join(year_range[0])\n",
    "        alternativeTitle = alternativeTitle.replace(year, '').strip().rstrip(',')\n",
    "    elif single_year:  # or if a 'yyyy' exists\n",
    "        year = single_year.group(1)\n",
    "        alternativeTitle = alternativeTitle.replace(year, '').strip().rstrip(',')\n",
    "     \n",
    "    altTitle = str(alternativeTitle)\n",
    "    title = altTitle\n",
    "    if year:\n",
    "        title += ' {' + year +'}'\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    \n",
    "    return title\n",
    "\n",
    "# Combine both functions to transform and format the title\n",
    "def combined_title(row):\n",
    "    row['Alternative Title'] = transform_title(row)\n",
    "    return format_title(row)\n",
    "\n",
    "# Apply the combined function to the DataFrame\n",
    "df['Title'] = df.apply(combined_title, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c663b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load locations.json\n",
    "json_path = os.path.join('../../', 'data', 'locations.json')\n",
    "states_in_us = locations['states']\n",
    "nations = locations['nations']\n",
    "\n",
    "# Define the function to format the \"Spatial Coverage\" values\n",
    "def format_spatial_coverage(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    parts = value.split('|')\n",
    "    formatted_parts = []\n",
    "    for part in parts:\n",
    "        if part in states_in_us:\n",
    "            # If part is a state, keep it as is\n",
    "            formatted_parts.append(part)\n",
    "        elif 'County' in part or 'Metro' in part:\n",
    "            # Format as \"state--county\" or \"state--city\"\n",
    "            state = parts[-1]  # Assume last part is the state\n",
    "            if state in states_in_us and part != state:  # Avoid duplicating the state in \"state--state\"\n",
    "                formatted_parts.append(f'{state}--{part}')\n",
    "            else:\n",
    "                formatted_parts.append(part)\n",
    "        elif part not in states_in_us and part not in nations:\n",
    "            # Other parts, format as \"state--city\" for cities\n",
    "            state = parts[-1]  # Assume last part is the state\n",
    "            if state in states_in_us and part != state:  # Avoid duplicating the state in \"state--state\"\n",
    "                formatted_parts.append(f'{state}--{part}')\n",
    "            else:\n",
    "                formatted_parts.append(part)\n",
    "        else:\n",
    "            # If part is a nation, keep it as is\n",
    "            formatted_parts.append(part)\n",
    "    return '|'.join(formatted_parts)\n",
    "\n",
    "# Apply the function to the \"Spatial Coverage\" column\n",
    "df['Original Spatial Coverage'] = df['Spatial Coverage']\n",
    "df['Spatial Coverage'] = df['Spatial Coverage'].apply(format_spatial_coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38345bf",
   "metadata": {},
   "source": [
    "### Write the DataFrame to a CSV file with Aardvark labels\n",
    "\n",
    "This can be uploaded to GBL Admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5842da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"{}.csv\".format(csv_name), index=False, na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efb18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
