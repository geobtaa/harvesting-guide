{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8921d99a",
   "metadata": {},
   "source": [
    "# Metadata Validation and Clean\n",
    "\n",
    "Note: this is the same as the Clean script, but extends the coordinates to 3 decimal points.\n",
    "\n",
    "This script will read a CSV of Aardvark metadata to check for required fields and values:\n",
    "1. Resource Class: Checks for a valid entry; if fails -> \"Other\"\n",
    "2. Access Rights: Checks for a valid entry; if fails -> \"Public\"\n",
    "3. Date Range: Ensures that the second integer is equal or larger than the first\n",
    "4. Format: Checks if Download is present; if so -> \"File\"\n",
    "5. Bounding Box: \n",
    "    - Rounds to 3 decimal points\n",
    "    - Checks for extremes (180 or 90) and decreases by .001\n",
    "    - Checks for points or lines and increases north or east by .0001\n",
    "    \n",
    "At the end, the script will write the changes to `cleaning_log.csv` and will create a new CSV with the full metadata and cleaned values. The new metadata file will contain a column to indicate if the row was cleaned or not. The column value will excludes rows where the only cleaning action was coordinate rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53415338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the acceptable values\n",
    "resource_class_values = ['Collections','Datasets','Imagery','Maps','Web services','Websites','Other']\n",
    "access_rights_values = ['Public', 'Restricted']\n",
    "\n",
    "# Load your CSV file into a pandas DataFrame\n",
    "# Fill this in with the name of your CSV!!!!\n",
    "csv_file_path = '10d-03.csv'\n",
    "data = pd.read_csv(csv_file_path, low_memory=False)\n",
    "\n",
    "# Create a DataFrame to store cleaning log\n",
    "cleaning_log = pd.DataFrame(columns=['ColumnName', 'OriginalValue', 'CleanedValue', 'CleaningAction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfbccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'Resource Class'\n",
    "def clean_resource_class(row):\n",
    "    global cleaning_log\n",
    "    resource_class_string = row['Resource Class']\n",
    "    original = resource_class_string\n",
    "\n",
    "    if pd.isnull(resource_class_string):\n",
    "        new_value = 'Datasets'\n",
    "        cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Resource Class', 'OriginalValue': original, 'CleanedValue': new_value, 'CleaningAction': 'Filled empty value with \"Datasets\"'}])], ignore_index=True)\n",
    "        return new_value\n",
    "    else:\n",
    "        resource_classes = resource_class_string.split('|')\n",
    "        new_resource_classes = []\n",
    "\n",
    "        for class_value in resource_classes:\n",
    "            class_value = class_value.strip()\n",
    "            if class_value in resource_class_values:\n",
    "                new_resource_classes.append(class_value)\n",
    "            else:\n",
    "                new_value = 'Other'  # Default value if no match is found\n",
    "                cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Resource Class', 'OriginalValue': class_value, 'CleanedValue': new_value, 'CleaningAction': 'Replaced unrecognized value with \"Other\"'}])], ignore_index=True)\n",
    "                new_resource_classes.append(new_value)\n",
    "\n",
    "        return '|'.join(new_resource_classes)\n",
    "\n",
    "data['Resource Class'] = data.apply(clean_resource_class, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'Access Rights'\n",
    "access_rights_values = ['Public', 'Restricted']\n",
    "\n",
    "def clean_access_rights(row):\n",
    "    global cleaning_log\n",
    "    x = row['Access Rights']\n",
    "    original = x\n",
    "\n",
    "    if pd.isnull(x) or str(x).strip() not in access_rights_values:\n",
    "        x = 'Public'  # Default to 'Public' if the value is missing or not in the list\n",
    "        action = 'Filled empty value with \"Public\"' if pd.isnull(x) else 'Replaced unrecognized value with \"Public\"'\n",
    "        cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Access Rights', 'OriginalValue': original, 'CleanedValue': x, 'CleaningAction': action}])], ignore_index=True)\n",
    "\n",
    "    return x\n",
    "\n",
    "data['Access Rights'] = data.apply(clean_access_rights, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'Date Range'\n",
    "# def clean_date_range(row):\n",
    "#     x = row['Date Range']\n",
    "#     original = x\n",
    "#     if pd.isnull(x) or x == '':\n",
    "#         return x  # returns the original value if it's empty or null\n",
    "#     else:\n",
    "#         date_ranges = str(x).split('|')\n",
    "#         for i in range(len(date_ranges)):\n",
    "#             years = date_ranges[i].split('-')\n",
    "#             if len(years) != 2 or not years[0].isdigit() or not years[1].isdigit() or int(years[0]) > int(years[1]):\n",
    "#                 years = sorted(years)\n",
    "#                 date_ranges[i] = '-'.join(years)\n",
    "#                 x = '|'.join(date_ranges)\n",
    "#                 global cleaning_log\n",
    "#                 cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Date Range', 'OriginalValue': original, 'CleanedValue': x, 'CleaningAction': 'Corrected date order'}])], ignore_index=True)\n",
    "#         return x\n",
    "# data['Date Range'] = data.apply(clean_date_range, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d147d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date_range(row):\n",
    "    global cleaning_log\n",
    "\n",
    "    x = row['Date Range']\n",
    "    original = x\n",
    "    if pd.isnull(x) or x == '':\n",
    "        return x  # returns the original value if it's empty or null\n",
    "    else:\n",
    "        date_ranges = str(x).split('|')\n",
    "        for i in range(len(date_ranges)):\n",
    "            years = date_ranges[i].split('-')\n",
    "\n",
    "            # Check if both years are either digits or 'Unknown'\n",
    "            if all(year.isdigit() for year in years):\n",
    "                if len(years) == 2 and years[0].isdigit() and years[1].isdigit() and int(years[0]) > int(years[1]):\n",
    "                    years = sorted(years, key=lambda y: (y.isdigit(), y))\n",
    "                    date_ranges[i] = '-'.join(years)\n",
    "                    x = '|'.join(date_ranges)\n",
    "                    cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Date Range', 'OriginalValue': original, 'CleanedValue': x, 'CleaningAction': 'Corrected date order'}])], ignore_index=True)\n",
    "            else:\n",
    "                # Clear the cell if the condition is not met\n",
    "                x = ''\n",
    "                cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Date Range', 'OriginalValue': original, 'CleanedValue': x, 'CleaningAction': 'Cleared non-integer date range'}])], ignore_index=True)\n",
    "                break  # Exit the loop as we've cleared the cell\n",
    "\n",
    "        return x\n",
    "\n",
    "data['Date Range'] = data.apply(clean_date_range, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'Format' based on 'Download' field\n",
    "def clean_format(row):\n",
    "    x = row['Format']\n",
    "    original = x\n",
    "    if pd.isnull(x) and pd.notnull(row['Download']):\n",
    "        x = 'File'\n",
    "        global cleaning_log\n",
    "        cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Format', 'OriginalValue': original, 'CleanedValue': x, 'CleaningAction': 'Filled missing value with \"File\"'}])], ignore_index=True)\n",
    "    return x\n",
    "\n",
    "data['Format'] = data.apply(clean_format, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Original Bounding Box'] = data.loc[:, 'Bounding Box']\n",
    "# Function to round decimal places\n",
    "def round_coordinates(row):\n",
    "    x = row['Bounding Box']\n",
    "    original = x\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    else:\n",
    "        pairs = x.split(',')\n",
    "        new_pairs = []\n",
    "        for pair in pairs:\n",
    "            coords = pair.split()\n",
    "            new_coords = [str(round(float(coord), 3)) for coord in coords]\n",
    "            new_pair = ' '.join(new_coords)\n",
    "            global cleaning_log\n",
    "            if new_pair != pair:\n",
    "                cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{'ID':row['ID'], 'ColumnName': 'Bounding Box', 'OriginalValue': pair, 'CleanedValue': new_pair, 'CleaningAction': 'Rounded to 3 decimal places'}])], ignore_index=True)\n",
    "            new_pairs.append(new_pair)\n",
    "        return ','.join(new_pairs)\n",
    "    \n",
    "data['Bounding Box'] = data.apply(round_coordinates, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bounding_box(row):\n",
    "    global cleaning_log\n",
    "\n",
    "    original_coords = str(row['Bounding Box'])\n",
    "    coords = original_coords.split(',')\n",
    "    \n",
    "    if original_coords == '' or original_coords == 'nan' or len(coords) != 4:\n",
    "        return np.nan\n",
    "\n",
    "    west, south, east, north = map(float, coords)\n",
    "\n",
    "    # Adjust if coordinates are at the extremes\n",
    "    if west in [180.000, -180.000]:\n",
    "        west = 179.999 if west > 0 else -179.999\n",
    "    if east in [180.000, -180.000]:\n",
    "        east = 179.999 if east > 0 else -179.999\n",
    "    if north == 90.000:\n",
    "        north = 89.999\n",
    "    if south == -90.000:\n",
    "        south = -89.999\n",
    "\n",
    "    east_modified = False\n",
    "    north_modified = False\n",
    "\n",
    "    if west == east:\n",
    "        east += 0.0001  # Add 0.0001 instead of 0.001\n",
    "        east_modified = True\n",
    "\n",
    "    if south == north:\n",
    "        north += 0.0001  # Add 0.0001 instead of 0.001\n",
    "        north_modified = True\n",
    "\n",
    "    # Format coordinates with four decimal places\n",
    "    new_coords = f\"{west:.3f},{south:.3f},{f'{east:.4f}' if east_modified else f'{east:.3f}'},{f'{north:.4f}' if north_modified else f'{north:.3f}'}\"\n",
    "\n",
    "    original_coords_formatted = f\"{float(coords[0]):.3f},{float(coords[1]):.3f},{float(coords[2]):.3f},{float(coords[3]):.3f}\"\n",
    "    \n",
    "    if new_coords != original_coords_formatted:\n",
    "        cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{'ID':row['ID'], 'ColumnName': 'Bounding Box', 'OriginalValue': row['Bounding Box'], 'CleanedValue': new_coords, 'CleaningAction': 'Corrected line/point to a box or adjusted extreme values'}])], ignore_index=True)\n",
    "\n",
    "    return new_coords\n",
    "\n",
    "data['Bounding Box'] = data.apply(clean_bounding_box, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed670c4",
   "metadata": {},
   "source": [
    "## After cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the cleaning_log to exclude rounding-only actions\n",
    "non_rounding_log = cleaning_log[~cleaning_log['CleaningAction'].str.contains(\"Rounded to\")]\n",
    "\n",
    "# Create a set with all IDs that have non-rounding cleaning actions\n",
    "cleaned_ids = set(non_rounding_log['ID'])\n",
    "\n",
    "cleaned_file_path = \"cleaned_\" + csv_file_path\n",
    "\n",
    "# Create a new column 'Cleaned'\n",
    "data['Cleaned'] = data['ID'].apply(lambda x: 'Yes' if x in cleaned_ids else 'No')\n",
    "\n",
    "# Write the cleaned data to a CSV file\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "cleaning_log.to_csv(\"cleaning_log.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
