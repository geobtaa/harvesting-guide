{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58e54c7",
   "metadata": {},
   "source": [
    "# Extract technical metadata\n",
    "\n",
    "This recipe will extract technical metadata from a directory of datasets and export it to a CSV file. It requires the python libraries `pandas`, `geopandas`, and `rasterio`. Part 1 writes the filenames, coordinate reference system, file format, resource type, and (optionally) the WKT polygon outline. Part 2 creates CSV files of the attribute table field names and types.\n",
    "\n",
    "Created 2024-10-18 by Karen Majewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf5cc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.warp import transform_bounds\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import box\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27766c8",
   "metadata": {},
   "source": [
    "## Part 1: Extract metadata to a CSV\n",
    "\n",
    "### Setup CSV and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5fadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from variable names to desired column headers\n",
    "column_mapping = {\n",
    "    'folder_name': 'Folder Name',\n",
    "    'filename': 'File Name',\n",
    "    'crs': 'Conforms To',\n",
    "    'file_format': 'Format',\n",
    "    \"total_area_km2\": 'Extent',\n",
    "    'spatial_resolution': 'Spatial Resolution',\n",
    "    'geometry_type': 'Resource Type',\n",
    "    'bounding_box': 'Bounding Box',\n",
    "    'wkt_outline': 'Geometry',\n",
    "    'folder_size': 'File Size'\n",
    "    \n",
    "}\n",
    "\n",
    "# Define global variables for the script\n",
    "root_directory = 'olmsted'\n",
    "output_csv = 'olmsted.csv'\n",
    "simplify_tolerance = None\n",
    "include_wkt = True\n",
    "decimal_places = 2\n",
    "\n",
    "\n",
    "# Define the output directory for the attribute table CSV files\n",
    "output_directory = 'olmsted_codebooks'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22227105",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "### File size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb611c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add up the files in each dataset folder\n",
    "\n",
    "def get_folder_size(folder_path, unit='MB', decimal_places=3):\n",
    "    \"\"\"\n",
    "    Calculate the total size of all files in a folder and return it in the specified unit.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder.\n",
    "    - unit (str): The unit for the size ('bytes', 'KB', 'MB'). Default is 'MB'.\n",
    "    - decimal_places (int): The number of decimal places to round the size to. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    - float: Total size of the folder contents in the specified unit, rounded to the specified number of decimal places.\n",
    "    \"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # Add to the total size only if it is a file (not a broken link, etc.)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    # Convert the total size to the specified unit\n",
    "    if unit == 'KB':\n",
    "        total_size /= 1024  # Convert bytes to kilobytes\n",
    "    elif unit == 'MB':\n",
    "        total_size /= (1024 * 1024)  # Convert bytes to megabytes\n",
    "\n",
    "    # Round the total size to the specified number of decimal places\n",
    "    rounded_size = round(total_size, decimal_places)\n",
    "    return rounded_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62c94c",
   "metadata": {},
   "source": [
    "### Geometry type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8023360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_geometry_type(data, is_raster=False):\n",
    "    \"\"\"\n",
    "    Determine the geometry type of a GeoDataFrame or indicate if the dataset is a raster.\n",
    "\n",
    "    Parameters:\n",
    "    - data (GeoDataFrame or DatasetReader): The data source, which can be a GeoDataFrame for vector data or DatasetReader for raster.\n",
    "    - is_raster (bool): Flag to indicate if the data source is a raster.\n",
    "\n",
    "    Returns:\n",
    "    - str: The geometry type description, or 'Unknown' if the geometry type cannot be determined.\n",
    "    \"\"\"\n",
    "    if is_raster:\n",
    "        return \"Raster data\"\n",
    "\n",
    "    if data.empty or data.geometry.is_empty.all():\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Get unique geometry types in the GeoDataFrame\n",
    "        geometry_types = data.geom_type.unique()\n",
    "\n",
    "        # Format the geometry type for output\n",
    "        if len(geometry_types) == 1:\n",
    "            # Single geometry type\n",
    "            geometry_type = geometry_types[0].replace(\"LineString\", \"Line\").replace(\"MultiPolygon\", \"Polygon\")\n",
    "        else:\n",
    "            # Mixed geometry types\n",
    "            geometry_type = \"Mixed geometries\"\n",
    "\n",
    "        return f\"{geometry_type} data\"\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to determine geometry type: {e}\")\n",
    "        return 'Unknown'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0a43e",
   "metadata": {},
   "source": [
    "### Report original CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c157507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reformat the CRS into a resolvable URI\n",
    "\n",
    "def format_crs_uri(crs_string):\n",
    "    # If the CRS is in the \"EPSG:xxxx\" format, convert it to a resolvable URI\n",
    "    if crs_string and crs_string.startswith(\"EPSG:\"):\n",
    "        epsg_code = crs_string.split(\":\")[1]\n",
    "        return f\"https://epsg.io/{epsg_code}\"\n",
    "    else:\n",
    "        # Return the original CRS string if it's not an EPSG code\n",
    "        return crs_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54400b40",
   "metadata": {},
   "source": [
    "### Rounding function (check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0a1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_coordinates(geometry, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Round the coordinates of a geometry to the specified number of decimal places.\n",
    "\n",
    "    Parameters:\n",
    "    - geometry (Geometry): The input Shapely geometry.\n",
    "    - decimal_places (int): Number of decimal places to round to.\n",
    "\n",
    "    Returns:\n",
    "    - Geometry: The geometry with rounded coordinates.\n",
    "    \"\"\"\n",
    "    if geometry.is_empty:\n",
    "        return geometry\n",
    "\n",
    "    # Function to round coordinates\n",
    "    def rounder(x, y, z=None):\n",
    "        if z is None:\n",
    "            return (round(x, decimal_places), round(y, decimal_places))\n",
    "        else:\n",
    "            return (round(x, decimal_places), round(y, decimal_places), round(z, decimal_places))\n",
    "\n",
    "    # Apply the rounding function using transform\n",
    "    return transform(rounder, geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef278ad",
   "metadata": {},
   "source": [
    "### Bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a2dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTOR \n",
    "\n",
    "def calculate_bounding_box(gdf, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Calculate and format the bounding box for a GeoDataFrame in WGS84 (EPSG:4326).\n",
    "    \n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame to process.\n",
    "    - decimal_places (int, optional): Number of decimal places to round coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted bounding box as a string.\n",
    "    \"\"\"\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Convert to WGS84 for bounding box calculation\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "        bounds = gdf.total_bounds\n",
    "        rounded_bounds = [round(coord, decimal_places) for coord in bounds]\n",
    "        return f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "    except Exception:\n",
    "        return 'Unknown'\n",
    "\n",
    "\n",
    "# RASTER\n",
    "\n",
    "def calculate_bounding_box_raster(src, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Calculate the bounding box and WKT outline for a raster file in WGS84 (EPSG:4326).\n",
    "    \n",
    "    Parameters:\n",
    "    - src (rasterio.io.DatasetReader): The raster source.\n",
    "    - decimal_places (int, optional): Number of decimal places to round coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the formatted bounding box as a string and the WKT representation of the bounding box.\n",
    "    \"\"\"\n",
    "    if src.crs is None:\n",
    "        return 'Unknown', 'None'\n",
    "\n",
    "    try:\n",
    "        # Reproject the bounding box to WGS84 if needed\n",
    "        left, bottom, right, top = src.bounds\n",
    "        if src.crs.to_string() != 'EPSG:4326':\n",
    "            left, bottom, right, top = transform_bounds(src.crs, 'EPSG:4326', left, bottom, right, top)\n",
    "\n",
    "        # Round the coordinates\n",
    "        rounded_bounds = [round(coord, decimal_places) for coord in [left, bottom, right, top]]\n",
    "        bbox_str = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "        # Create WKT for a Polygon representing the bounding box\n",
    "        wkt_outline = f\"POLYGON(({rounded_bounds[0]} {rounded_bounds[1]}, {rounded_bounds[0]} {rounded_bounds[3]}, \" \\\n",
    "                      f\"{rounded_bounds[2]} {rounded_bounds[3]}, {rounded_bounds[2]} {rounded_bounds[1]}, \" \\\n",
    "                      f\"{rounded_bounds[0]} {rounded_bounds[1]}))\"\n",
    "\n",
    "        return bbox_str, wkt_outline\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate bounding box and WKT outline: {e}\")\n",
    "        return 'Unknown', 'None'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b8716",
   "metadata": {},
   "source": [
    "### Geometry (WKT Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75322f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wkt_outline(gdf, simplify_tolerance=None, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Generate a WKT representation of a generalized outline for the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame containing the geometries.\n",
    "    - simplify_tolerance (float, optional): The tolerance for the simplify() method to reduce detail.\n",
    "    - decimal_places (int, optional): The number of decimal places to round the coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - str: The WKT representation of the generalized outline.\n",
    "    \"\"\"\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'None'\n",
    "\n",
    "    try:\n",
    "        # Convert to WGS84 for WKT generation\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "        # Create a unified geometry from all geometries in the GeoDataFrame\n",
    "        unified_geom = gdf.geometry.union_all()\n",
    "\n",
    "        # Use the convex hull to create a generalized outline\n",
    "        if not unified_geom.is_empty:\n",
    "            generalized_outline = unified_geom.convex_hull\n",
    "        else:\n",
    "            return 'None'\n",
    "\n",
    "        # Optionally simplify the outline for further generalization\n",
    "        if simplify_tolerance is not None:\n",
    "            generalized_outline = generalized_outline.simplify(simplify_tolerance)\n",
    "\n",
    "        # Round the coordinates of the outline\n",
    "        generalized_outline = round_coordinates(generalized_outline, decimal_places)\n",
    "\n",
    "        # Convert the resulting geometry to WKT using shapely's wkt module\n",
    "        if isinstance(generalized_outline, Polygon):\n",
    "            wkt_outline = generalized_outline.wkt\n",
    "        else:\n",
    "            return 'None'\n",
    "\n",
    "        return wkt_outline\n",
    "    except Exception:\n",
    "        return 'None'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce00478",
   "metadata": {},
   "source": [
    "### Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66f1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_area(gdf):\n",
    "    \"\"\"\n",
    "    Calculate the total area covered by a GeoDataFrame in square kilometers using an equal-area projection.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame to process.\n",
    "\n",
    "    Returns:\n",
    "    - float or str: The total area in square kilometers, or 'Unknown' if unavailable.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Reproject to an equal-area projection for accurate area calculation\n",
    "        gdf = gdf.to_crs(epsg=6933)\n",
    "        total_area_km2 = gdf.geometry.area.sum() / 1e6  # Convert to square kilometers\n",
    "        return round(total_area_km2, 3)\n",
    "    except Exception:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def calculate_total_area_raster(src):\n",
    "    \"\"\"\n",
    "    Calculate the total area covered by a raster file in square kilometers.\n",
    "\n",
    "    Parameters:\n",
    "    - src (rasterio.io.DatasetReader): The raster source.\n",
    "\n",
    "    Returns:\n",
    "    - float or str: The total area in square kilometers, or 'Unknown' if unavailable.\n",
    "    \"\"\"\n",
    "    if src.crs is None:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Create a Polygon of the raster bounds\n",
    "        left, bottom, right, top = src.bounds\n",
    "        raster_bbox = box(left, bottom, right, top)\n",
    "        raster_gdf = gpd.GeoDataFrame({'geometry': [raster_bbox]}, crs=src.crs)\n",
    "\n",
    "        # Reproject to an equal-area projection for accurate area calculation\n",
    "        raster_gdf = raster_gdf.to_crs(epsg=6933)\n",
    "        total_area_m2 = raster_gdf.geometry.area.sum()\n",
    "        total_area_km2 = total_area_m2 / 1e6  # Convert to square kilometers\n",
    "\n",
    "        return round(total_area_km2, 3)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate total area for raster: {e}\")\n",
    "        return 'Unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44f505",
   "metadata": {},
   "source": [
    "### Walk through the files and extract metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2521e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through the files and extract metadata\n",
    "def extract_metadata():\n",
    "    \"\"\"\n",
    "    Extract metadata from geospatial datasets in a directory.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary of lists for metadata\n",
    "    metadata = {\n",
    "        'filename': [],\n",
    "        'folder_name': [],\n",
    "        'crs': [],\n",
    "        'file_format': [],\n",
    "        'geometry_type': [],\n",
    "        'bounding_box': [],\n",
    "        'total_area_km2': [],\n",
    "        'spatial_resolution': [],\n",
    "        'folder_size': [],\n",
    "        'wkt_outline': []\n",
    "    }\n",
    "\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {'.shp': 'Shapefile', '.geojson': 'GeoJSON'}\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, _, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "            filepath = os.path.join(root, filename)\n",
    "            folder_name = os.path.basename(os.path.dirname(filepath))\n",
    "            folder_size = get_folder_size(os.path.dirname(filepath), unit='MB')\n",
    "\n",
    "            # Vector Data Processing\n",
    "            if file_ext in vector_formats:\n",
    "                process_vector(filepath, filename, vector_formats[file_ext], folder_name, folder_size, metadata,\n",
    "                               simplify_tolerance, include_wkt, decimal_places)\n",
    "\n",
    "            # Raster Data Processing\n",
    "            elif file_ext == '.tif':\n",
    "                process_raster(filepath, filename, folder_name, folder_size, metadata, include_wkt, decimal_places)\n",
    "\n",
    "        # Geodatabase Processing (directories with .gdb)\n",
    "        if root.endswith('.gdb'):\n",
    "            folder_name = os.path.basename(root)\n",
    "            folder_size = get_folder_size(root, unit='MB')\n",
    "            process_geodatabase(root, folder_name, folder_size, metadata, simplify_tolerance, include_wkt, decimal_places)\n",
    "\n",
    "    # Convert metadata dictionary to DataFrame and save as CSV\n",
    "    \n",
    "    # After processing, create the DataFrame\n",
    "    df = pd.DataFrame(metadata)\n",
    "\n",
    "    # Rename columns using column_mapping\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "    # Save the DataFrame as CSV\n",
    "    output_csv_path = os.path.join(root_directory, output_csv)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Metadata extraction complete. CSV saved to {output_csv_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e3cfb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vector(filepath, filename, file_format, folder_name, folder_size, metadata, simplify_tolerance, include_wkt, decimal_places):\n",
    "    try:\n",
    "        gdf = gpd.read_file(filepath)\n",
    "        if gdf.crs is None:\n",
    "            logging.warning(f\"Dataset {filename} has no CRS. Spatial calculations may be inaccurate.\")\n",
    "            crs_uri = 'Unknown'\n",
    "        else:\n",
    "            original_crs = gdf.crs.to_string()\n",
    "            crs_uri = format_crs_uri(original_crs)\n",
    "            \n",
    "        if gdf.crs is None:\n",
    "            # Assign a known CRS\n",
    "            gdf.crs = 'EPSG:26916'  # Replace with the correct CRS\n",
    "            crs_uri = format_crs_uri(gdf.crs.to_string())\n",
    "            logging.info(f\"Assigned CRS {gdf.crs} to dataset {filename}\")\n",
    "        else:\n",
    "            original_crs = gdf.crs.to_string()\n",
    "            crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "\n",
    "        # Calculate metadata components\n",
    "        bbox = calculate_bounding_box(gdf, decimal_places)\n",
    "        wkt_outline = generate_wkt_outline(gdf, simplify_tolerance, decimal_places) if include_wkt else None\n",
    "        total_area_km2 = calculate_total_area(gdf)\n",
    "#         spatial_resolution = calculate_spatial_resolution_vector(gdf)\n",
    "\n",
    "        # Process geometry type\n",
    "        geometry_type = process_geometry_type(gdf)\n",
    "\n",
    "        # Store metadata directly into the dictionary of lists\n",
    "        metadata['filename'].append(filename)\n",
    "        metadata['folder_name'].append(folder_name)\n",
    "        metadata['crs'].append(crs_uri)\n",
    "        metadata['file_format'].append(file_format)\n",
    "        metadata['geometry_type'].append(geometry_type)\n",
    "        metadata['bounding_box'].append(bbox)\n",
    "        metadata['total_area_km2'].append(total_area_km2)\n",
    "        metadata['spatial_resolution'].append('')\n",
    "        metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "        metadata['wkt_outline'].append(wkt_outline if include_wkt else None)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not read vector file {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308d4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raster(filepath, filename, folder_name, folder_size, metadata, include_wkt, decimal_places):\n",
    "    try:\n",
    "        with rasterio.open(filepath) as src:\n",
    "            if src.crs is None:\n",
    "                logging.warning(f\"Raster dataset {filename} has no CRS. Spatial calculations may be inaccurate.\")\n",
    "                crs_uri = 'Unknown'\n",
    "            else:\n",
    "                original_crs = src.crs.to_string()\n",
    "                crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "            # Calculate spatial resolution and area\n",
    "            pixel_size_x, pixel_size_y = src.res\n",
    "            spatial_resolution = round((abs(pixel_size_x) + abs(pixel_size_y)) / 2, 2)\n",
    "            total_area_km2 = calculate_total_area_raster(src)\n",
    "\n",
    "            # Get bounding box and WKT outline\n",
    "            bbox, wkt_outline = calculate_bounding_box_raster(src, decimal_places)\n",
    "\n",
    "            # Store metadata directly into the dictionary of lists\n",
    "            metadata['filename'].append(filename)\n",
    "            metadata['folder_name'].append(folder_name)\n",
    "            metadata['crs'].append(crs_uri)\n",
    "            metadata['file_format'].append('GeoTIFF')\n",
    "            metadata['geometry_type'].append('Raster data')\n",
    "            metadata['bounding_box'].append(bbox)\n",
    "            metadata['total_area_km2'].append(total_area_km2)\n",
    "            metadata['spatial_resolution'].append(spatial_resolution)\n",
    "            metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "            metadata['wkt_outline'].append(wkt_outline if include_wkt else None)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not read raster file {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c3a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_geodatabase(root, folder_name, folder_size, metadata):\n",
    "    \"\"\"\n",
    "    Process a geodatabase to extract metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - root (str): The path to the geodatabase.\n",
    "    - folder_name (str): The name of the folder containing the geodatabase.\n",
    "    - folder_size (float): The size of the folder in MB.\n",
    "    - metadata (dict): The dictionary to store metadata for all files.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    geodatabase_name = os.path.basename(root)\n",
    "    \n",
    "    # Record basic metadata for the geodatabase\n",
    "    metadata['filename'].append(geodatabase_name)\n",
    "    metadata['folder_name'].append(folder_name)\n",
    "    metadata['file_format'].append('Geodatabase')\n",
    "    metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "    \n",
    "    # Leave fields empty as spatial processing is no longer required\n",
    "    metadata['crs'].append('')\n",
    "    metadata['geometry_type'].append('')\n",
    "    metadata['bounding_box'].append('')\n",
    "    metadata['total_area_km2'].append('')\n",
    "    metadata['spatial_resolution'].append('')\n",
    "    metadata['wkt_outline'].append('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e8478",
   "metadata": {},
   "source": [
    "### Executing the code for Part 1\n",
    "\n",
    "Run option 1 to process the metadata without extracting the WKT polygon outline\n",
    "    Run option 2 to obtain the outline. Review the simplify_tolerance value and update if needed. `.01` can be used for decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6edf7efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata extraction complete. CSV saved to olmsted/olmsted.csv\n"
     ]
    }
   ],
   "source": [
    "extract_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea9e04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 Exclude WKT outline from the metadata\n",
    "# extract_metadata(root_directory, include_wkt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d68de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Include WKT outline in the metadata\n",
    "# extract_metadata(root_directory, simplify_tolerance=.001, include_wkt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140b4b5",
   "metadata": {},
   "source": [
    "## Part 2: Attribute Tables\n",
    "\n",
    "This function will read the attribute table fields and write them to a CSV in a defined directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "919eff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attribute_table_info(root_directory, output_dir):\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {\n",
    "        '.shp': 'Shapefile',\n",
    "        '.geojson': 'GeoJSON'\n",
    "    }\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, _, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            # Get the file extension\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(root, filename)\n",
    "\n",
    "            # Check if the file is a recognized vector format\n",
    "            if file_ext in vector_formats:\n",
    "                try:\n",
    "                    # Read the vector file with GeoPandas\n",
    "                    gdf = gpd.read_file(filepath)\n",
    "\n",
    "                    # Extract field information\n",
    "                    field_info = []\n",
    "                    for column in gdf.columns:\n",
    "                        field_metadata = {\n",
    "                            'Field Name': column,\n",
    "                            'Data Type': str(gdf[column].dtype),\n",
    "                            'Unique Values': gdf[column].nunique(),\n",
    "                            'Null Values': gdf[column].isnull().sum(),\n",
    "                            'Definition' : '',\n",
    "                            'Definition Source' : ''\n",
    "                        }\n",
    "                        field_info.append(field_metadata)\n",
    "\n",
    "                    # Convert the field information to a DataFrame\n",
    "                    field_df = pd.DataFrame(field_info)\n",
    "\n",
    "                    # Create the output CSV filename\n",
    "                    output_csv = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_fields.csv\")\n",
    "\n",
    "                    # Save the DataFrame to a CSV file\n",
    "                    field_df.to_csv(output_csv, index=False)\n",
    "\n",
    "#                     print(f\"Field information extracted for {filename}. CSV saved to {output_csv}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362a409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attribute table information\n",
    "extract_attribute_table_info(root_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1e097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
