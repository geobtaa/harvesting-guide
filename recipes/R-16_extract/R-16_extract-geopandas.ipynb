{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64715113",
   "metadata": {},
   "source": [
    "# Extract technical metadata\n",
    "\n",
    "This recipe will extract technical metadata from a directory of datasets and export it to a CSV file. It requires the python libraries `pandas`, `geopandas`, and `rasterio`. Part 1 writes the filenames, coordinate reference system, file format, resource type, and (optionally) the WKT polygon outline. Part 2 creates CSV files of the attribute table field names and types.\n",
    "\n",
    "Created 2024-10-18 by Karen Majewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1aff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0054a82",
   "metadata": {},
   "source": [
    "## Part 1: Extract metadata to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3022b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from variable names to desired column headers\n",
    "column_mapping = {\n",
    "    'folder_name': 'Folder Name',\n",
    "    'filename': 'File Name',\n",
    "    'crs': 'Conforms To',\n",
    "    'file_format': 'Format',\n",
    "    'geometry_type': 'Resource Type',\n",
    "    'bounding_box': 'Bounding Box',\n",
    "    'wkt_outline': 'Geometry',\n",
    "    'folder_size': 'File Size'\n",
    "}\n",
    "\n",
    "# Define the root directory for the geospatial data\n",
    "root_directory = 'data'\n",
    "\n",
    "# Define the output directory for the attribute table CSV files\n",
    "output_directory = 'codebooks'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df276f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add up the files in each dataset folder\n",
    "\n",
    "def get_folder_size(folder_path, unit='MB', decimal_places=3):\n",
    "    \"\"\"\n",
    "    Calculate the total size of all files in a folder and return it in the specified unit.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder.\n",
    "    - unit (str): The unit for the size ('bytes', 'KB', 'MB'). Default is 'MB'.\n",
    "    - decimal_places (int): The number of decimal places to round the size to. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    - float: Total size of the folder contents in the specified unit, rounded to the specified number of decimal places.\n",
    "    \"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # Add to the total size only if it is a file (not a broken link, etc.)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    # Convert the total size to the specified unit\n",
    "    if unit == 'KB':\n",
    "        total_size /= 1024  # Convert bytes to kilobytes\n",
    "    elif unit == 'MB':\n",
    "        total_size /= (1024 * 1024)  # Convert bytes to megabytes\n",
    "\n",
    "    # Round the total size to the specified number of decimal places\n",
    "    rounded_size = round(total_size, decimal_places)\n",
    "    return rounded_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d1c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reformat the CRS into a resolvable URI\n",
    "\n",
    "def format_crs_uri(crs_string):\n",
    "    # If the CRS is in the \"EPSG:xxxx\" format, convert it to a resolvable URI\n",
    "    if crs_string and crs_string.startswith(\"EPSG:\"):\n",
    "        epsg_code = crs_string.split(\":\")[1]\n",
    "        return f\"https://epsg.io/{epsg_code}\"\n",
    "    else:\n",
    "        # Return the original CRS string if it's not an EPSG code\n",
    "        return crs_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a23188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to create Geometry values (WKT polygon outlines)\n",
    "\n",
    "def round_coordinates(geometry, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Round the coordinates of a geometry to the specified number of decimal places.\n",
    "\n",
    "    Parameters:\n",
    "    - geometry (Geometry): The input Shapely geometry.\n",
    "    - decimal_places (int): Number of decimal places to round to.\n",
    "\n",
    "    Returns:\n",
    "    - Geometry: The geometry with rounded coordinates.\n",
    "    \"\"\"\n",
    "    if geometry.is_empty:\n",
    "        return geometry\n",
    "\n",
    "    # Function to round coordinates\n",
    "    def rounder(x, y, z=None):\n",
    "        if z is None:\n",
    "            return (round(x, decimal_places), round(y, decimal_places))\n",
    "        else:\n",
    "            return (round(x, decimal_places), round(y, decimal_places), round(z, decimal_places))\n",
    "\n",
    "    # Apply the rounding function using transform\n",
    "    return transform(rounder, geometry)\n",
    "\n",
    "def generate_wkt_outline(gdf, simplify_tolerance=None, decimal_places=2): #default values of none and 2\n",
    "    \"\"\"\n",
    "    Generate a WKT representation of a generalized outline for the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame containing the geometries.\n",
    "    - simplify_tolerance (float, optional): The tolerance for the simplify() method to reduce detail.\n",
    "    - decimal_places (int, optional): The number of decimal places to round the coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - str: The WKT representation of the generalized outline.\n",
    "    \"\"\"\n",
    "    # Create a unified geometry from all geometries in the GeoDataFrame\n",
    "    unified_geom = gdf.geometry.union_all()\n",
    "\n",
    "    # Use the convex hull to create a generalized outline\n",
    "    if not unified_geom.is_empty:\n",
    "        generalized_outline = unified_geom.convex_hull\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "    # Optionally simplify the outline for further generalization\n",
    "    if simplify_tolerance is not None:\n",
    "        generalized_outline = generalized_outline.simplify(simplify_tolerance)\n",
    "\n",
    "    # Round the coordinates of the outline\n",
    "    generalized_outline = round_coordinates(generalized_outline, decimal_places)\n",
    "\n",
    "    # Convert the resulting geometry to WKT using shapely's wkt module\n",
    "    if isinstance(generalized_outline, Polygon):\n",
    "        wkt_outline = generalized_outline.wkt\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "    return wkt_outline\n",
    "\n",
    "\n",
    "def generate_raster_wkt(bbox):\n",
    "    \"\"\"\n",
    "    Generate a WKT representation of a raster bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    - bbox (list): The bounding box as [left, bottom, right, top].\n",
    "\n",
    "    Returns:\n",
    "    - str: The WKT representation of the bounding box.\n",
    "    \"\"\"\n",
    "    left, bottom, right, top = bbox\n",
    "    # Create a rectangular polygon from the bounding box\n",
    "    rectangle = box(left, bottom, right, top)\n",
    "    # Return the WKT representation of the rectangle\n",
    "    return rectangle.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bae562a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to extract a variety of technical metadata values from the datasets\n",
    "\n",
    "def extract_metadata(directory, simplify_tolerance=None, include_wkt=True, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Extract metadata from geospatial datasets in a directory.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): The directory containing the datasets.\n",
    "    - simplify_tolerance (float, optional): Tolerance for simplifying WKT outlines.\n",
    "    - include_wkt (bool, optional): Whether to include the WKT outline in the metadata.\n",
    "    - decimal_places (int, optional): Number of decimal places to round WKT coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # List to hold metadata for each file\n",
    "    metadata = []\n",
    "\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {\n",
    "        '.shp': 'Shapefile',\n",
    "        '.geojson': 'GeoJSON'\n",
    "    }\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Get the file extension\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(root, filename)\n",
    "\n",
    "            # Get the name of the enclosing folder\n",
    "            folder_name = os.path.basename(os.path.dirname(filepath))\n",
    "            \n",
    "            # Calculate the total size of the folder in MB; can switch to KB\n",
    "            folder_size = get_folder_size(os.path.dirname(filepath), unit='MB')\n",
    "\n",
    "            # Check if the file is a recognized vector format\n",
    "            if file_ext in vector_formats:\n",
    "                try:\n",
    "                    # Read the vector file with GeoPandas\n",
    "                    gdf = gpd.read_file(filepath)\n",
    "\n",
    "                    # Get the original CRS\n",
    "                    original_crs = gdf.crs.to_string() if gdf.crs else 'Unknown'\n",
    "                    # Convert the original CRS to a resolvable URI if possible\n",
    "                    crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "                    # Reproject to WGS84 (EPSG:4326) if needed for bounding box calculation\n",
    "                    if gdf.crs and gdf.crs.to_string() != 'EPSG:4326':\n",
    "                        gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "                    # Calculate and round bounding box\n",
    "                    bounds = gdf.total_bounds if not gdf.empty else [None, None, None, None]\n",
    "                    rounded_bounds = [round(coord, 3) if coord is not None else None for coord in bounds]\n",
    "                    bbox = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "                    # Generate WKT outline if include_wkt is True\n",
    "                    wkt_outline = None\n",
    "                    if include_wkt:\n",
    "#                         wkt_outline = generate_wkt_outline(gdf, simplify_tolerance, decimal_places)\n",
    "                        wkt_outline = generate_wkt_outline(gdf, simplify_tolerance=0.001, decimal_places=2)\n",
    "\n",
    "                    # Process geometry type\n",
    "                    geometry_type = gdf.geom_type.unique()[0] if not gdf.empty else 'Unknown'\n",
    "                    if geometry_type != 'Unknown':\n",
    "                        geometry_type = geometry_type.replace(\"LineString\", \"Line\").replace(\"MultiPolygon\", \"Polygon\") + \" data\"\n",
    "\n",
    "                    # Extract metadata\n",
    "                    file_metadata = {\n",
    "                        column_mapping['filename']: filename,\n",
    "                        column_mapping['folder_name']: folder_name,\n",
    "                        column_mapping['crs']: crs_uri,\n",
    "                        column_mapping['file_format']: vector_formats[file_ext],\n",
    "                        column_mapping['geometry_type']: geometry_type,\n",
    "                        column_mapping['bounding_box']: bbox,\n",
    "                        column_mapping['folder_size']: str(folder_size) + \" MB\"\n",
    "                    }\n",
    "\n",
    "                    # Add the WKT outline to metadata if included\n",
    "                    if include_wkt:\n",
    "                        file_metadata[column_mapping['wkt_outline']] = wkt_outline\n",
    "\n",
    "                    # Add the metadata to the list\n",
    "                    metadata.append(file_metadata)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read vector file {filename}: {e}\")\n",
    "\n",
    "            \n",
    "            # Check if the file is a raster format (e.g., .tif)\n",
    "            elif file_ext == '.tif':\n",
    "                try:\n",
    "                    # Read the raster file with Rasterio\n",
    "                    with rasterio.open(filepath) as src:\n",
    "                        # Get the original CRS\n",
    "                        original_crs = src.crs.to_string() if src.crs else 'Unknown'\n",
    "                        crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "                        # Get the bounding box, handling both object and tuple cases\n",
    "                        bounds = src.bounds\n",
    "                        if isinstance(bounds, tuple):\n",
    "                            left, bottom, right, top = bounds\n",
    "                        else:\n",
    "                            left, bottom, right, top = bounds.left, bounds.bottom, bounds.right, bounds.top\n",
    "\n",
    "                        # Reproject the bounding box to WGS84 if needed\n",
    "                        if src.crs and src.crs.to_string() != 'EPSG:4326':\n",
    "                            from rasterio.warp import transform_bounds\n",
    "                            left, bottom, right, top = transform_bounds(src.crs, 'EPSG:4326', left, bottom, right, top)\n",
    "\n",
    "                        # Round bounding box coordinates\n",
    "                        rounded_bounds = [round(coord, 3) for coord in [left, bottom, right, top]]\n",
    "                        bbox = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "                        # Generate WKT outline if include_wkt is True\n",
    "                        wkt_outline = None\n",
    "                        if include_wkt:\n",
    "                            wkt_outline = generate_raster_wkt([left, bottom, right, top])                \n",
    "                        \n",
    "                        # Extract metadata\n",
    "                        file_metadata = {\n",
    "                            column_mapping['filename']: filename,\n",
    "                            column_mapping['folder_name']: folder_name,\n",
    "                            column_mapping['crs']: crs_uri,\n",
    "                            column_mapping['file_format']: 'GeoTIFF',\n",
    "                            column_mapping['geometry_type']: 'Raster data',\n",
    "                            column_mapping['bounding_box']: bbox,\n",
    "                            column_mapping['folder_size']: str(folder_size) + \" MB\"\n",
    "                        }\n",
    "                        \n",
    "                        # Add the WKT outline to metadata if included\n",
    "                        if include_wkt:\n",
    "                            file_metadata[column_mapping['wkt_outline']] = wkt_outline\n",
    "\n",
    "                        # Add the metadata to the list\n",
    "                        metadata.append(file_metadata)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read raster file {filename}: {e}\")\n",
    "            \n",
    "\n",
    "        # Additional check for geodatabases (folders with .gdb extension)\n",
    "        if root.endswith('.gdb'):\n",
    "            try:\n",
    "                folder_name = os.path.basename(os.path.dirname(root))\n",
    "                folder_size = get_folder_size(root, unit='MB')\n",
    "\n",
    "                # Try listing layers in the geodatabase\n",
    "                try:\n",
    "                    layers = gpd.io.file.fiona.listlayers(root)\n",
    "                    for layer in layers:\n",
    "                        # Read each layer\n",
    "                        gdf = gpd.read_file(root, layer=layer)\n",
    "\n",
    "                        # Get the original CRS\n",
    "                        original_crs = gdf.crs.to_string() if gdf.crs else 'Unknown'\n",
    "                        crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "                        # Reproject to WGS84 (EPSG:4326) if needed\n",
    "                        if gdf.crs and gdf.crs.to_string() != 'EPSG:4326':\n",
    "                            gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "                        # Calculate and round bounding box\n",
    "                        bounds = gdf.total_bounds if not gdf.empty else [None, None, None, None]\n",
    "                        rounded_bounds = [round(coord, 3) if coord is not None else None for coord in bounds]\n",
    "                        bbox = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "                        # Generate WKT outline if include_wkt is True\n",
    "                        wkt_outline = None\n",
    "                        if include_wkt:\n",
    "                            wkt_outline = generate_wkt_outline(gdf, simplify_tolerance, decimal_places)\n",
    "\n",
    "                        # Process geometry type\n",
    "                        geometry_type = gdf.geom_type.unique()[0] if not gdf.empty else 'Unknown'\n",
    "                        if geometry_type != 'Unknown':\n",
    "                            geometry_type = geometry_type.replace(\"LineString\", \"Line\").replace(\"MultiPolygon\", \"Polygon\") + \" data\"\n",
    "\n",
    "                        # Extract metadata\n",
    "                        file_metadata = {\n",
    "                            column_mapping['filename']: f\"{os.path.basename(root)} - {layer}\",\n",
    "                            column_mapping['folder_name']: folder_name,\n",
    "                            column_mapping['crs']: crs_uri,\n",
    "                            column_mapping['file_format']: 'Geodatabase',\n",
    "                            column_mapping['geometry_type']: geometry_type,\n",
    "                            column_mapping['bounding_box']: bbox,\n",
    "                            column_mapping['folder_size']: str(folder_size) + \" MB\"\n",
    "                        }\n",
    "\n",
    "                        # Add the WKT outline to metadata if included\n",
    "                        if include_wkt:\n",
    "                            file_metadata[column_mapping['wkt_outline']] = wkt_outline\n",
    "\n",
    "                        # Add the metadata to the list\n",
    "                        metadata.append(file_metadata)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read geodatabase {root}: {e}\")\n",
    "                    # Fill in default values for the geodatabase metadata\n",
    "                    file_metadata = {\n",
    "                        column_mapping['filename']: os.path.basename(root),\n",
    "                        column_mapping['folder_name']: folder_name,\n",
    "                        column_mapping['crs']: '',\n",
    "                        column_mapping['file_format']: '',\n",
    "                        column_mapping['geometry_type']: '',\n",
    "                        column_mapping['bounding_box']: '',\n",
    "                        column_mapping['folder_size']: str(folder_size) + \" MB\"\n",
    "                    }\n",
    "\n",
    "                    # Add the WKT outline column as 'None' if included\n",
    "                    if include_wkt:\n",
    "                        file_metadata[column_mapping['wkt_outline']] = ''\n",
    "\n",
    "                    # Add the default metadata to the list\n",
    "                    metadata.append(file_metadata)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error with geodatabase {root}: {e}\")\n",
    "\n",
    "\n",
    "    # Convert the metadata list to a DataFrame\n",
    "    df = pd.DataFrame(metadata)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_csv = os.path.join(directory, 'geospatial_metadata.csv')\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f'Metadata extraction complete. CSV saved to {output_csv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48fcff",
   "metadata": {},
   "source": [
    "### Executing the code for Part 1\n",
    "\n",
    "Run option 1 to process the metadata without extracting the WKT polygon outline\n",
    "    Run option 2 to obtain the outline. Review the simplify_tolerance value and update if needed. `.01` can be used for decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c150e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 Exclude WKT outline from the metadata\n",
    "extract_metadata(root_directory, include_wkt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db3baa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majew030/opt/anaconda3/envs/notebooks/lib/python3.10/site-packages/pyogrio/raw.py:196: UserWarning: Measured (M) geometry types are not supported. Original type 'PointM' is converted to 'Point'\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read geodatabase data/Building_Footprints_Microsoft/Building_Footprints_Microsoft_IN.gdb: 'NoneType' object has no attribute 'listlayers'\n",
      "Could not read geodatabase data/Boundaries_Miscellaneous_IGIO/County_Government_Boundaries_IGIO_IN_Apr2018.gdb: 'NoneType' object has no attribute 'listlayers'\n",
      "Metadata extraction complete. CSV saved to data/geospatial_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Include WKT outline in the metadata\n",
    "extract_metadata(root_directory, simplify_tolerance=.001, include_wkt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a13c5a",
   "metadata": {},
   "source": [
    "## Part 2: Attribute Tables\n",
    "\n",
    "This function will read the attribute table fields and write them to a CSV in a defined directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecf281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attribute_table_info(root_directory, output_dir):\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {\n",
    "        '.shp': 'Shapefile',\n",
    "        '.geojson': 'GeoJSON'\n",
    "    }\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, _, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            # Get the file extension\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(root, filename)\n",
    "\n",
    "            # Check if the file is a recognized vector format\n",
    "            if file_ext in vector_formats:\n",
    "                try:\n",
    "                    # Read the vector file with GeoPandas\n",
    "                    gdf = gpd.read_file(filepath)\n",
    "\n",
    "                    # Extract field information\n",
    "                    field_info = []\n",
    "                    for column in gdf.columns:\n",
    "                        field_metadata = {\n",
    "                            'Field Name': column,\n",
    "                            'Data Type': str(gdf[column].dtype),\n",
    "                            'Unique Values': gdf[column].nunique(),\n",
    "                            'Null Values': gdf[column].isnull().sum(),\n",
    "                            'Definition' : '',\n",
    "                            'Definition Source' : ''\n",
    "                        }\n",
    "                        field_info.append(field_metadata)\n",
    "\n",
    "                    # Convert the field information to a DataFrame\n",
    "                    field_df = pd.DataFrame(field_info)\n",
    "\n",
    "                    # Create the output CSV filename\n",
    "                    output_csv = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_fields.csv\")\n",
    "\n",
    "                    # Save the DataFrame to a CSV file\n",
    "                    field_df.to_csv(output_csv, index=False)\n",
    "\n",
    "#                     print(f\"Field information extracted for {filename}. CSV saved to {output_csv}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a7e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attribute table information\n",
    "extract_attribute_table_info(root_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61d261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
