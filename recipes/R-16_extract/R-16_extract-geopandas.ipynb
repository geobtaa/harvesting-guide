{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58e54c7",
   "metadata": {},
   "source": [
    "# Extract technical metadata\n",
    "\n",
    "This recipe will extract technical metadata from a directory of datasets and export it to a CSV file. It requires the python libraries `pandas`, `geopandas`, and `rasterio`. Part 1 writes the filenames, coordinate reference system, file format, resource type, and (optionally) the WKT polygon outline. Part 2 creates CSV files of the attribute table field names and types.\n",
    "\n",
    "Created 2024-10-18 by Karen Majewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bcf5cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.warp import transform_bounds\n",
    "from shapely.geometry import Polygon, MultiPolygon, box\n",
    "from shapely.ops import transform\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27766c8",
   "metadata": {},
   "source": [
    "## Part 1: Extract metadata to a CSV\n",
    "\n",
    "### Setup CSV and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "8f5fadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from variable names to desired column headers\n",
    "column_mapping = {\n",
    "    'folder_name': 'Folder Name',\n",
    "    'filename': 'File Name',\n",
    "    'crs': 'Conforms To',\n",
    "    'file_format': 'Format',\n",
    "    \"total_area_km2\": 'Extent',\n",
    "    'spatial_resolution': 'Spatial Resolution',\n",
    "    'geometry_type': 'Resource Type',\n",
    "    'bounding_box': 'Bounding Box',\n",
    "    'wkt_outline': 'Geometry',\n",
    "    'folder_size': 'File Size'\n",
    "    \n",
    "}\n",
    "\n",
    "# Define global variables for the script\n",
    "root_directory = 'landuse-1973'\n",
    "output_csv = 'landuse.csv'\n",
    "decimal_places = 2\n",
    "\n",
    "# Turn calculation of the Geometry (WKT Outline) to True or False. \n",
    "# Complex shapes will have too many vertices to be useful. \n",
    "\n",
    "simplify_tolerance = 50\n",
    "include_wkt = False\n",
    "\n",
    "\n",
    "# Define the output directory for the attribute table CSV files\n",
    "output_directory = 'parcel_codebooks'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22227105",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "### File size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "fbb611c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add up the files in each dataset folder\n",
    "\n",
    "def get_folder_size(folder_path, unit='MB', decimal_places=3):\n",
    "    \"\"\"\n",
    "    Calculate the total size of all files in a folder and return it in the specified unit.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder.\n",
    "    - unit (str): The unit for the size ('bytes', 'KB', 'MB'). Default is 'MB'.\n",
    "    - decimal_places (int): The number of decimal places to round the size to. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    - float: Total size of the folder contents in the specified unit, rounded to the specified number of decimal places.\n",
    "    \"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # Add to the total size only if it is a file (not a broken link, etc.)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    # Convert the total size to the specified unit\n",
    "    if unit == 'KB':\n",
    "        total_size /= 1024  # Convert bytes to kilobytes\n",
    "    elif unit == 'MB':\n",
    "        total_size /= (1024 * 1024)  # Convert bytes to megabytes\n",
    "\n",
    "    # Round the total size to the specified number of decimal places\n",
    "    rounded_size = round(total_size, decimal_places)\n",
    "    return rounded_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62c94c",
   "metadata": {},
   "source": [
    "### Geometry type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e8023360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_geometry_type(data, is_raster=False):\n",
    "    \"\"\"\n",
    "    Determine the geometry type of a GeoDataFrame or indicate if the dataset is a raster.\n",
    "\n",
    "    Parameters:\n",
    "    - data (GeoDataFrame or DatasetReader): The data source, which can be a GeoDataFrame for vector data or DatasetReader for raster.\n",
    "    - is_raster (bool): Flag to indicate if the data source is a raster.\n",
    "\n",
    "    Returns:\n",
    "    - str: The geometry type description, or 'Unknown' if the geometry type cannot be determined.\n",
    "    \"\"\"\n",
    "    if is_raster:\n",
    "        return \"Raster data\"\n",
    "\n",
    "    if data.empty or data.geometry.is_empty.all():\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Get unique geometry types in the GeoDataFrame\n",
    "        geometry_types = data.geom_type.unique()\n",
    "\n",
    "        # Format the geometry type for output\n",
    "        if len(geometry_types) == 1:\n",
    "            # Single geometry type\n",
    "            geometry_type = geometry_types[0].replace(\"LineString\", \"Line\").replace(\"MultiPolygon\", \"Polygon\")\n",
    "        else:\n",
    "            # Mixed geometry types\n",
    "            geometry_type = \"Mixed geometries\"\n",
    "\n",
    "        return f\"{geometry_type} data\"\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to determine geometry type: {e}\")\n",
    "        return 'Unknown'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0a43e",
   "metadata": {},
   "source": [
    "### Report original CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c157507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reformat the CRS into a resolvable URI\n",
    "\n",
    "def format_crs_uri(crs_string):\n",
    "    # If the CRS is in the \"EPSG:xxxx\" format, convert it to a resolvable URI\n",
    "    if crs_string and crs_string.startswith(\"EPSG:\"):\n",
    "        epsg_code = crs_string.split(\":\")[1]\n",
    "        return f\"https://epsg.io/{epsg_code}\"\n",
    "    else:\n",
    "        # Return the original CRS string if it's not an EPSG code\n",
    "        return crs_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54400b40",
   "metadata": {},
   "source": [
    "### Rounding function (check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0d0a1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_coordinates(geometry, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Round the coordinates of a geometry to the specified number of decimal places.\n",
    "\n",
    "    Parameters:\n",
    "    - geometry (Geometry): The input Shapely geometry.\n",
    "    - decimal_places (int): Number of decimal places to round to.\n",
    "\n",
    "    Returns:\n",
    "    - Geometry: The geometry with rounded coordinates.\n",
    "    \"\"\"\n",
    "    if geometry.is_empty:\n",
    "        return geometry\n",
    "\n",
    "    # Function to round coordinates\n",
    "    def rounder(x, y, z=None):\n",
    "        if z is None:\n",
    "            return (round(x, decimal_places), round(y, decimal_places))\n",
    "        else:\n",
    "            return (round(x, decimal_places), round(y, decimal_places), round(z, decimal_places))\n",
    "\n",
    "    # Apply the rounding function using transform\n",
    "    return transform(rounder, geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef278ad",
   "metadata": {},
   "source": [
    "### Bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "25a2dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTOR \n",
    "\n",
    "def calculate_bounding_box(gdf, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Calculate and format the bounding box for a GeoDataFrame in WGS84 (EPSG:4326).\n",
    "    \n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame to process.\n",
    "    - decimal_places (int, optional): Number of decimal places to round coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted bounding box as a string.\n",
    "    \"\"\"\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Convert to WGS84 for bounding box calculation\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "        bounds = gdf.total_bounds\n",
    "        rounded_bounds = [round(coord, decimal_places) for coord in bounds]\n",
    "        return f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "    except Exception:\n",
    "        return 'Unknown'\n",
    "\n",
    "\n",
    "# RASTER\n",
    "\n",
    "def calculate_bounding_box_raster(src, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Calculate the bounding box and WKT outline for a raster file in WGS84 (EPSG:4326).\n",
    "    \n",
    "    Parameters:\n",
    "    - src (rasterio.io.DatasetReader): The raster source.\n",
    "    - decimal_places (int, optional): Number of decimal places to round coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the formatted bounding box as a string and the WKT representation of the bounding box.\n",
    "    \"\"\"\n",
    "    if src.crs is None:\n",
    "        return 'Unknown', 'None'\n",
    "\n",
    "    try:\n",
    "        # Reproject the bounding box to WGS84 if needed\n",
    "        left, bottom, right, top = src.bounds\n",
    "        if src.crs.to_string() != 'EPSG:4326':\n",
    "            left, bottom, right, top = transform_bounds(src.crs, 'EPSG:4326', left, bottom, right, top)\n",
    "\n",
    "        # Round the coordinates\n",
    "        rounded_bounds = [round(coord, decimal_places) for coord in [left, bottom, right, top]]\n",
    "        bbox_str = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "        # Create WKT for a Polygon representing the bounding box\n",
    "        wkt_outline = f\"POLYGON(({rounded_bounds[0]} {rounded_bounds[1]}, {rounded_bounds[0]} {rounded_bounds[3]}, \" \\\n",
    "                      f\"{rounded_bounds[2]} {rounded_bounds[3]}, {rounded_bounds[2]} {rounded_bounds[1]}, \" \\\n",
    "                      f\"{rounded_bounds[0]} {rounded_bounds[1]}))\"\n",
    "\n",
    "        return bbox_str, wkt_outline\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate bounding box and WKT outline: {e}\")\n",
    "        return 'Unknown', 'None'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b8716",
   "metadata": {},
   "source": [
    "### Geometry (WKT Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "014ca5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wkt_outline(gdf, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Generate a WKT representation of a generalized outline for the dataset.\n",
    "    \"\"\"\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'missing CRS'\n",
    "\n",
    "    try:\n",
    "        global simplify_tolerance\n",
    "\n",
    "        # Convert to WGS84 for WKT generation\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "        logging.info(\"Converted GeoDataFrame to EPSG:4326.\")\n",
    "\n",
    "        # Create a unified geometry from all geometries in the GeoDataFrame\n",
    "        unified_geom = gdf.geometry.union_all()\n",
    "        logging.info(f\"Unified geometry type: {type(unified_geom)}\")\n",
    "\n",
    "        # Count vertices before simplification\n",
    "        num_vertices_before = count_vertices(unified_geom)\n",
    "        logging.info(f\"Number of vertices before simplification: {num_vertices_before}\")\n",
    "\n",
    "        # Simplify the outline using the global simplify_tolerance\n",
    "        if simplify_tolerance is not None:\n",
    "            generalized_outline = unified_geom.simplify(simplify_tolerance, preserve_topology=True)\n",
    "            logging.info(f\"Simplified geometry with tolerance {simplify_tolerance}.\")\n",
    "        else:\n",
    "            generalized_outline = unified_geom\n",
    "\n",
    "        # Count vertices after simplification\n",
    "        num_vertices_after = count_vertices(generalized_outline)\n",
    "        logging.info(f\"Number of vertices after simplification: {num_vertices_after}\")\n",
    "\n",
    "        # Round the coordinates of the outline\n",
    "        generalized_outline = round_coordinates(generalized_outline, decimal_places)\n",
    "        logging.info(\"Rounded coordinates of the generalized outline.\")\n",
    "\n",
    "        # Convert the resulting geometry to WKT\n",
    "        if isinstance(generalized_outline, (Polygon, MultiPolygon)):\n",
    "            wkt_outline = generalized_outline.wkt\n",
    "            logging.info(\"Generated WKT outline.\")\n",
    "        else:\n",
    "            logging.warning(\"Generalized outline is not a Polygon or MultiPolygon.\")\n",
    "            return ''\n",
    "\n",
    "        return wkt_outline\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate WKT outline: {e}\")\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5552d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vertices(geometry):\n",
    "    \"\"\"\n",
    "    Count the number of vertices in a geometry.\n",
    "\n",
    "    Parameters:\n",
    "    - geometry (Geometry): The input Shapely geometry.\n",
    "\n",
    "    Returns:\n",
    "    - int: The number of vertices.\n",
    "    \"\"\"\n",
    "    if geometry.is_empty:\n",
    "        return 0\n",
    "    if isinstance(geometry, Polygon):\n",
    "        return len(geometry.exterior.coords)\n",
    "    elif isinstance(geometry, MultiPolygon):\n",
    "        return sum(len(polygon.exterior.coords) for polygon in geometry.geoms)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "75322f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_wkt_outline(gdf, decimal_places=2):\n",
    "#     \"\"\"\n",
    "#     Generate a WKT representation of a generalized outline for the dataset.\n",
    "\n",
    "#     Parameters:\n",
    "#     - gdf (GeoDataFrame): The GeoDataFrame containing the geometries.\n",
    "#     - simplify_tolerance (float, optional): The tolerance for the simplify() method to reduce detail.\n",
    "#     - decimal_places (int, optional): The number of decimal places to round the coordinates.\n",
    "\n",
    "#     Returns:\n",
    "#     - str: The WKT representation of the generalized outline.\n",
    "#     \"\"\"\n",
    "#     if gdf.empty or gdf.crs is None:\n",
    "#         return 'None'\n",
    "\n",
    "#     try:\n",
    "#         global simplify_tolerance\n",
    "#         # Convert to WGS84 for WKT generation\n",
    "#         gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "#         # Create a unified geometry from all geometries in the GeoDataFrame\n",
    "#         unified_geom = gdf.geometry.union_all()\n",
    "\n",
    "#         # Use the convex hull to create a generalized outline\n",
    "#         if not unified_geom.is_empty:\n",
    "#             generalized_outline = unified_geom.convex_hull\n",
    "#         else:\n",
    "#             return 'None'\n",
    "\n",
    "#         # Optionally simplify the outline for further generalization\n",
    "#         if simplify_tolerance is not None:\n",
    "#             generalized_outline = generalized_outline.simplify(simplify_tolerance)\n",
    "\n",
    "#         # Round the coordinates of the outline\n",
    "#         generalized_outline = round_coordinates(generalized_outline, decimal_places)\n",
    "\n",
    "#         # Convert the resulting geometry to WKT using shapely's wkt module\n",
    "#         if isinstance(generalized_outline, Polygon):\n",
    "#             wkt_outline = generalized_outline.wkt\n",
    "#         else:\n",
    "#             return 'None'\n",
    "\n",
    "#         return wkt_outline\n",
    "#     except Exception:\n",
    "#         return 'None'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce00478",
   "metadata": {},
   "source": [
    "### Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a6af68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area using bounding box\n",
    "\n",
    "def calculate_total_area(gdf):\n",
    "    \"\"\"\n",
    "    Calculate the total area covered by a GeoDataFrame in square kilometers using an equal-area projection.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame to process.\n",
    "\n",
    "    Returns:\n",
    "    - float or str: The total area in square kilometers, or '' if unavailable.\n",
    "    \"\"\"\n",
    "\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return ''\n",
    "\n",
    "    try:\n",
    "        # Calculate the area using the bounding box as an approximation\n",
    "        bounds = gdf.total_bounds  # [minx, miny, maxx, maxy]\n",
    "        bbox_polygon = box(*bounds)\n",
    "        bbox_gdf = gpd.GeoDataFrame({'geometry': [bbox_polygon]}, crs=gdf.crs)\n",
    "\n",
    "        # Reproject to an equal-area projection for accurate area calculation\n",
    "        bbox_gdf = bbox_gdf.to_crs(epsg=6933)\n",
    "        total_area_km2 = bbox_gdf.geometry.area.sum() / 1e6  # Convert to square kilometers\n",
    "\n",
    "        return round(total_area_km2, 3)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to calculate total area: {e}\")\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44f505",
   "metadata": {},
   "source": [
    "### Walk through the files and extract metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2521e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata():\n",
    "    \"\"\"\n",
    "    Extract metadata from geospatial datasets in a directory.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary of lists for metadata\n",
    "    metadata = {\n",
    "        'filename': [],\n",
    "        'folder_name': [],\n",
    "        'crs': [],\n",
    "        'file_format': [],\n",
    "        'geometry_type': [],\n",
    "        'bounding_box': [],\n",
    "        'total_area_km2': [],\n",
    "        'spatial_resolution': [],\n",
    "        'folder_size': [],\n",
    "        'wkt_outline': []\n",
    "    }\n",
    "\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {\n",
    "        '.shp': 'Shapefile',\n",
    "        '.geojson': 'GeoJSON'\n",
    "    }\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "            filepath = os.path.join(root, filename)\n",
    "            folder_name = os.path.basename(os.path.dirname(filepath))\n",
    "            folder_size = get_folder_size(os.path.dirname(filepath), unit='MB')\n",
    "\n",
    "            # Vector Data Processing\n",
    "            if file_ext in vector_formats:\n",
    "                process_vector(filepath, filename, vector_formats[file_ext], folder_name, folder_size, metadata, decimal_places)\n",
    "\n",
    "\n",
    "            # Raster Data Processing\n",
    "            elif file_ext == '.tif':\n",
    "                process_raster(filepath, filename, folder_name, folder_size, metadata, decimal_places)\n",
    "\n",
    "            # Identify GeoPackages and record their name and size\n",
    "            elif file_ext == '.gpkg':\n",
    "                # Record basic metadata for the GeoPackage\n",
    "                metadata['filename'].append(filename)\n",
    "                metadata['folder_name'].append(folder_name)\n",
    "                metadata['crs'].append('')\n",
    "                metadata['file_format'].append('GeoPackage')\n",
    "                metadata['geometry_type'].append('')\n",
    "                metadata['bounding_box'].append('')\n",
    "                metadata['total_area_km2'].append('')\n",
    "                metadata['spatial_resolution'].append('')\n",
    "                metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "                metadata['wkt_outline'].append('')\n",
    "\n",
    "        # Geodatabase Detection (directories with .gdb)\n",
    "        for dir_name in dirs:\n",
    "            if dir_name.endswith('.gdb'):\n",
    "                gdb_path = os.path.join(root, dir_name)\n",
    "                folder_name = os.path.basename(os.path.dirname(gdb_path))\n",
    "                folder_size = get_folder_size(gdb_path, unit='MB')\n",
    "\n",
    "                # Record basic metadata for the geodatabase\n",
    "                metadata['filename'].append(dir_name)\n",
    "                metadata['folder_name'].append(folder_name)\n",
    "                metadata['crs'].append('')\n",
    "                metadata['file_format'].append('Geodatabase')\n",
    "                metadata['geometry_type'].append('')\n",
    "                metadata['bounding_box'].append('')\n",
    "                metadata['total_area_km2'].append('')\n",
    "                metadata['spatial_resolution'].append('')\n",
    "                metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "                metadata['wkt_outline'].append('')\n",
    "\n",
    "    # Convert metadata dictionary to DataFrame and save as CSV\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(metadata)\n",
    "\n",
    "    # Rename columns using column_mapping\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "    # Save the DataFrame as CSV\n",
    "    output_csv_path = os.path.join(root_directory, output_csv)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Metadata extraction complete. CSV saved to {output_csv_path}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0e3cfb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vector(filepath, filename, file_format, folder_name, folder_size, metadata, decimal_places):\n",
    "    global include_wkt\n",
    "    try:\n",
    "        logging.info(f\"Processing vector file {filename}\")\n",
    "        gdf = gpd.read_file(filepath)\n",
    "\n",
    "        # Handle CRS\n",
    "        if gdf.crs is None:\n",
    "            logging.warning(f\"Dataset {filename} has no CRS. Spatial calculations may be inaccurate.\")\n",
    "            # Assign a known CRS if you have one, or leave as ''\n",
    "            gdf.crs = 'EPSG:26916'  # Replace with the correct CRS if known\n",
    "            crs_uri = format_crs_uri(gdf.crs)\n",
    "            logging.info(f\"Assigned CRS {gdf.crs} to dataset {filename}\")\n",
    "        else:\n",
    "            original_crs = gdf.crs.to_string()\n",
    "            crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "        # Calculate metadata components\n",
    "        bbox = calculate_bounding_box(gdf, decimal_places)\n",
    "        if include_wkt:\n",
    "            wkt_outline = generate_wkt_outline(gdf, decimal_places)\n",
    "        else:\n",
    "            wkt_outline = ''\n",
    "        total_area_km2 = calculate_total_area(gdf)\n",
    "\n",
    "        # Process geometry type\n",
    "        geometry_type = process_geometry_type(gdf)\n",
    "\n",
    "        # Store metadata directly into the dictionary of lists\n",
    "        metadata['filename'].append(filename)\n",
    "        metadata['folder_name'].append(folder_name)\n",
    "        metadata['crs'].append(crs_uri)\n",
    "        metadata['file_format'].append(file_format)\n",
    "        metadata['geometry_type'].append(geometry_type)\n",
    "        metadata['bounding_box'].append(bbox)\n",
    "        metadata['total_area_km2'].append(total_area_km2)\n",
    "        metadata['spatial_resolution'].append('')\n",
    "        metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "        metadata['wkt_outline'].append(wkt_outline)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not process vector file {filename}: {e}\")\n",
    "        append_empty_metadata(metadata, filename, folder_name, file_format, folder_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "308d4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raster(filepath, filename, folder_name, folder_size, metadata, decimal_places):\n",
    "    global include_wkt\n",
    "    try:\n",
    "        with rasterio.open(filepath) as src:\n",
    "            if src.crs is None:\n",
    "                logging.warning(f\"Raster dataset {filename} has no CRS. Spatial calculations may be inaccurate.\")\n",
    "                crs_uri = 'Unknown'\n",
    "            else:\n",
    "                original_crs = src.crs.to_string()\n",
    "                crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "            # Calculate spatial resolution and area\n",
    "            pixel_size_x, pixel_size_y = src.res\n",
    "            spatial_resolution = round((abs(pixel_size_x) + abs(pixel_size_y)) / 2, 2)\n",
    "            total_area_km2 = calculate_total_area_raster(src)\n",
    "\n",
    "            # Get bounding box and WKT outline\n",
    "            bbox, wkt_outline = calculate_bounding_box_raster(src, decimal_places)\n",
    "\n",
    "            # Store metadata directly into the dictionary of lists\n",
    "            metadata['filename'].append(filename)\n",
    "            metadata['folder_name'].append(folder_name)\n",
    "            metadata['crs'].append(crs_uri)\n",
    "            metadata['file_format'].append('GeoTIFF')\n",
    "            metadata['geometry_type'].append('Raster data')\n",
    "            metadata['bounding_box'].append(bbox)\n",
    "            metadata['total_area_km2'].append(total_area_km2)\n",
    "            metadata['spatial_resolution'].append(spatial_resolution)\n",
    "            metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "            metadata['wkt_outline'].append(wkt_outline if include_wkt else None)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not read raster file {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "04c3a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_geodatabase(root, folder_name, folder_size, metadata):\n",
    "    \"\"\"\n",
    "    Process a geodatabase to extract metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - root (str): The path to the geodatabase.\n",
    "    - folder_name (str): The name of the folder containing the geodatabase.\n",
    "    - folder_size (float): The size of the folder in MB.\n",
    "    - metadata (dict): The dictionary to store metadata for all files.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    geodatabase_name = os.path.basename(root)\n",
    "    \n",
    "    # Record basic metadata for the geodatabase\n",
    "    metadata['filename'].append(geodatabase_name)\n",
    "    metadata['folder_name'].append(folder_name)\n",
    "    metadata['file_format'].append('Geodatabase')\n",
    "    metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "    \n",
    "    # Leave fields empty as spatial processing is no longer required\n",
    "    metadata['crs'].append('')\n",
    "    metadata['geometry_type'].append('')\n",
    "    metadata['bounding_box'].append('')\n",
    "    metadata['total_area_km2'].append('')\n",
    "    metadata['spatial_resolution'].append('')\n",
    "    metadata['wkt_outline'].append('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1129b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_empty_metadata(metadata, filename, folder_name, file_format, folder_size):\n",
    "    metadata['filename'].append(filename)\n",
    "    metadata['folder_name'].append(folder_name)\n",
    "    metadata['crs'].append('')\n",
    "    metadata['file_format'].append(file_format)\n",
    "    metadata['geometry_type'].append('')\n",
    "    metadata['bounding_box'].append('')\n",
    "    metadata['total_area_km2'].append('')\n",
    "    metadata['spatial_resolution'].append('')\n",
    "    metadata['folder_size'].append(f\"{folder_size} MB\")\n",
    "    metadata['wkt_outline'].append('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e8478",
   "metadata": {},
   "source": [
    "### Executing the code for Part 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6edf7efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Processing vector file allelu73.shp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata extraction complete. CSV saved to landuse-1973/landuse.csv\n"
     ]
    }
   ],
   "source": [
    "extract_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140b4b5",
   "metadata": {},
   "source": [
    "## Part 2: Attribute Tables\n",
    "\n",
    "This function will read the attribute table fields and write them to a CSV in a defined directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "919eff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attribute_table_info(root_directory, output_dir):\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {\n",
    "        '.shp': 'Shapefile',\n",
    "        '.geojson': 'GeoJSON'\n",
    "    }\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, _, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            # Get the file extension\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(root, filename)\n",
    "\n",
    "            # Check if the file is a recognized vector format\n",
    "            if file_ext in vector_formats:\n",
    "                try:\n",
    "                    # Read the vector file with GeoPandas\n",
    "                    gdf = gpd.read_file(filepath)\n",
    "\n",
    "                    # Extract field information\n",
    "                    field_info = []\n",
    "                    for column in gdf.columns:\n",
    "                        field_metadata = {\n",
    "                            'Field Name': column,\n",
    "                            'Data Type': str(gdf[column].dtype),\n",
    "                            'Unique Values': gdf[column].nunique(),\n",
    "                            'Null Values': gdf[column].isnull().sum(),\n",
    "                            'Definition' : '',\n",
    "                            'Definition Source' : ''\n",
    "                        }\n",
    "                        field_info.append(field_metadata)\n",
    "\n",
    "                    # Convert the field information to a DataFrame\n",
    "                    field_df = pd.DataFrame(field_info)\n",
    "\n",
    "                    # Create the output CSV filename\n",
    "                    output_csv = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_fields.csv\")\n",
    "\n",
    "                    # Save the DataFrame to a CSV file\n",
    "                    field_df.to_csv(output_csv, index=False)\n",
    "\n",
    "                    print(f\"Field information extracted for {filename}. CSV saved to {output_csv}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "362a409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attribute table information\n",
    "extract_attribute_table_info(root_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1e097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
