{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6328f1",
   "metadata": {},
   "source": [
    "# Extract technical metadata\n",
    "\n",
    "This recipe will extract technical metadata from a directory of datasets and export it to a CSV file. It requires the python libraries `pandas`, `geopandas`, and `rasterio`. Part 1 writes the filenames, coordinate reference system, file format, resource type, and (optionally) the WKT polygon outline. Part 2 creates CSV files of the attribute table field names and types.\n",
    "\n",
    "Created 2024-10-18 by Karen Majewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3703769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f049a29",
   "metadata": {},
   "source": [
    "## Part 1: Extract metadata to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from variable names to desired column headers\n",
    "column_mapping = {\n",
    "    'folder_name': 'Folder Name',\n",
    "    'filename': 'File Name',\n",
    "    'crs': 'Conforms To',\n",
    "    'file_format': 'Format',\n",
    "    'geometry_type': 'Resource Type',\n",
    "    'bounding_box': 'Bounding Box',\n",
    "    'wkt_outline': 'Geometry',\n",
    "    'folder_size': 'File Size'\n",
    "}\n",
    "\n",
    "# Define the root directory for the geospatial data\n",
    "root_directory = 'data'\n",
    "\n",
    "# Define the output directory for the attribute table CSV files\n",
    "output_directory = 'codebooks'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a5034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add up the files in each dataset folder\n",
    "\n",
    "def get_folder_size(folder_path, unit='MB', decimal_places=3):\n",
    "    \"\"\"\n",
    "    Calculate the total size of all files in a folder and return it in the specified unit.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder.\n",
    "    - unit (str): The unit for the size ('bytes', 'KB', 'MB'). Default is 'MB'.\n",
    "    - decimal_places (int): The number of decimal places to round the size to. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    - float: Total size of the folder contents in the specified unit, rounded to the specified number of decimal places.\n",
    "    \"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # Add to the total size only if it is a file (not a broken link, etc.)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    # Convert the total size to the specified unit\n",
    "    if unit == 'KB':\n",
    "        total_size /= 1024  # Convert bytes to kilobytes\n",
    "    elif unit == 'MB':\n",
    "        total_size /= (1024 * 1024)  # Convert bytes to megabytes\n",
    "\n",
    "    # Round the total size to the specified number of decimal places\n",
    "    rounded_size = round(total_size, decimal_places)\n",
    "    return rounded_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b356b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reformat the CRS into a resolvable URI\n",
    "\n",
    "def format_crs_uri(crs_string):\n",
    "    # If the CRS is in the \"EPSG:xxxx\" format, convert it to a resolvable URI\n",
    "    if crs_string and crs_string.startswith(\"EPSG:\"):\n",
    "        epsg_code = crs_string.split(\":\")[1]\n",
    "        return f\"https://epsg.io/{epsg_code}\"\n",
    "    else:\n",
    "        # Return the original CRS string if it's not an EPSG code\n",
    "        return crs_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to create Geometry values (WKT polygon outlines)\n",
    "\n",
    "def round_coordinates(geometry, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Round the coordinates of a geometry to the specified number of decimal places.\n",
    "\n",
    "    Parameters:\n",
    "    - geometry (Geometry): The input Shapely geometry.\n",
    "    - decimal_places (int): Number of decimal places to round to.\n",
    "\n",
    "    Returns:\n",
    "    - Geometry: The geometry with rounded coordinates.\n",
    "    \"\"\"\n",
    "    if geometry.is_empty:\n",
    "        return geometry\n",
    "\n",
    "    # Function to round coordinates\n",
    "    def rounder(x, y, z=None):\n",
    "        if z is None:\n",
    "            return (round(x, decimal_places), round(y, decimal_places))\n",
    "        else:\n",
    "            return (round(x, decimal_places), round(y, decimal_places), round(z, decimal_places))\n",
    "\n",
    "    # Apply the rounding function using transform\n",
    "    return transform(rounder, geometry)\n",
    "\n",
    "def generate_wkt_outline(gdf, simplify_tolerance=None, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Generate a WKT representation of a generalized outline for the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame containing the geometries.\n",
    "    - simplify_tolerance (float, optional): The tolerance for the simplify() method to reduce detail.\n",
    "    - decimal_places (int, optional): The number of decimal places to round the coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - str: The WKT representation of the generalized outline.\n",
    "    \"\"\"\n",
    "    # Create a unified geometry from all geometries in the GeoDataFrame\n",
    "    unified_geom = gdf.geometry.union_all()\n",
    "\n",
    "    # Use the convex hull to create a generalized outline\n",
    "    if not unified_geom.is_empty:\n",
    "        generalized_outline = unified_geom.convex_hull\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "    # Optionally simplify the outline for further generalization\n",
    "    if simplify_tolerance is not None:\n",
    "        generalized_outline = generalized_outline.simplify(simplify_tolerance)\n",
    "\n",
    "    # Round the coordinates of the outline\n",
    "    generalized_outline = round_coordinates(generalized_outline, decimal_places)\n",
    "\n",
    "    # Convert the resulting geometry to WKT using shapely's wkt module\n",
    "    if isinstance(generalized_outline, Polygon):\n",
    "        wkt_outline = generalized_outline.wkt\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "    return wkt_outline\n",
    "\n",
    "\n",
    "def generate_raster_wkt(bbox):\n",
    "    \"\"\"\n",
    "    Generate a WKT representation of a raster bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    - bbox (list): The bounding box as [left, bottom, right, top].\n",
    "\n",
    "    Returns:\n",
    "    - str: The WKT representation of the bounding box.\n",
    "    \"\"\"\n",
    "    left, bottom, right, top = bbox\n",
    "    # Create a rectangular polygon from the bounding box\n",
    "    rectangle = box(left, bottom, right, top)\n",
    "    # Return the WKT representation of the rectangle\n",
    "    return rectangle.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a061dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to extract a variety of technical metadata values from the datasets\n",
    "\n",
    "def extract_metadata(directory, simplify_tolerance=None, include_wkt=True, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Extract metadata from geospatial datasets in a directory.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): The directory containing the datasets.\n",
    "    - simplify_tolerance (float, optional): Tolerance for simplifying WKT outlines.\n",
    "    - include_wkt (bool, optional): Whether to include the WKT outline in the metadata.\n",
    "    - decimal_places (int, optional): Number of decimal places to round WKT coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # List to hold metadata for each file\n",
    "    metadata = []\n",
    "\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {\n",
    "        '.shp': 'Shapefile',\n",
    "        '.geojson': 'GeoJSON'\n",
    "    }\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Get the file extension\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(root, filename)\n",
    "\n",
    "            # Get the name of the enclosing folder\n",
    "            folder_name = os.path.basename(os.path.dirname(filepath))\n",
    "            \n",
    "            # Calculate the total size of the folder in MB; can switch to KB\n",
    "            folder_size = get_folder_size(os.path.dirname(filepath), unit='MB')\n",
    "\n",
    "            # Check if the file is a recognized vector format\n",
    "            if file_ext in vector_formats:\n",
    "                try:\n",
    "                    # Read the vector file with GeoPandas\n",
    "                    gdf = gpd.read_file(filepath)\n",
    "\n",
    "                    # Get the original CRS\n",
    "                    original_crs = gdf.crs.to_string() if gdf.crs else 'Unknown'\n",
    "                    # Convert the original CRS to a resolvable URI if possible\n",
    "                    crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "                    # Reproject to WGS84 (EPSG:4326) if needed for bounding box calculation\n",
    "                    if gdf.crs and gdf.crs.to_string() != 'EPSG:4326':\n",
    "                        gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "                    # Calculate and round bounding box\n",
    "                    bounds = gdf.total_bounds if not gdf.empty else [None, None, None, None]\n",
    "                    rounded_bounds = [round(coord, 3) if coord is not None else None for coord in bounds]\n",
    "                    bbox = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "                    # Generate WKT outline if include_wkt is True\n",
    "                    wkt_outline = None\n",
    "                    if include_wkt:\n",
    "                        wkt_outline = generate_wkt_outline(gdf, simplify_tolerance, decimal_places)\n",
    "\n",
    "                    # Process geometry type\n",
    "                    geometry_type = gdf.geom_type.unique()[0] if not gdf.empty else 'Unknown'\n",
    "                    if geometry_type != 'Unknown':\n",
    "                        geometry_type = geometry_type.replace(\"LineString\", \"Line\").replace(\"MultiPolygon\", \"Polygon\") + \" data\"\n",
    "\n",
    "                    # Extract metadata\n",
    "                    file_metadata = {\n",
    "                        column_mapping['filename']: filename,\n",
    "                        column_mapping['folder_name']: folder_name,\n",
    "                        column_mapping['crs']: crs_uri,\n",
    "                        column_mapping['file_format']: vector_formats[file_ext],\n",
    "                        column_mapping['geometry_type']: geometry_type,\n",
    "                        column_mapping['bounding_box']: bbox,\n",
    "                        column_mapping['folder_size']: str(folder_size) + \" MB\"\n",
    "                    }\n",
    "\n",
    "                    # Add the WKT outline to metadata if included\n",
    "                    if include_wkt:\n",
    "                        file_metadata[column_mapping['wkt_outline']] = wkt_outline\n",
    "\n",
    "                    # Add the metadata to the list\n",
    "                    metadata.append(file_metadata)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read vector file {filename}: {e}\")\n",
    "\n",
    "            \n",
    "            # Check if the file is a raster format (e.g., .tif)\n",
    "            elif file_ext == '.tif':\n",
    "                try:\n",
    "                    # Read the raster file with Rasterio\n",
    "                    with rasterio.open(filepath) as src:\n",
    "                        # Get the original CRS\n",
    "                        original_crs = src.crs.to_string() if src.crs else 'Unknown'\n",
    "                        crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "                        # Get the bounding box, handling both object and tuple cases\n",
    "                        bounds = src.bounds\n",
    "                        if isinstance(bounds, tuple):\n",
    "                            left, bottom, right, top = bounds\n",
    "                        else:\n",
    "                            left, bottom, right, top = bounds.left, bounds.bottom, bounds.right, bounds.top\n",
    "\n",
    "                        # Reproject the bounding box to WGS84 if needed\n",
    "                        if src.crs and src.crs.to_string() != 'EPSG:4326':\n",
    "                            from rasterio.warp import transform_bounds\n",
    "                            left, bottom, right, top = transform_bounds(src.crs, 'EPSG:4326', left, bottom, right, top)\n",
    "\n",
    "                        # Round bounding box coordinates\n",
    "                        rounded_bounds = [round(coord, 3) for coord in [left, bottom, right, top]]\n",
    "                        bbox = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "                        # Generate WKT outline if include_wkt is True\n",
    "                        wkt_outline = None\n",
    "                        if include_wkt:\n",
    "                            wkt_outline = generate_raster_wkt([left, bottom, right, top])                \n",
    "                        \n",
    "                        # Extract metadata\n",
    "                        file_metadata = {\n",
    "                            column_mapping['filename']: filename,\n",
    "                            column_mapping['folder_name']: folder_name,\n",
    "                            column_mapping['crs']: crs_uri,\n",
    "                            column_mapping['file_format']: 'GeoTIFF',\n",
    "                            column_mapping['geometry_type']: 'Raster data',\n",
    "                            column_mapping['bounding_box']: bbox,\n",
    "                            column_mapping['folder_size']: str(folder_size) + \" MB\"\n",
    "                        }\n",
    "                        \n",
    "                        # Add the WKT outline to metadata if included\n",
    "                        if include_wkt:\n",
    "                            file_metadata[column_mapping['wkt_outline']] = wkt_outline\n",
    "\n",
    "                        # Add the metadata to the list\n",
    "                        metadata.append(file_metadata)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read raster file {filename}: {e}\")\n",
    "            \n",
    "\n",
    "        # Additional check for geodatabases (folders with .gdb extension)\n",
    "        if root.endswith('.gdb'):\n",
    "            try:\n",
    "                folder_name = os.path.basename(os.path.dirname(root))\n",
    "                folder_size = get_folder_size(root, unit='MB')\n",
    "\n",
    "                # Try listing layers in the geodatabase\n",
    "                try:\n",
    "                    layers = gpd.io.file.fiona.listlayers(root)\n",
    "                    for layer in layers:\n",
    "                        # Read each layer\n",
    "                        gdf = gpd.read_file(root, layer=layer)\n",
    "\n",
    "                        # Get the original CRS\n",
    "                        original_crs = gdf.crs.to_string() if gdf.crs else 'Unknown'\n",
    "                        crs_uri = format_crs_uri(original_crs)\n",
    "\n",
    "                        # Reproject to WGS84 (EPSG:4326) if needed\n",
    "                        if gdf.crs and gdf.crs.to_string() != 'EPSG:4326':\n",
    "                            gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "                        # Calculate and round bounding box\n",
    "                        bounds = gdf.total_bounds if not gdf.empty else [None, None, None, None]\n",
    "                        rounded_bounds = [round(coord, 3) if coord is not None else None for coord in bounds]\n",
    "                        bbox = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "                        # Generate WKT outline if include_wkt is True\n",
    "                        wkt_outline = None\n",
    "                        if include_wkt:\n",
    "                            wkt_outline = generate_wkt_outline(gdf, simplify_tolerance, decimal_places)\n",
    "\n",
    "                        # Process geometry type\n",
    "                        geometry_type = gdf.geom_type.unique()[0] if not gdf.empty else 'Unknown'\n",
    "                        if geometry_type != 'Unknown':\n",
    "                            geometry_type = geometry_type.replace(\"LineString\", \"Line\").replace(\"MultiPolygon\", \"Polygon\") + \" data\"\n",
    "\n",
    "                        # Extract metadata\n",
    "                        file_metadata = {\n",
    "                            column_mapping['filename']: f\"{os.path.basename(root)} - {layer}\",\n",
    "                            column_mapping['folder_name']: folder_name,\n",
    "                            column_mapping['crs']: crs_uri,\n",
    "                            column_mapping['file_format']: 'Geodatabase',\n",
    "                            column_mapping['geometry_type']: geometry_type,\n",
    "                            column_mapping['bounding_box']: bbox,\n",
    "                            column_mapping['folder_size']: str(folder_size) + \" MB\"\n",
    "                        }\n",
    "\n",
    "                        # Add the WKT outline to metadata if included\n",
    "                        if include_wkt:\n",
    "                            file_metadata[column_mapping['wkt_outline']] = wkt_outline\n",
    "\n",
    "                        # Add the metadata to the list\n",
    "                        metadata.append(file_metadata)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read geodatabase {root}: {e}\")\n",
    "                    # Fill in default values for the geodatabase metadata\n",
    "                    file_metadata = {\n",
    "                        column_mapping['filename']: os.path.basename(root),\n",
    "                        column_mapping['folder_name']: folder_name,\n",
    "                        column_mapping['crs']: '',\n",
    "                        column_mapping['file_format']: '',\n",
    "                        column_mapping['geometry_type']: '',\n",
    "                        column_mapping['bounding_box']: '',\n",
    "                        column_mapping['folder_size']: str(folder_size) + \" MB\"\n",
    "                    }\n",
    "\n",
    "                    # Add the WKT outline column as 'None' if included\n",
    "                    if include_wkt:\n",
    "                        file_metadata[column_mapping['wkt_outline']] = ''\n",
    "\n",
    "                    # Add the default metadata to the list\n",
    "                    metadata.append(file_metadata)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error with geodatabase {root}: {e}\")\n",
    "\n",
    "\n",
    "    # Convert the metadata list to a DataFrame\n",
    "    df = pd.DataFrame(metadata)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_csv = os.path.join(directory, 'geospatial_metadata.csv')\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f'Metadata extraction complete. CSV saved to {output_csv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f51cb",
   "metadata": {},
   "source": [
    "### Executing the code for Part 1\n",
    "\n",
    "Run option 1 to process the metadata without extracting the WKT polygon outline\n",
    "    Run option 2 to obtain the outline. Review the simplify_tolerance value and update if needed. `.01` can be used for decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b100767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 Exclude WKT outline from the metadata\n",
    "extract_metadata(root_directory, include_wkt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Include WKT outline in the metadata\n",
    "extract_metadata(root_directory, simplify_tolerance=0.1, include_wkt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdbcaf",
   "metadata": {},
   "source": [
    "## Part 2: Attribute Tables\n",
    "\n",
    "This function will read the attribute table fields and write them to a CSV in a defined directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attribute_table_info(root_directory, output_dir):\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {\n",
    "        '.shp': 'Shapefile',\n",
    "        '.geojson': 'GeoJSON'\n",
    "    }\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, _, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            # Get the file extension\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(root, filename)\n",
    "\n",
    "            # Check if the file is a recognized vector format\n",
    "            if file_ext in vector_formats:\n",
    "                try:\n",
    "                    # Read the vector file with GeoPandas\n",
    "                    gdf = gpd.read_file(filepath)\n",
    "\n",
    "                    # Extract field information\n",
    "                    field_info = []\n",
    "                    for column in gdf.columns:\n",
    "                        field_metadata = {\n",
    "                            'Field Name': column,\n",
    "                            'Data Type': str(gdf[column].dtype),\n",
    "                            'Unique Values': gdf[column].nunique(),\n",
    "                            'Null Values': gdf[column].isnull().sum(),\n",
    "                            'Definition' : '',\n",
    "                            'Definition Source' : ''\n",
    "                        }\n",
    "                        field_info.append(field_metadata)\n",
    "\n",
    "                    # Convert the field information to a DataFrame\n",
    "                    field_df = pd.DataFrame(field_info)\n",
    "\n",
    "                    # Create the output CSV filename\n",
    "                    output_csv = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_fields.csv\")\n",
    "\n",
    "                    # Save the DataFrame to a CSV file\n",
    "                    field_df.to_csv(output_csv, index=False)\n",
    "\n",
    "#                     print(f\"Field information extracted for {filename}. CSV saved to {output_csv}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attribute table information\n",
    "extract_attribute_table_info(root_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50644acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
