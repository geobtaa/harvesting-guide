{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58e54c7",
   "metadata": {},
   "source": [
    "# Extract technical metadata\n",
    "\n",
    "This recipe will extract technical metadata from a directory of datasets and export it to a CSV file. It requires the python libraries `pandas`, `geopandas`, and `rasterio`. Part 1 writes the filenames, coordinate reference system, file format, resource type, and (optionally) the WKT polygon outline. Part 2 creates CSV files of the attribute table field names and types.\n",
    "\n",
    "Created 2024-10-18 by Karen Majewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.warp import transform_bounds\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27766c8",
   "metadata": {},
   "source": [
    "## Part 1: Extract metadata to a CSV\n",
    "\n",
    "### Setup CSV and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5fadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from variable names to desired column headers\n",
    "column_mapping = {\n",
    "    'folder_name': 'Folder Name',\n",
    "    'filename': 'File Name',\n",
    "    'crs': 'Conforms To',\n",
    "    'file_format': 'Format',\n",
    "    \"total_area_km2\": 'Extent',\n",
    "    'spatial_resolution': 'Spatial Resolution',\n",
    "    'geometry_type': 'Resource Type',\n",
    "    'bounding_box': 'Bounding Box',\n",
    "    'wkt_outline': 'Geometry',\n",
    "    'folder_size': 'File Size'\n",
    "    \n",
    "}\n",
    "\n",
    "# Define the root directory for the geospatial data\n",
    "root_directory = 'data'\n",
    "\n",
    "# Define the output directory for the attribute table CSV files\n",
    "output_directory = 'codebooks'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22227105",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "### File size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb611c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add up the files in each dataset folder\n",
    "\n",
    "def get_folder_size(folder_path, unit='MB', decimal_places=3):\n",
    "    \"\"\"\n",
    "    Calculate the total size of all files in a folder and return it in the specified unit.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder.\n",
    "    - unit (str): The unit for the size ('bytes', 'KB', 'MB'). Default is 'MB'.\n",
    "    - decimal_places (int): The number of decimal places to round the size to. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    - float: Total size of the folder contents in the specified unit, rounded to the specified number of decimal places.\n",
    "    \"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # Add to the total size only if it is a file (not a broken link, etc.)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    # Convert the total size to the specified unit\n",
    "    if unit == 'KB':\n",
    "        total_size /= 1024  # Convert bytes to kilobytes\n",
    "    elif unit == 'MB':\n",
    "        total_size /= (1024 * 1024)  # Convert bytes to megabytes\n",
    "\n",
    "    # Round the total size to the specified number of decimal places\n",
    "    rounded_size = round(total_size, decimal_places)\n",
    "    return rounded_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62c94c",
   "metadata": {},
   "source": [
    "### Geometry type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8023360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_geometry_type(data, is_raster=False):\n",
    "    \"\"\"\n",
    "    Determine the geometry type of a GeoDataFrame or indicate if the dataset is a raster.\n",
    "\n",
    "    Parameters:\n",
    "    - data (GeoDataFrame or DatasetReader): The data source, which can be a GeoDataFrame for vector data or DatasetReader for raster.\n",
    "    - is_raster (bool): Flag to indicate if the data source is a raster.\n",
    "\n",
    "    Returns:\n",
    "    - str: The geometry type description, or 'Unknown' if the geometry type cannot be determined.\n",
    "    \"\"\"\n",
    "    if is_raster:\n",
    "        return \"Raster data\"\n",
    "\n",
    "    if data.empty or data.geometry.is_empty.all():\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Get unique geometry types in the GeoDataFrame\n",
    "        geometry_types = data.geom_type.unique()\n",
    "\n",
    "        # Format the geometry type for output\n",
    "        if len(geometry_types) == 1:\n",
    "            # Single geometry type\n",
    "            geometry_type = geometry_types[0].replace(\"LineString\", \"Line\").replace(\"MultiPolygon\", \"Polygon\")\n",
    "        else:\n",
    "            # Mixed geometry types\n",
    "            geometry_type = \"Mixed geometries\"\n",
    "\n",
    "        return f\"{geometry_type} data\"\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to determine geometry type: {e}\")\n",
    "        return 'Unknown'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0a43e",
   "metadata": {},
   "source": [
    "### Report original CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reformat the CRS into a resolvable URI\n",
    "\n",
    "def format_crs_uri(crs_string):\n",
    "    # If the CRS is in the \"EPSG:xxxx\" format, convert it to a resolvable URI\n",
    "    if crs_string and crs_string.startswith(\"EPSG:\"):\n",
    "        epsg_code = crs_string.split(\":\")[1]\n",
    "        return f\"https://epsg.io/{epsg_code}\"\n",
    "    else:\n",
    "        # Return the original CRS string if it's not an EPSG code\n",
    "        return crs_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54400b40",
   "metadata": {},
   "source": [
    "### Rounding function (check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_coordinates(geometry, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Round the coordinates of a geometry to the specified number of decimal places.\n",
    "\n",
    "    Parameters:\n",
    "    - geometry (Geometry): The input Shapely geometry.\n",
    "    - decimal_places (int): Number of decimal places to round to.\n",
    "\n",
    "    Returns:\n",
    "    - Geometry: The geometry with rounded coordinates.\n",
    "    \"\"\"\n",
    "    if geometry.is_empty:\n",
    "        return geometry\n",
    "\n",
    "    # Function to round coordinates\n",
    "    def rounder(x, y, z=None):\n",
    "        if z is None:\n",
    "            return (round(x, decimal_places), round(y, decimal_places))\n",
    "        else:\n",
    "            return (round(x, decimal_places), round(y, decimal_places), round(z, decimal_places))\n",
    "\n",
    "    # Apply the rounding function using transform\n",
    "    return transform(rounder, geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef278ad",
   "metadata": {},
   "source": [
    "### Bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bounding_box(gdf, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Calculate and format the bounding box for a GeoDataFrame in WGS84 (EPSG:4326).\n",
    "    \n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame to process.\n",
    "    - decimal_places (int, optional): Number of decimal places to round coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted bounding box as a string.\n",
    "    \"\"\"\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Convert to WGS84 for bounding box calculation\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "        bounds = gdf.total_bounds\n",
    "        rounded_bounds = [round(coord, decimal_places) for coord in bounds]\n",
    "        return f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "    except Exception:\n",
    "        return 'Unknown'\n",
    "\n",
    "\n",
    "def calculate_bounding_box_raster(src, decimal_places=4):\n",
    "    \"\"\"\n",
    "    Calculate the bounding box and WKT outline for a raster file in WGS84 (EPSG:4326).\n",
    "    \n",
    "    Parameters:\n",
    "    - src (rasterio.io.DatasetReader): The raster source.\n",
    "    - decimal_places (int, optional): Number of decimal places to round coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the formatted bounding box as a string and the WKT representation of the bounding box.\n",
    "    \"\"\"\n",
    "    if src.crs is None:\n",
    "        return 'Unknown', 'None'\n",
    "\n",
    "    try:\n",
    "        # Reproject the bounding box to WGS84 if needed\n",
    "        left, bottom, right, top = src.bounds\n",
    "        if src.crs.to_string() != 'EPSG:4326':\n",
    "            left, bottom, right, top = transform_bounds(src.crs, 'EPSG:4326', left, bottom, right, top)\n",
    "\n",
    "        # Round the coordinates\n",
    "        rounded_bounds = [round(coord, decimal_places) for coord in [left, bottom, right, top]]\n",
    "        bbox_str = f\"{rounded_bounds[0]},{rounded_bounds[1]},{rounded_bounds[2]},{rounded_bounds[3]}\"\n",
    "\n",
    "        # Create WKT for a Polygon representing the bounding box\n",
    "        wkt_outline = f\"POLYGON(({rounded_bounds[0]} {rounded_bounds[1]}, {rounded_bounds[0]} {rounded_bounds[3]}, \" \\\n",
    "                      f\"{rounded_bounds[2]} {rounded_bounds[3]}, {rounded_bounds[2]} {rounded_bounds[1]}, \" \\\n",
    "                      f\"{rounded_bounds[0]} {rounded_bounds[1]}))\"\n",
    "\n",
    "        return bbox_str, wkt_outline\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate bounding box and WKT outline: {e}\")\n",
    "        return 'Unknown', 'None'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b8716",
   "metadata": {},
   "source": [
    "### Geometry (WKT Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75322f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wkt_outline(gdf, simplify_tolerance=None, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Generate a WKT representation of a generalized outline for the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame containing the geometries.\n",
    "    - simplify_tolerance (float, optional): The tolerance for the simplify() method to reduce detail.\n",
    "    - decimal_places (int, optional): The number of decimal places to round the coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - str: The WKT representation of the generalized outline.\n",
    "    \"\"\"\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'None'\n",
    "\n",
    "    try:\n",
    "        # Convert to WGS84 for WKT generation\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "        # Create a unified geometry from all geometries in the GeoDataFrame\n",
    "        unified_geom = gdf.geometry.unary_union\n",
    "\n",
    "        # Use the convex hull to create a generalized outline\n",
    "        if not unified_geom.is_empty:\n",
    "            generalized_outline = unified_geom.convex_hull\n",
    "        else:\n",
    "            return 'None'\n",
    "\n",
    "        # Optionally simplify the outline for further generalization\n",
    "        if simplify_tolerance is not None:\n",
    "            generalized_outline = generalized_outline.simplify(simplify_tolerance)\n",
    "\n",
    "        # Round the coordinates of the outline\n",
    "        generalized_outline = round_coordinates(generalized_outline, decimal_places)\n",
    "\n",
    "        # Convert the resulting geometry to WKT using shapely's wkt module\n",
    "        if isinstance(generalized_outline, Polygon):\n",
    "            wkt_outline = generalized_outline.wkt\n",
    "        else:\n",
    "            return 'None'\n",
    "\n",
    "        return wkt_outline\n",
    "    except Exception:\n",
    "        return 'None'\n",
    "\n",
    "def generate_raster_wkt(bbox, src_crs=None, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Generate a WKT representation of a bounding box for a raster, optionally transforming to WGS84.\n",
    "\n",
    "    Parameters:\n",
    "    - bbox (list): A list of bounding box coordinates [left, bottom, right, top].\n",
    "    - src_crs (CRS, optional): The original CRS of the bounding box. If provided and not EPSG:4326, the bbox will be transformed.\n",
    "    - decimal_places (int, optional): Number of decimal places to round coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - str: The WKT representation of the bounding box as a Polygon.\n",
    "    \"\"\"\n",
    "    left, bottom, right, top = bbox\n",
    "\n",
    "    # If src_crs is provided and is not EPSG:4326, transform the bounding box\n",
    "    if src_crs and src_crs.to_string() != 'EPSG:4326':\n",
    "        left, bottom, right, top = transform_bounds(src_crs, 'EPSG:4326', left, bottom, right, top)\n",
    "\n",
    "    # Round the coordinates\n",
    "    left = round(left, decimal_places)\n",
    "    bottom = round(bottom, decimal_places)\n",
    "    right = round(right, decimal_places)\n",
    "    top = round(top, decimal_places)\n",
    "\n",
    "    # Create the WKT for a Polygon representing the bounding box\n",
    "    wkt = f\"POLYGON(({left} {bottom}, {left} {top}, {right} {top}, {right} {bottom}, {left} {bottom}))\"\n",
    "    return wkt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce00478",
   "metadata": {},
   "source": [
    "### Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_area(gdf):\n",
    "    \"\"\"\n",
    "    Calculate the total area covered by a GeoDataFrame in square kilometers using an equal-area projection.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame to process.\n",
    "\n",
    "    Returns:\n",
    "    - float or str: The total area in square kilometers, or 'Unknown' if unavailable.\n",
    "    \"\"\"\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Reproject to an equal-area projection for accurate area calculation\n",
    "        gdf = gdf.to_crs(epsg=6933)\n",
    "        total_area_km2 = gdf.geometry.area.sum() / 1e6  # Convert to square kilometers\n",
    "        return round(total_area_km2, 3)\n",
    "    except Exception:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def calculate_total_area_raster(src):\n",
    "    \"\"\"\n",
    "    Calculate the total area covered by a raster file in square kilometers.\n",
    "\n",
    "    Parameters:\n",
    "    - src (rasterio.io.DatasetReader): The raster source.\n",
    "\n",
    "    Returns:\n",
    "    - float or str: The total area in square kilometers, or 'Unknown' if unavailable.\n",
    "    \"\"\"\n",
    "    if src.crs is None:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Reproject to an equal-area projection for accurate area calculation\n",
    "        gdf = gdf.to_crs(epsg=6933)\n",
    "        # Calculate area based on pixel resolution and total number of pixels\n",
    "        pixel_size_x, pixel_size_y = src.res  # Resolution of each pixel in meters\n",
    "        total_pixels = src.width * src.height  # Total number of pixels in the raster\n",
    "        total_area_m2 = pixel_size_x * pixel_size_y * total_pixels  # Total area in square meters\n",
    "        total_area_km2 = total_area_m2 / 1e6  # Convert to square kilometers\n",
    "\n",
    "        return round(total_area_km2, 3)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate total area for raster: {e}\")\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44f505",
   "metadata": {},
   "source": [
    "### Spatial resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ab225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTOR: Calculate average distance between vertices\n",
    "\n",
    "\n",
    "def calculate_avg_vertex_distance(geom):\n",
    "    \"\"\"\n",
    "    Calculate the average distance between consecutive vertices of a polygon, line geometry, or multi-part geometry.\n",
    "\n",
    "    Parameters:\n",
    "    - geom (shapely.geometry): A Shapely geometry object (Polygon, LineString, MultiPolygon, or MultiLineString).\n",
    "\n",
    "    Returns:\n",
    "    - float: The average distance between consecutive vertices, or None if not applicable.\n",
    "    \"\"\"\n",
    "    if geom.is_empty or not geom.is_valid:\n",
    "        return None\n",
    "    \n",
    "    # Handle multi-part geometries by iterating through each sub-geometry\n",
    "    if geom.geom_type.startswith('Multi'):\n",
    "        all_distances = []\n",
    "        for part in geom.geoms:\n",
    "            part_distance = calculate_avg_vertex_distance(part)\n",
    "            if part_distance is not None:\n",
    "                all_distances.append(part_distance)\n",
    "        # Calculate the mean of the distances if there are any valid distances\n",
    "        if all_distances:\n",
    "            return sum(all_distances) / len(all_distances)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Handle single-part geometries\n",
    "    coords = list(geom.exterior.coords) if geom.geom_type == 'Polygon' else list(geom.coords)\n",
    "    \n",
    "    if len(coords) < 2:\n",
    "        return None\n",
    "    \n",
    "    # Calculate the distance between each consecutive pair of coordinates\n",
    "    distances = [\n",
    "        ((coords[i][0] - coords[i-1][0]) ** 2 + (coords[i][1] - coords[i-1][1]) ** 2) ** 0.5\n",
    "        for i in range(1, len(coords))\n",
    "    ]\n",
    "    \n",
    "    # Return the average distance\n",
    "    return sum(distances) / len(distances)\n",
    "\n",
    "def calculate_spatial_resolution_vector(gdf):\n",
    "    \"\"\"\n",
    "    Calculate the average spatial resolution (vertex distance) for a GeoDataFrame using an equal-area projection.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): The GeoDataFrame to process.\n",
    "\n",
    "    Returns:\n",
    "    - float or str: The spatial resolution in meters, or 'Unknown' if unavailable.\n",
    "    \"\"\"\n",
    "    if gdf.empty or gdf.crs is None:\n",
    "        return 'Unknown'\n",
    "\n",
    "    try:\n",
    "        # Reproject to an equal-area projection for accurate spatial resolution calculation\n",
    "        gdf = gdf.to_crs(epsg=6933)\n",
    "        avg_vertex_distance = gdf.geometry.apply(calculate_avg_vertex_distance)\n",
    "        if avg_vertex_distance.notna().any():\n",
    "            return round(avg_vertex_distance.dropna().mean(), 3)\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    except Exception:\n",
    "        return 'Unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(directory, simplify_tolerance=None, include_wkt=True, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Extract metadata from geospatial datasets in a directory.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): The directory containing the datasets.\n",
    "    - simplify_tolerance (float, optional): Tolerance for simplifying WKT outlines.\n",
    "    - include_wkt (bool, optional): Whether to include the WKT outline in the metadata.\n",
    "    - decimal_places (int, optional): Number of decimal places to round WKT coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    metadata = []  # List to hold metadata for each file\n",
    "\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {'.shp': 'Shapefile', '.geojson': 'GeoJSON'}\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "            filepath = os.path.join(root, filename)\n",
    "            folder_name = os.path.basename(os.path.dirname(filepath))\n",
    "            folder_size = get_folder_size(os.path.dirname(filepath), unit='MB')\n",
    "\n",
    "            # Vector Data Processing\n",
    "            if file_ext in vector_formats:\n",
    "                process_vector(filepath, filename, vector_formats[file_ext], folder_name, folder_size, metadata,\n",
    "                               simplify_tolerance, include_wkt, decimal_places)\n",
    "\n",
    "            # Raster Data Processing\n",
    "            elif file_ext == '.tif':\n",
    "                process_raster(filepath, filename, folder_name, folder_size, metadata, include_wkt, decimal_places)\n",
    "\n",
    "        # Geodatabase Processing (directories with .gdb)\n",
    "        if root.endswith('.gdb'):\n",
    "            process_geodatabase(root, folder_name, folder_size, metadata, simplify_tolerance, include_wkt, decimal_places)\n",
    "\n",
    "    # Convert metadata to DataFrame and save as CSV\n",
    "    df = pd.DataFrame(metadata)\n",
    "    output_csv = os.path.join(directory, 'geospatial_metadata.csv')\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f'Metadata extraction complete. CSV saved to {output_csv}')\n",
    "\n",
    "\n",
    "def process_vector(filepath, filename, file_format, folder_name, folder_size, metadata, simplify_tolerance, include_wkt, decimal_places):\n",
    "    try:\n",
    "        gdf = gpd.read_file(filepath)\n",
    "        original_crs = gdf.crs.to_string() if gdf.crs else 'Unknown'\n",
    "        crs_uri = format_crs_uri(original_crs) if gdf.crs else 'Unknown'\n",
    "\n",
    "        # Calculate metadata components\n",
    "        bbox = calculate_bounding_box(gdf, decimal_places)\n",
    "        wkt_outline = generate_wkt_outline(gdf, simplify_tolerance, decimal_places) if include_wkt else None\n",
    "        total_area_km2 = calculate_total_area(gdf)  # Use vector area calculation\n",
    "        spatial_resolution = calculate_spatial_resolution_vector(gdf)\n",
    "\n",
    "        # Process geometry type\n",
    "        geometry_type = process_geometry_type(gdf)\n",
    "\n",
    "        # Store metadata\n",
    "        file_metadata = {\n",
    "            'filename': filename,\n",
    "            'folder_name': folder_name,\n",
    "            'crs': crs_uri,\n",
    "            'file_format': file_format,\n",
    "            'geometry_type': geometry_type,\n",
    "            'bounding_box': bbox,\n",
    "            'total_area_km2': total_area_km2,\n",
    "            'spatial_resolution': spatial_resolution,\n",
    "            'folder_size': f\"{folder_size} MB\",\n",
    "            'wkt_outline': wkt_outline if include_wkt else None\n",
    "        }\n",
    "        metadata.append(file_metadata)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read vector file {filename}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def process_raster(filepath, filename, folder_name, folder_size, metadata, include_wkt, decimal_places):\n",
    "    try:\n",
    "        with rasterio.open(filepath) as src:\n",
    "            original_crs = src.crs.to_string() if src.crs else 'Unknown'\n",
    "            crs_uri = format_crs_uri(original_crs) if src.crs else 'Unknown'\n",
    "\n",
    "            # Calculate spatial resolution and area\n",
    "            pixel_size_x, pixel_size_y = src.res\n",
    "            spatial_resolution = round((pixel_size_x + pixel_size_y) / 2, 3)\n",
    "            total_area_km2 = calculate_total_area_raster(src)  # Use raster area calculation\n",
    "\n",
    "            # Get bounding box and WKT outline\n",
    "            bbox, wkt_outline = calculate_bounding_box_raster(src, decimal_places)\n",
    "\n",
    "            # Store metadata\n",
    "            file_metadata = {\n",
    "                'filename': filename,\n",
    "                'folder_name': folder_name,\n",
    "                'crs': crs_uri,\n",
    "                'file_format': 'GeoTIFF',\n",
    "                'geometry_type': 'Raster data',\n",
    "                'bounding_box': bbox,\n",
    "                'total_area_km2': total_area_km2,\n",
    "                'spatial_resolution': spatial_resolution,\n",
    "                'folder_size': f\"{folder_size} MB\",\n",
    "                'wkt_outline': wkt_outline if include_wkt else None\n",
    "            }\n",
    "            metadata.append(file_metadata)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read raster file {filename}: {e}\")\n",
    "\n",
    "\n",
    "# Helper function for geodatabase processing\n",
    "def process_geodatabase(root, folder_name, folder_size, metadata, simplify_tolerance, include_wkt, decimal_places):\n",
    "    try:\n",
    "        layers = gpd.io.file.fiona.listlayers(root)\n",
    "        for layer in layers:\n",
    "            gdf = gpd.read_file(root, layer=layer)\n",
    "            original_crs = gdf.crs.to_string() if gdf.crs else 'Unknown'\n",
    "            crs_uri = format_crs_uri(original_crs) if gdf.crs else 'Unknown'\n",
    "\n",
    "            # Calculate metadata components\n",
    "            bbox = calculate_bounding_box(gdf, decimal_places)\n",
    "            wkt_outline = generate_wkt_outline(gdf, simplify_tolerance, decimal_places) if include_wkt else None\n",
    "            total_area_km2 = calculate_total_area(gdf)\n",
    "            spatial_resolution = calculate_spatial_resolution_vector(gdf)\n",
    "\n",
    "            # Process geometry type\n",
    "            geometry_type = process_geometry_type(gdf)\n",
    "\n",
    "            # Store metadata\n",
    "        file_metadata = {\n",
    "            'filename': f\"{os.path.basename(root)} - {layer}\",\n",
    "            'folder_name': folder_name,\n",
    "            'crs': crs_uri,\n",
    "            'file_format': 'Geodatabase',\n",
    "            'geometry_type': geometry_type,\n",
    "            'bounding_box': bbox,\n",
    "            'total_area_km2': total_area_km2,\n",
    "            'spatial_resolution': spatial_resolution,\n",
    "            'folder_size': f\"{folder_size} MB\",\n",
    "            'wkt_outline': wkt_outline if include_wkt else None\n",
    "        }\n",
    "        metadata.append(file_metadata)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read geodatabase {root}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e8478",
   "metadata": {},
   "source": [
    "### Executing the code for Part 1\n",
    "\n",
    "Run option 1 to process the metadata without extracting the WKT polygon outline\n",
    "    Run option 2 to obtain the outline. Review the simplify_tolerance value and update if needed. `.01` can be used for decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 Exclude WKT outline from the metadata\n",
    "extract_metadata(root_directory, include_wkt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Include WKT outline in the metadata\n",
    "extract_metadata(root_directory, simplify_tolerance=.001, include_wkt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140b4b5",
   "metadata": {},
   "source": [
    "## Part 2: Attribute Tables\n",
    "\n",
    "This function will read the attribute table fields and write them to a CSV in a defined directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919eff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attribute_table_info(root_directory, output_dir):\n",
    "    # Supported vector formats by GeoPandas\n",
    "    vector_formats = {\n",
    "        '.shp': 'Shapefile',\n",
    "        '.geojson': 'GeoJSON'\n",
    "    }\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, _, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            # Get the file extension\n",
    "            file_ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(root, filename)\n",
    "\n",
    "            # Check if the file is a recognized vector format\n",
    "            if file_ext in vector_formats:\n",
    "                try:\n",
    "                    # Read the vector file with GeoPandas\n",
    "                    gdf = gpd.read_file(filepath)\n",
    "\n",
    "                    # Extract field information\n",
    "                    field_info = []\n",
    "                    for column in gdf.columns:\n",
    "                        field_metadata = {\n",
    "                            'Field Name': column,\n",
    "                            'Data Type': str(gdf[column].dtype),\n",
    "                            'Unique Values': gdf[column].nunique(),\n",
    "                            'Null Values': gdf[column].isnull().sum(),\n",
    "                            'Definition' : '',\n",
    "                            'Definition Source' : ''\n",
    "                        }\n",
    "                        field_info.append(field_metadata)\n",
    "\n",
    "                    # Convert the field information to a DataFrame\n",
    "                    field_df = pd.DataFrame(field_info)\n",
    "\n",
    "                    # Create the output CSV filename\n",
    "                    output_csv = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_fields.csv\")\n",
    "\n",
    "                    # Save the DataFrame to a CSV file\n",
    "                    field_df.to_csv(output_csv, index=False)\n",
    "\n",
    "#                     print(f\"Field information extracted for {filename}. CSV saved to {output_csv}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attribute table information\n",
    "extract_attribute_table_info(root_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
